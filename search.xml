<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>DevOps 实战</title>
      <link href="2020/09/05/devops/"/>
      <url>2020/09/05/devops/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h2 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h2><p>维基百科的定义</p><blockquote><p>DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。</p></blockquote><p><strong>DevOps 是通过平台（Platform）、流程（Process）和人（People）的有机整合，以C（协作）A（自动化）L（精益）M（度量）S（共享）文化为指引，旨在建立一种可以快速交付价值并且具有持续改进能力的现代化 IT 组织。</strong></p><h2 id="DevOps-的价值"><a href="#DevOps-的价值" class="headerlink" title="DevOps 的价值"></a>DevOps 的价值</h2><p><strong>高效的软件交付方式</strong></p><p>根据DevOps现状报告，可以得出 DevOps 的 4 个结果指标。</p><ol><li><strong>部署频率</strong>：指应用和服务向生产环境部署代码的频率。</li><li><strong>变更前置时间</strong>：指代码从提交到成功运行在生产环境的时长。</li><li><strong>服务恢复时间</strong>：指线上应用和服务出现故障到恢复运行的时长。</li><li><strong>变更失败率</strong>：指应用和服务在生产环境部署失败或者部署后导致服务降级的比例。</li></ol><p>每年，这个报告都会基于这 4 个核心指标统计行业内高效能团队和低效能团队之间的差距。从去年的数据来看，与低效能团队相比，高效能团队的部署频率高了 46 倍，变更前置时间快了 2500 多倍，服务恢复时间也快了 2600 多倍，失败率低了 7 倍。</p><p>DevOps 状态报告中提到的四项结果指标，分别代表了软件交付的两个最重要的方面，也就是交付效率和交付质量。而且，从数据结果中，我们还能得到一个惊人的发现，那就是高效能的组织不仅做到了高效率，还实现了高质量，由此可见，鱼与熊掌可以兼得。</p><blockquote><p>DevOps 状态报告合集 <a href="https://pan.baidu.com/s/1W7-_et-wulD7AueBU2KTow">https://pan.baidu.com/s/1W7-_et-wulD7AueBU2KTow</a> 提取码：mgl1</p></blockquote><p><strong>激发团队的创造力</strong></p><p>实施 DevOps，一方面可以通过种种流程优化和自动化能力，改善软件开发团队的工作节奏，另一方面，也可以让大家关注同一个目标，彼此信任，高效协作，调动员工的积极性和创新能力，从而让整个团队进入一种积极创造价值的状态，而这所带来的影响远非建设一两个工具平台可比拟的。</p><h2 id="DevOps-的实施"><a href="#DevOps-的实施" class="headerlink" title="DevOps 的实施"></a>DevOps 的实施</h2><h3 id="DevOps-工具"><a href="#DevOps-工具" class="headerlink" title="DevOps 工具"></a>DevOps 工具</h3><p><strong>一切软件交付过程中的手动环节，都是未来可以尝试进行优化的方向。</strong>即便在运维圈里面，<strong>ITIL（IT 基础架构库)</strong> 一直是运维赖以生存的基石，也并不妨碍自动化的理念逐步深入到ITIL 流程之中，从而在受控的基础上不断优化流程流转效率。</p><p>工具平台的引入和建设就成为了 DevOps 打动人的关键因素之一。但是大量的引入这类工具，会造成企业内部的工具平台泛滥，很多同质化的工具在完成从0 到 1 的过程后就停滞不前，陷入重复的怪圈，显然也是一种资源浪费。也有很多公司引入了完整的敏捷项目管理工具，但是却以传统项目管理的方式来使用这套工具，效率跟以前相比并没有明显的提升。对于自研平台来说，也是同样的道理。如果仅仅是把线下的审批流程搬到线上执行，固然能提升一部分执行效率，但是对于企业期望的质变来说，却是相距甚远。</p><p>说到底，工具没法解决人的问题，这样一条看似取巧的路径，却没法解决企业的根本问题。这时候，就需要文化闪亮登场了。</p><h3 id="DevOps-文化"><a href="#DevOps-文化" class="headerlink" title="DevOps 文化"></a>DevOps 文化</h3><p>首先要建立一套DevOps的机制，包括 OKR 指标的设定、关键指标达成后的激励、成立专项的工作小组、引入外部的咨询顾问，以及一套客观的评判标准，这一切都保证了团队走在正确的道路上。而承载这套客观标准的就是一套通用的度量平台，说到底，还是需要将<strong>规则内建于工具之中，并通过工具来指导实践。</strong></p><p>这样一来，当团队通过 DevOps 获得了实实在在的改变，那么 <strong>DevOps 所倡导的职责共担、持续改进的文化</strong>自然也会生根发芽。</p><p>所以你看，DevOps 中的文化和工具，本身就是一体两面，我们既不能盲目地奉行工具决定论，上来就大干快干地采购和建设工具，也不能盲目地空谈文化，在内部形成一种脱离实际的风气。</p><h3 id="DevOps-的-3-个支柱"><a href="#DevOps-的-3-个支柱" class="headerlink" title="DevOps 的 3 个支柱"></a>DevOps 的 3 个支柱</h3><p>对工具和文化的体系化认知，可以归纳到 DevOps 的 3 个支柱之中，即<strong>人（People）、流程（Process）和平台（Platform）</strong>。3 个支柱之间两两组合，构成了我们实施 DevOps的”正确姿势”，只强调其中一个维度的重要性，明显是很片面的。</p><ul><li><p><strong>人 + 流程 = 文化</strong></p><p>在具体的流程之下，人会形成一套行为准则，而这套行为准则会潜移默化地影响软件交付效率和质量的方方面面。这些行为准则组合到一起，就构成了企业内部的文化。</p><p><strong>指导 DevOps 落地发展的思想，就是 DevOps 的文化</strong>。</p><ul><li><strong>责任共担和质量导向的文化：</strong>在谷歌 SRE 的实践中，研发交付的应用需要自运维一段时间，并且要在达到一定的质量指标之后才会交接给 SRE 进行运维。但是，为了避免出现“研发一走，运维背锅”的情况，他们还建立了“打回”的流程，也就是当 SRE 运维一段时间后，如果发现应用稳定性不达标，就会重新交还给开发自己负责维护，这样一来，研发就会主动地保障线上应用的质量。</li><li><strong>线上安全点数的文化：</strong>在一定的额度范围内，允许团队出现问题，并且不追究责任。这就可以激励团队更加主动地完成交付活动，不必每一次都战战兢兢，生怕出错。通过流程和行为的改变，团队的文化也在慢慢地改进。</li></ul></li><li><p><strong>流程 + 平台 = 工具</strong></p><p><strong>平台的最大意义，就是承载企业内部的标准化流程。</strong>当这些标准化流程被固化在平台之中时，所有人都能够按照一套规则沟通，沟通效率显然会大幅提升。</p><p><strong>平台上固化的每一种流程，其实都是可以用来解决实际问题的工具。</strong>很多人分不清工具和平台的关系，好像只要引入或者开发了一个工具，都可以称之为平台，也正因为这样，企业内部的平台比比皆是。</p><p>实际上，平台除了有<strong>用户量、认可度、老板加持</strong>等因素之外，还会有 3 个显著特征。</p><ol><li><strong>吸附效应</strong>：平台会不断地吸收中小型的工具，逐渐成为一个能力集合体。</li><li><strong>规模效应</strong>：平台的成本不会随着使用方的扩展而线性增加，能够实现规模化。</li><li><strong>积木效应</strong>：平台具备基础通用共享能力，能够快速搭建新的业务实现。</li></ol></li><li><p><strong>平台 + 人 = 培训赋能</strong></p><p>平台是标准化流程的载体，一方面可以规范和约束员工的行为，另一方面，通过平台赋能，所有人都能以相同的操作，获得相同的结果。这样一来，跨领域之间的交接和专家就被平台所取代，当一件事情不再依赖于个人的时候，等待的浪费就会大大降低，平台就成了组织内部的能力集合体。</p><p>但与此同时，当我们定义了期望达到的目标，并提供了平台工具，那么对人的培训就变得至关重要，因为只有这样，才能让工具平台发挥最大的效用。更加重要的是，通过最终的用户使用验证，可以发现大量的可改进空间，进一步推动平台能力的提升，从而带动组织整体的飞轮效应，加速组织的进化。</p></li></ul><p>所以你看，<strong>文化、工具和培训</strong>作为 DevOps 建设的 3 个重心，折射出来的是对<strong>组织流程、平台和人</strong>的关注，<strong>三位一体，缺一不可</strong>。</p><h2 id="DevOps的实施路线图"><a href="#DevOps的实施路线图" class="headerlink" title="DevOps的实施路线图"></a>DevOps的实施路线图</h2><p>通过模型和框架，来帮助企业识别当前的 DevOps 能力水平并加以改进。</p><p>下列是DevOps的熟练度模型：</p><p><img src="/assets/images/ops/devops/devops-model.png" alt="devops-model"></p><blockquote><p>研发运营一体化（DevOps）能力成熟度模型</p></blockquote><p>在实际参考模型和框架的时候，我认为应该尽量遵循以下步骤和原则：</p><ul><li><strong>1.识别差距。</strong> 通过和模型、框架进行对标，可以快速识别出企业当前存在的短板和差距，并建立企业当前的能力状态基线，用于对比改进后所取得的效果。</li><li><strong>2.锚定目标。</strong>数字化转型的核心在于优化软件交付效率。通过对标模型框架，企业需要明确什么是影响软件交付效率进一步提升的最大瓶颈，当前存在的最大痛点是什么，哪些能力的改善有助于企业达成预定的目标……同时，要根据企业的现状，甄别对标的差距结果，识别出哪些是真实有效的，哪些可以通过平台能力快速补齐。</li><li><strong>3.关注能力。</strong>模型和框架是能力和实践的集合，也就是道法术器的“术”这个层面，所以在应用模型的过程中，核心的关注点应该在能力本身，而不是单纯地比较数字和结果。根据锚定的目标识别所需要的能力，再导入与能力相匹配的实践，不断强化实践，从而使能力本身得到提升。</li><li><strong>4.持续改进。</strong>模型和框架本身也不是一成不变的，也需要像 DevOps 一样不断迭代更新，以适应更高的软件交付需要。</li></ul><p>下面是以模型为指导，对示例企业进行了全面梳理，汇总了一张大盘图</p><p><img src="/assets/images/ops/devops/devops-model-use.png" alt="devops-model-use"></p><p>接下来，针对识别出来的这些差距点，找到需要改进的目标和预期效果，并分析哪些关键能力制约了交付效率的提升，对问题进行逐个优化。</p><p>由此可以看出，<strong>DevOps 的能力实践和能力框架模型相辅相成</strong>：能力实践定义了企业落地DevOps 的路线图和主要建设顺序，能力模型可以指导支撑方法的各类实践的落地建设；能力实践时刻跟随企业价值交付的导向，而能力模型的积累和沉淀，能够让企业游刃有余地面对未来的各种挑战。</p><p>至于 ITIL 和 CMMI，这些过往的框架体系自身也在跟随 DevOps 的大潮在持续演进，比如以流程合规为代表的 ITIL 最近推出了第 4 个版本。我们引用一下 <strong>ITIL V4 的指导原则，包括：关注价值、关注现状、交互式流程和反馈、协作和可视化、自动化和持续优化、极简原则和关注实践。</strong></p><h2 id="价值流分析"><a href="#价值流分析" class="headerlink" title="价值流分析"></a>价值流分析</h2><p><strong>什么是价值？</strong>简单来说，价值就是<strong>那些带给企业生存发展的核心资源</strong>，比如生产力、盈利能力、市场份额、用户满意度等。</p><p><strong>VSM</strong> 是 Value Stream Mapping 的缩写，也就是我们常说的<strong>价值流图</strong>。它起源于传统制造业的精益思想，用于分析和管理一个产品交付给用户所经历的业务流、信息流，以及各个阶段的移交过程。</p><p>说白了，VSM 就是要说清楚在需求提出后，怎么一步步地加工原材料，进行层层的质量检查，最终将产品交付给用户的过程。通过观察完整流程中各个环节的流动效率和交付质量，识别不合理的、低效率的环节，进行优化，从而实现整体效率的提升。</p><p>通过使用价值流图对软件交付过程进行建模，使整个过程可视化，从而识别出交付的瓶颈和各个环节之间的依赖关系，这恰恰是“DevOps 三步工作法”的第一步“流动”所要解决的问题。</p><p><strong>DevOps 三步工作法:</strong></p><p><strong>第一步：流动。</strong>通过工作可视化，限制在制品数量，并注入一系列的工程实践，从而加速从开发到运营的流动过程，实现低风险的发布。<br><strong>第二步：反馈。</strong>通过注入流动各个过程的反馈能力，使缺陷在第一时间被发现，用户和运营数据第一时间展示，从而提升组织的响应能力。<br><strong>第三步：持续学习和试验。</strong>没有任何文化和流程是天生完美的，通过团队激励学习分享，将持续改进注入日常工作，使组织不断进步。</p><h3 id="VSM关键要素"><a href="#VSM关键要素" class="headerlink" title="VSM关键要素"></a>VSM关键要素</h3><ol><li><strong>前置时间（Lead Time，简称 LT）</strong>。前置时间在 DevOps 中是一项非常重要的指标。具体来说，它是指一个需求从提出（典型的就是创建一个需求任务）的时间点开始，一直到最终上线交付给用户为止的时间周期。这部分时间直接体现了软件开发团队的<strong>交付速率</strong>，并且可以用来计算<strong>交付吞吐量</strong>。DevOps 的核心使命之一就是优化这段时长。</li><li><strong>增值活动时间和不增值活动时间（Value Added Time/Non-Value Added Time，简称VAT/NVAT）</strong>。在精益思想中，最重要的就是<strong>消除浪费</strong>，也就是说最大化流程中那些增值活动的时长，降低不增值活动的时长。在软件开发行业中，典型的不增值活动有很多，比如无意义的会议、需求的反复变更、开发的缺陷流向下游带来的返工等。</li><li><strong>完成度和准确度（% Complete/Accurate，简称 %C/A）</strong>。这个指标用来表明工作的质量，也就是有多少工作因为质量不符合要求而被下游打回。这里面蕴含了大量的沟通和返工成本，从精益的视角来看，也是一种浪费。</li></ol><p>关于前置时间，有很多种解释，一般建议采用需求前置时间和开发前置时间两个指标进行衡量</p><ul><li><p>需求前置时间：从需求提出（创建任务），到完成开发、测试、上线，最终验收通过的时间周期，考查的是团队整体的交付能力，也是用户核心感知的周期。</p></li><li><p>开发前置时间：从需求开始开发（进入开发中状态），到完成开发、测试、上线，最终验收通过的时间周期，考查的是团队的开发能力和工程能力。</p></li></ul><h3 id="开展-VSM"><a href="#开展-VSM" class="headerlink" title="开展 VSM"></a>开展 VSM</h3><p>如何开展一次成功的 VSM 活动呢？一般来说，有 2 种方式。</p><ol><li><strong>召开一次企业内部价值流程梳理的工作坊或者会议。</strong></li></ol><p>​    选取改进项目对象中某个核心的业务模块，参加会议的人员需要覆盖软件交付的所有环节，包括工具平台提供方。而且，参会人员要尽量是相对资深的，因为他们对自身所负责的业务和上下游都有比较深刻的理解，比较容易识别出问题背后的根本原因。</p><ol start="2"><li><strong>内部人员走访。</strong></li></ol><p>​    通常来说，企业内部的DevOps 转型工作都会有牵头人，甚至会成立转型小组，那么可以由这个小组中的成员对<br>软件交付的各个环节的团队进行走访。这种方式在时间上是比较灵活的，但对走访人的要求比较高，最好是 DevOps 领域的专家，同时是企业内部的老员工，这样可以跟受访人有比较深入坦诚的交流。</p><p>沟通时，要建立一个问题列表，避免东拉西扯。</p><ul><li>在价值交付过程中，你所在团队的主要职责是什么？</li><li>你所在团队的上下游团队有哪些？</li><li>价值在当前环节的处理方式，时长是怎样的？</li><li>有哪些关键系统支持了价值交付工作？</li><li>是否存在等待或其他类型的浪费？</li><li>工作向下游流转后被打回的比例是多少？</li></ul><p>为了方便你更好地理解这些问题，我给你提供一份测试团队的访谈示例。</p><table><thead><tr><th>关键问题</th><th>参考答案</th></tr></thead><tbody><tr><td>在价值交付的过程中，你所在团队的主要职责是什么?</td><td>我们是软件质量的把关人，负责交付软件的功能质量验收工作，避免缺陷流入线上环节。</td></tr><tr><td>你所在团队的上下游团队有哪些?</td><td>我们的上游是开发团队，下游是运维团队，另外还跟项目管理团队和安全团队有关系。</td></tr><tr><td>价值在当前环节的处理方式，时长是怎样的?</td><td>从迭代需求开始，我们就会参与需求评审，并进行测试设计。研发提测后，我们就会按照测试计划和案例对功能进行验收，如果验收通过，就给出测试报告并流转下游，如果存在问题，就提出缺陷。—般来说，平均测试流转周期为2.5天。</td></tr><tr><td>有哪些关键系统支持了价值交付工作?</td><td>包括研发提测系统，测试管理平台，缺陷系统。</td></tr><tr><td>是否存在等待和其他类型的浪费?</td><td>开发提测后一般都需要开发人员在测试环境部署，有时候开发人员不在就要等待，另外每次申请测试环境也需要向环境部门申请，往往几天才能下来。</td></tr><tr><td>工作向下游流转后被打回的比例有多少?</td><td>这个要看缺陷漏测率和线上缺陷逃逸率指标，我们有相关的数据，人概漏测率0.15%。</td></tr></tbody></table><p>通过访谈交流，我们就可以对整个软件交付过程有一个全面的认识，并根据交付中的环节、上下游关系、处理时长、识别出来的等待浪费时长等，按照 VSM 模型图画出当前部门的价值流交付图，以及各个阶段的典型工具，如下图所示：</p><p><img src="/assets/images/ops/devops/image-20200821102924116.png" alt="image-20200821102924116"></p><h3 id="VSM的价值"><a href="#VSM的价值" class="headerlink" title="VSM的价值"></a>VSM的价值</h3><p>实际上，它的价值绝不仅限于输出了一幅价值流交付图而已。VSM 具有非常丰富的价值，包括以下几个方面：</p><ol><li><p><strong>看见全貌。</strong></p><p>如果只关注单点问题，我们会很容易陷入局部优化的怪圈。DevOps 追求的是价值流动效率最大化，也就是说，就算单点能力再强，单点之间的割裂和浪费对于价值交付效率的影响也是超乎想象的。所以，对于流程改进来说，第一步，也是最重要的一步，就是能够看见全貌，这样才能从全局视角找到可优化的瓶颈点，从而提升整体的交付效率。</p><p>另外，<strong>对于全局交付的建模，最终也会体现到软件持续交付流水线的建设上</strong>，因为流水线反映的就是企业客观的交付流程。</p></li><li><p><strong>识别问题。</strong></p><p>VSM 中的几个关键指标，也就是前置时长、增值和不增值时长，以及完成度和准确度，都是可以客观量化改进的指标。当面对这样一幅价值流图的时候，我们很容易就能识别出当前最重要的问题和改进事项。</p></li><li><p><strong>促进沟通。</strong></p><p>在我们开展 VSM 梳理的时候，团队才第一次真正了解上下游团队的职责、工作方式，以及让他们痛苦低效的事情。这时，我们通常会设身处地地想：“只要我们多做一点点，就能大大改善兄弟团队的生存状况了。”实际上，这种<strong>同理心对打破协作的壁垒很有帮助</strong>，可以为改善团队内部文化带来非常正面的影响。实际上，这也是我推荐你用会议或者工作坊的方式推进 VSM 的根本原因。</p></li><li><p><strong>驱动度量。</strong></p><p>在 VSM 访谈的时候，我们要问一个团队的交付周期、准确率等指标问题，如果你发现这个团队支支吾吾，只能给出模糊的回答，这时你就要注意啦，这里本身就大有问题。因为这就表示当前环节的度量指标不够清晰，或者指标过于复杂，团队不清楚关键的结果指标。<br>另外，如果数据的提取需要大量时间，比如需要采用人为统计算数的方式，那么这就体现了这个环节的平台建设能力不足，无法自动化地收集和统计数据，甚至有些关键数据还没有沉淀到数据系统中，只能通过人工本地化的方式进行管理。<br>这些都是 DevOps 转型的过程中需要解决的问题，可以优先处理。可以说，<strong>VSM 是一场团队协作的试炼</strong>。收集 VSM 数据的过程本身，就需要平台间的打通和数据共享，以及自动化的推进，这有助于度量活动的开展。</p></li><li><p><strong>价值展现。</strong></p><p>如何让高层领导明白企业交付效率改善所带来的价值呢？价值流梳理就是一种很好的方式。因为 <strong>VSM 从价值分析而来，到价值优化而去</strong>，本身就是在回答 DevOps 对于企业的价值问题。</p></li></ol><h2 id="DevOps的实施路径"><a href="#DevOps的实施路径" class="headerlink" title="DevOps的实施路径"></a>DevOps的实施路径</h2><p>如果想在企业内部推行一种新的模式，无外乎有两种可行的轨迹：一种是<strong>自底向上</strong>，一种是<strong>自顶向下</strong>。</p><h3 id="自底向上"><a href="#自底向上" class="headerlink" title="自底向上"></a>自底向上</h3><p>在这种模式下，企业内部的 DevOps 引入和实践源自于一个小部门或者小团队，他们可能是 DevOps 的早期倡导者和实践者，为了解决自身团队内部，以及上下游团队交互过程中的问题，开始尝试使用 DevOps 模式。由于团队比较小，而且内部的相关资源调动起来相对简单，所以这种模式比较容易在局部获得效果。</p><p>采用“<strong>羽化原则</strong>”，也就是首先在自己团队内部，以及和自己团队所负责的业务范围有强依赖关系的上下游团队之间建立联系，<strong>一方面不断扩展自己团队的能力范围，另一方面，逐步模糊上下游团队的边界，由点及面地打造 DevOps 共同体</strong>。</p><p>当然，如果想让 DevOps 转型的效果最大化，你一定要想方设法地让<strong>高层知晓局部改进的效果</strong>，让他们认可这样的尝试，最终实现横向扩展，在企业内部逐步铺开。</p><h3 id="自顶向下"><a href="#自顶向下" class="headerlink" title="自顶向下"></a>自顶向下</h3><p>企业高层基于自己对于行业趋势发展的把握和团队现状的了解，以行政命令的方式下达任务目标。在这种模式下，公司领导有足够的意愿来推动 DevOps 转型并投入资源，各个团队也有足够清晰的目标。</p><p>那么，这样是不是就万事大吉了呢？其实不然。在企业内部有这样一种说法：只要有目标，就一定能达成。因为公司领导对于细节的把握很难做到面面俱到，团队为了达成上层目标，总是能想到一些视角或数据来证明目标已经达成，这样的 DevOps 转型说不定对公司业务和团队而言反而是一种伤害。</p><p>无论企业的 DevOps 转型采用哪条轨迹，<strong>寻求管理层的认可和支持都是一个必选项</strong>。如果没有管理层的支持，DevOps 转型之路将困难重重。因为无论在什么时代，变革一直都是一场勇敢者的游戏。对于一家成熟的企业而言，无论是组织架构、团队文化，还是工程能力、协作精神，都是长期沉淀的结果，而不是在一朝一夕间建立的。</p><p>除此之外，转型工作还需要持续的资源投入，这些必须借助企业内部相对比较 high level 的管理层的推动，才能最终达成共识并快速落地。如果你所在的公司恰好有这样一位具备前瞻性视角的高层领导，那么恭喜你，你已经获得了 DevOps 转型道路上至关重要的资源。</p><h3 id="通用路径"><a href="#通用路径" class="headerlink" title="通用路径"></a>通用路径</h3><h4 id="第-1-步：寻找合适的试点项目"><a href="#第-1-步：寻找合适的试点项目" class="headerlink" title="第 1 步：寻找合适的试点项目"></a>第 1 步：寻找合适的试点项目</h4><p>一个合适的项目应该具备以下几个特征：</p><ul><li><strong>贴近核心业务</strong>。DevOps 要以业务价值为导向。对于核心业务，管理层的关注度足够高，各项业务指标也相对比较完善，如果改进效果可以通过核心业务指标来呈现，会更有说服力。同时，核心业务的资源投入会有长期保障。毕竟，你肯定不希望 DevOps 转型落地项目因为业务调整而半途而废吧。</li><li><strong>倾向敏捷业务</strong>。敏捷性质的业务需求量和变更都比较频繁，更加容易验证 DevOps 改造所带来的效果。如果一个业务以稳定为主要诉求，整体处于维护阶段，变更的诉求和意愿都比较低，那么这对于 DevOps 而言，就不是一个好的选择。我之前在跟一家军工企业沟通的时候，了解到他们每年就固定上线两次，那么在这种情况下，你说还有没有必要搞 DevOps 呢？</li><li><strong>改进意愿优先</strong>。如果公司内部的团队心比天高，完全瞧不上 DevOps，觉得自己当前的流程是最完美的，那么，你再跟他们费力强调 DevOps 的价值，结果很可能事倍功半。相反，那些目前绩效一般般的团队都有非常强烈的改进诉求，也更加愿意配合转型工作。这时，团队的精力就可以聚焦于做事本身，而不会浪费在反复拉锯的沟通上。</li></ul><h4 id="第-2-步：寻找团队痛点"><a href="#第-2-步：寻找团队痛点" class="headerlink" title="第 2 步：寻找团队痛点"></a>第 2 步：寻找团队痛点</h4><p>所谓痛点，就是当前最影响团队效率的事情，同时也是改进之后可以产生最大效益的事情。</p><p>可以通过<strong>价值流分析活动</strong>来寻找团队痛点。</p><h4 id="第-3-步：快速建立初期成功"><a href="#第-3-步：快速建立初期成功" class="headerlink" title="第 3 步：快速建立初期成功"></a>第 3 步：快速建立初期成功</h4><p>在进行的转型初期，切记不要把面铺得太广，把战线拉得太长。 <strong>首先识别一个改进点，定义一个目标。</strong>比如，环境申请和准备时间过程，那么就可以定义这样一个指标：优化 50% 的环境准备时长。这样一来，团队的目标会更加明确，方便任务的拆解和细化，可以在几周内见到明显的成果。</p><h4 id="第-4-步：快速展示和持续改进"><a href="#第-4-步：快速展示和持续改进" class="headerlink" title="第 4 步：快速展示和持续改进"></a>第 4 步：快速展示和持续改进</h4><p>取得阶段性的成果之后，要及时向管理层汇报，并且在团队内部进行总结。这样，一方面可以增强管理层和团队的信心，逐步加大资源投入；另一方面，也能够及时发现改进过程中的问题，在团队内部形成持续学习的氛围，激发团队成员的积极性，可以从侧面改善团队的文化。</p><p>在这条路径之下，也隐藏着一些可以预见的问题，最典型的就是DevOps 转型的 J 型曲线，这也是在 2018 年 DevOps 状态报告中的一个重点发现。</p><p><img src="/assets/images/ops/devops/image-20200825110138146.png" alt="image-20200825110138146"></p><p>在转型之初，团队需要快速识别出主要问题，并给出解决方案。在这个阶段，整个团队的效能水平比较低，可以通过一些实践引入和工具的落地，快速提升自动化的能力和水平，从而帮助团队获得初期的成功。</p><p>但是，随着交付能力的提升，质量能力和技术债务的问题开始显现。比如，由于大量的手工回归测试，团队难以压缩测试周期，从而导致交付周期陷入瓶颈；项目架构的问题带来的技术债务导致集成问题增多，耦合性太强导致改动牵一发而动全身……</p><p>这个时候，团队开始面临选择：是继续推进呢？还是停滞不前呢？继续推进意味着团队需要分出额外的精力来加强自动化核心能力的预研和建设，比如优化构建时长、提升自动化测试覆盖率等，这些都需要长期的投入，甚至有可能会导致一段时间内团队交付能力的下降。</p><p>与此同时，与组织的固有流程和边界问题相关的人为因素，也会制约企业效率的进一步提升。如何让团队能够有信心减少评审和审批流程，同样依赖于质量保障体系的建设。如果团队迫于业务压力，暂缓 DevOps 改进工作，那就意味着 DevOps 难以真正落地发挥价值，很多 DevOps 项目就是这样“死”掉的。</p><p>在转型初期，建立一个<strong>专职的转型工作小组</strong>还是很有必要的。这个团队主要由 DevOps 转型关联团队的主要负责人、DevOps 专家和外部咨询顾问等牵头组成，一般是各自领域的专家或者资深成员，相当于 DevOps 实施的“大脑”，主要负责制定 DevOps 转型项目计划、改进目标识别、技术方案设计和流程改造等。</p><p><img src="/assets/images/ops/devops/image-20200825110241851.png" alt="image-20200825110241851"></p><blockquote><p>转型小组的团队组成示意图</p></blockquote><h2 id="业务敏捷"><a href="#业务敏捷" class="headerlink" title="业务敏捷"></a>业务敏捷</h2><p>在现在这个多变的时代，没人能够准确地预测需求的价值。所以，交付能力的提升，可以帮助业务以最小的成本进行试错，将新功能快速交付给用户。同时，用户和市场的情况又能够快速地反馈给业务方，从而帮助业务校准方向。而业务的敏捷能力高低，恰恰体现在对功能的设计和需求的把握上，如果不能灵活地调整需求，专注于最有价值的事情，同样会拖累交付能力，导致整体效率的下降。</p><p>也就是说，在这样一种快速迭代交付的模式下，业务敏捷和交付能力二者缺一不可。</p><p><strong>所以开发更少的功能，聚焦用户价值，持续快速验证，就成了产品需求管理的核心思想。</strong></p><h3 id="开发更少的功能"><a href="#开发更少的功能" class="headerlink" title="开发更少的功能"></a>开发更少的功能</h3><p>在把握需求质量的前提下，如何尽可能地减小需求交付批次，采用最小的实现方案，保证高优先级的需求可以快速交付，从而提升上线实验和反馈的频率，就成了最关键的问题。</p><p>关于需求分析，比较常见的方法就是 <strong>影响地图</strong>。</p><p>影响地图是通过简单的“Why-Who-How-What”分析方法，实现业务目标和产品功能之间的映射关系。</p><ul><li>Why 代表目标，它可以是一个核心的业务目标，也可以是一个实际的用户需求。</li><li>Who 代表影响对象，也就是通过影响谁来实现这个目标。</li><li>How 代表影响，也就是怎样影响用户以实现我们的目标。</li><li>What 代表需要交付什么样的功能，可以带来期望的影响。</li></ul><p>如果你是第一次接触影响地图，可能会听起来有点晕。没关系，我给你举个例子，来帮你理解这套分析方法。</p><p>比如，一个专栏希望可以在上线 3 个月内吸引 1 万名用户，那么，这个 Why，也就是最核心的业务目标。为了达成这个目标，需要影响的角色包含哪些呢？其实就包含了作者、平台提供方、渠道方和最终用户。需要对他们施加哪些影响呢？对作者来说，需要快速地回答用户的问题，提升内容的质量；对平台来说，需要对专栏进行重点曝光，增加营销活动；对渠道方来说，需要提高推广力度和渠道引流；对于用户来说，增加分享有礼、免费试读和个人积分等活动。</p><p>那么基于以上这些影响方式，转化为最终的实际需求，就形成了一张完整的影响地图，如下图所示：</p><p><img src="/assets/images/ops/devops/image-20200826104543898.png" alt="image-20200826104543898"></p><p>需求这么多，优先级要怎么安排呢？别急，现在我就给你介绍一下 “<strong>卡诺模型</strong>“。</p><blockquote><p>卡诺模型（Kano Model），是日本大师授野纪昭博士提出的一套需求分析方法，它对理解用户需求，对其进行分类和排序方面有着很深刻的洞察。</p></blockquote><p>卡诺模型将产品需求划分为五种类型：</p><ol><li><p><strong>兴奋型</strong>：指超乎用户想象的需求，是可遇不可求的功能。比如用户想要一个更好的功能手机，乔布斯带来了 iPhone，这会给用户带来极大的满足感。</p></li><li><p><strong>期望型</strong>：用户的满意度会随着这类需求数量的增多而线性增长，做得越多，效果越好，但难以有质的突破。比如，一个电商平台最开始是卖书，后面逐步扩展到卖电脑、家居用品等多个类别。用户更多的线性需求被满足，满意度自然也会提升。</p></li><li><p><strong>必备型</strong>：这些是产品必须要有的功能，如果没有的话，会带来非常大的影响。不过有这些功能的话，也没人会夸你做得有多好，比如安全机制和风控机制等。</p></li><li><p><strong>无差别型</strong>：做了跟没做一样，这就是典型的无用功。比如你花了好大力气做了一个需求，但是几乎没有用户使用，这个需求就属于无差别型。</p></li><li><p><strong>反向型</strong>：无中生有类需求，实际上根本不具备使用条件，或者用户压根不这么想。这类需求做出来以后，通常会给用户带来很大的困扰，成为被吐槽的对象。</p></li></ol><p>对于五类需求来说，核心要做到 3 点：</p><ul><li><strong>优先规划期望型和必备型需求</strong>，将其纳入日常的交付迭代中，保持一定的交付节奏；识别无差别型和反向型需求，这些对于用户来说并没有产生价值。如果团队对需求的分类有争议，可以进一步开展用户调研和分析。</li><li><strong>追求兴奋型需求</strong>，因为它会带来产品的竞争壁垒和差异化。不过，对于大公司而言，经常会遇到创新者的窘境，也就是坚持固有的商业模式，而很难真正投入资源创新和自我</li><li><strong>颠覆</strong>。这就要采用精益创业的思想，采用 MVP（最小可行产品）的思路，进行快速验证，并且降低试错成本，以抓住新的机遇。</li></ul><h3 id="聚焦用户价值"><a href="#聚焦用户价值" class="headerlink" title="聚焦用户价值"></a>聚焦用户价值</h3><p>而<strong>用户故事则是以用户的价值为核心，圈定一种角色，表明通过什么样的活动，最终达到什么样的价值</strong>。团队在讨论需求的时候，采用一种讲故事的形式，代入到设定的用户场景之中，跟随用户的操作路径，从而达成用户的目标，解决用户的实际问题。这样做的好处在于，经过团队的共同讨论和沟通，产品、研发和测试对需求目标可以达成共识，尤其是对想要带给用户的价值达成共识。</p><p>在这个过程中，团队不断探索更好的实现方案和实现路径，并补充关联的用户故事，从而形成完整的待办事项。更重要的是，团队成员逐渐培养了用户和产品思维，不再拘泥于技术实现本身，增强了彼此之间的信任，积极性方面也会有所改善，从而提升整个团队的敏捷性。用户故事的粒度同样需要进行拆分，拆分的原则是针对一类用户角色，交付一个完整的用户价值，也就是说用户故事不能再继续拆分的粒度。当然，在实际工作中，拆分的粒度还是以迭代周期为参考，在一个迭代周期内交付完成即可，一般建议是 3～5 天。检验用户故事拆分粒度是否合适，可以遵循 <strong>INVEST 原则</strong>。</p><ul><li><p><strong>Independent（独立的）</strong>：减少用户故事之间的依赖，可以让用户故事更加灵活地验证和交付，而避免大批量交付对于业务敏捷性而言至关重要。</p></li><li><p><strong>Negotiable（可协商的）</strong>：用户故事不应该是滴水不漏、行政命令式的，而是要抛出一个场景描述，并在需求沟通阶段不断细化完成。</p></li><li><p><strong>Valuable（有价值的）</strong>：用户故事是以用户价值为核心的，所以每个故事都是在对用户交付价值，所以要站在用户的视角思考问题，避免像最近特别火的那句话一样：“我不要你觉得，我要我觉得。”</p></li><li><p><strong>Estimatable（可评估的）</strong>：用户故事应该可以粗略评估工作量，无论是故事点数还是时间，都可以。如果是一个预研性质的故事，则需要进一步深挖可行性，避免不知道为什么做而做。</p></li><li><p><strong>Small（小的）</strong>：用户故事应该是最小的交付颗粒度，所以按照敏捷开发方式，无论迭代还是看板，都需要在一个交付周期内完成。</p></li><li><p><strong>Testable（可测试的）</strong>：也就是验收条件，如果没有办法证明需求已经完成，也就没有办法进行验收和交付。</p></li></ul><h3 id="持续快速验证"><a href="#持续快速验证" class="headerlink" title="持续快速验证"></a>持续快速验证</h3><p><strong>需求的价值难以预测，但是需求的价值却可以定义。</strong></p><p>需求价值的定义，可以理解为需求价值的度量，分为客观指标和主观 2 个方面。</p><ul><li>客观指标：也就是客观数据能够表明的指标，比如对电商行业来说，可以从购买流程角度，识别商品到达率、详情到达率、加入购物车率、完成订单率等等；</li><li>主观指标：也就是用户体验、用户满意度、用户推荐率等等，无法直接度量，只能通过侧面数据关联得出。</li></ul><p>但是无论是客观指标，还是主观指标，每一个需求在提出的时候，可以在这些指标中选择需求上线后的预期，并定义相关的指标。一方面加强价值导向，让产品交付更有价值的需求，另外一方面，也强调数据导向，尽量客观地展现实际结果。</p><p>从技术层面来说，一个业务需求的背后，一般都会关联一个埋点需求。所谓埋点分析，是网站分析的一种常用的数据采集方法。设计良好的埋点功能，不仅能帮助采集用户操作行为，还能识别完整的上下文操作路径，甚至进行用户画像的聚类和分析，帮助识别不同类型用户的行为习惯。从用户层面来说，众测机制和用户反馈渠道是比较常见的两种方式，核心就是既要听用户怎么说，也要看用户怎么做。</p><p>最后，引入业务的 DevOps，就成了 BizDevOps。 BizDevOps 的核心理念：</p><ul><li>对齐业务和开发目标、指标；</li><li>把握安全、合规指标；</li><li>及时对齐需求，减少无用开发；</li><li>体现 DevOps 的价值；</li><li>让开发团队开始接触业务，不单单是执行，调动积极性。</li></ul><h2 id="精益看板"><a href="#精益看板" class="headerlink" title="精益看板"></a>精益看板</h2><p>如果没有在制品限制的拉动系统，只能说是一个可视化系统，而不是看板系统，这一点非常重要。</p><p>加快价值流动是精益看板的核心。在软件开发中，这个价值可能是一个新功能，也可能是缺陷修复，体验优化。根据利特尔法则，我们知道：平均吞吐率 = 在制品数量 / 平均前置时间。其中，在制品数量就是当前团队并行处理的工作事项的数量。</p><p>在<strong>制品数量会影响前置时间，并行的任务数量越多，前置时间就会越长</strong>，也就是交付周期变长，这显然不是理想的状态。</p><p>不仅如此，前置时间还会影响交付质量，前置时间增长，则质量下降。</p><p><strong>精益看板的实践方法</strong>分为了五个步骤。</p><ul><li>第一步：可视化流程；</li><li>第二步：定义清晰的规则；</li><li>第三步：限制在制品数量；</li><li>第四步：管理工作流程；</li><li>第五步：建立反馈和持续改进。</li></ul><h3 id="可视化流程"><a href="#可视化流程" class="headerlink" title="可视化流程"></a>可视化流程</h3><p>在最开始，我们只需要忠实客观地把这个现有流程呈现出来就可以了，而无需对现有流程进行优化和调整。也正因为如此，看板方法的引入初期给组织带来的冲击相对较小，不会因为剧烈变革引起组织的强烈不适甚至是反弹。所以，看板方法是一种相对温和的渐进式改进方法。</p><p>看板的主要构成元素可以简单概括成“<strong>一列一行</strong>”。</p><p><strong>一列</strong>是指看板的竖向队列，是按照价值流转的各个主要阶段进行划分的，比如常见的需求、开发、测试、发布等。</p><p>竖向队列划分的标准主要有两点：</p><ul><li><strong>是否构成一个独立的环节。</strong>比如对于前后端分离的开发来说，前端开发和后端开发就是两个独立的环节，一般由不同的角色负责，这种就比较适合独立阶段。</li><li><strong>是否存在状态的流转和移交。</strong>看板是驱动上下游协同的信号卡，所以，我们需要重点关注存在上下游交付和评审的环节，这也是提示交付吞吐率和前置时长的关键节点。</li></ul><p>除此之外，看板的设计需要定义明确的起点和终点。对于精益看板来说，覆盖端到端的完整价值交付环节是比较理想的状态。</p><p><img src="/assets/images/ops/devops/image-20200827100321071.png" alt="image-20200827100321071"></p><p><strong>一行</strong>是指看板横向的泳道。泳道用于<strong>需求与需求之间划清界限</strong>，尤其在使用物理看板的时候，经常会因为便利贴贴的位置随意等原因导致混乱，而定义泳道就可以很好地解决这个问题。</p><p><img src="/assets/images/ops/devops/image-20200827100514357.png" alt="image-20200827100514357"></p><h3 id="定义清晰的规则"><a href="#定义清晰的规则" class="headerlink" title="定义清晰的规则"></a>定义清晰的规则</h3><p>沟通的成本甚至要大于工作的成本。而规则可以大大地降低团队成员之间的沟通成本，统一团队的沟通语言，形成团队成员之间的默契。看板的规则包含两个方面，一个是可视化规则，另一个是显式化规则，我分别来介绍一下。</p><ul><li><p>可视化规则。</p><p>看板中的主要构成元素是“一列一行”。实际上，看板中卡片的设计也有讲究，主要有 3 点。</p><ul><li><strong>卡片的颜色</strong>：用于区分不同的任务类型，比如需求（绿色）、缺陷（红色）和改进事项（蓝色）；</li><li><strong>卡片的内容</strong>：用于显示任务的主要信息，比如电子看板 ID 号，需求的名称、描述、负责人、预估工作量和停留时长等；</li><li><strong>卡片的依赖和阻塞状态</strong>：用于提起关注，比如在卡片上通过张贴不同的标志，表示当前卡片的健康程度，对于存在依赖和阻塞状态的卡片，需要团队高优先级协调和处理。这样一来，看板就显得主次分明啦。</li></ul></li><li><p>显式化规则。</p><p>看板除了要让人看得懂，还要让人会操作，这一点非常重要。</p><ul><li>谁来负责整理和移动卡片？</li><li>什么时间点进行卡片操作？</li><li>卡片的操作步骤是怎样的？（比如，卡片每停留一天需要做一次标记。）</li><li>什么时候需要线下沟通？（比如缺陷和阻塞）</li><li>哪些标识代表当前最高优先级的任务？</li><li>看板卡片的填充规则是怎样的？</li><li>谁来保障线下和线上看板的状态一致性？</li></ul></li></ul><h3 id="限制在制品数量"><a href="#限制在制品数量" class="headerlink" title="限制在制品数量"></a>限制在制品数量</h3><p><strong>应用看板方法只能暴露团队的现有问题，而不能解决团队的现有问题。</strong></p><p><strong>看板方法的好处在于，通过降低在制品数量，可以将这些潜在的问题逐步暴露出来。</strong></p><p>限制在制品数量有两个关键节点：一个是需求流入节点，一个是需求交付节点。</p><ul><li><p><strong>需求流入节点</strong></p><p>根据需求的优先级限制并行任务数量。</p></li><li><p><strong>需求交付节点</strong></p><p>关键在于加速需求的流出。</p></li></ul><h3 id="管理工作流程"><a href="#管理工作流程" class="headerlink" title="管理工作流程"></a>管理工作流程</h3><p>需要配套的管理流程，来保障看板机制的顺畅运转。在看板方法中，常见的有三种会议，分别是每日站会、队列填充会议和发布规划会议。</p><ol><li><p><strong>每日站会。</strong></p><p>与 Scrum 方法的“夺命三连问”（昨天做了什么？今天计划做什么？有什么困难或者阻塞？）不同，看板方法更加关注两点：<br><strong>待交付的任务。</strong>看板追求价值的快速流动，所以，对于在交付环节阻塞的任务，你要重点关注是什么原因导致的。<br><strong>紧急、缺陷、阻塞和长期没有更新的任务。</strong>这些任务在规则中也有相应的定义，如果出现了这些问题，团队需要最高优先级进行处理。这里有一个小技巧，就是当卡片放置在看板之中时，每停留一天，卡片的负责人就会手动增加一个小圆点标记，通过这个标记的数量，就可以看出哪些任务已经停留了太长时间。而对于使用电子看板的团队来说，这就更加简单了。比如，Jira 本身就支持停留时长的显示。当然，你也可以自建过滤器，按照停留时长排序，重点关注 Top 问题的情况。</p><p>每日站会要尽量<strong>保持高效</strong>，对于一些存在争议的问题，或者是技术细节的讨论，可以放在会后单独进行</p></li><li><p><strong>队列填充会议。</strong></p><p>队列填充会议的目标有两点：<strong>一个是对任务的优先级进行排序</strong>，<strong>一个是展示需求开发的状态</strong>。一般情况下，队列填充会议需要业务方、技术方和产品项目负责人参与进来，对需求的优先级达成一致，并填充到看板的就绪状态中。</p></li><li><p><strong>发布规划会议</strong>。</p><p>发布规划会议以最终交付为目标。一般情况下，项目的交付节奏会影响队列填充的节奏，二者最好保持同步。另外，随着部署和发布的分离，研发团队越来越趋近于持续开发持续部署，而发布由业务方统一规划把控，发布规划会议有助于研发团队和业务方的信息同步，从而实现按节奏部署和按需发布的理想状态。</p></li></ol><h3 id="建立反馈和持续改进"><a href="#建立反馈和持续改进" class="headerlink" title="建立反馈和持续改进"></a>建立反馈和持续改进</h3><p>实际上，无论是 DevOps 还是精益看板，任何一套方法框架的终点都是持续改进。因为，作为一种新的研发思想和研发方法，只有结合业务实际，并根据自身的情况持续优化规则、节奏、工具和流程，才能更好地为业务服务。</p><p>看板方法的实践是一个循序渐进的过程。为此看板创始人 David J Anderson 总结了看板方法的成熟度模型，用于指导中大型团队实践看板方法，如下图所示：</p><p><img src="/assets/images/ops/devops/KMM-Image.png" alt="img"></p><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>配置管理的四个核心理念： <strong>版本变更标准化，将一切纳入版本控制，全流程可追溯和单一可信数据源。</strong></p><h3 id="1-版本变更标准化"><a href="#1-版本变更标准化" class="headerlink" title="1. 版本变更标准化"></a>1. 版本变更标准化</h3><p>版本控制是配置管理中的一个非常核心的概念，而对于软件来说，最核心的资产就是源代码。</p><p>配置管理中的另一个核心概念是<strong>变更</strong>。我们对软件做的任何改变都可以称之为一次变更，比如一个需求，一行代码，甚至是一个环境配置。<strong>版本来源于变更</strong>。对于变更而言，核心就是要记录：<strong>谁，在什么时间，做了什么改动，具体改了哪些内容，又是谁批准的。</strong></p><p>用好版本控制系统也需要有一套规则和行为规范。比如，版本控制系统需要打通公司的统一认证系统，也就是任何人想要访问版本控制系统，都需要经过公司统一登录的认证。同时，在使用 Git 的时候，你需要正确配置本地信息，尤其是用户名和邮箱信息，这样才能在提交时生成完整的用户信息。另外，系统本身也需要增加相关的校验机制，避免由于员工配置错误导致无效信息被提交入库。</p><p>软件改动说明一般就是版本控制系统的提交记录，一个完整的提交记录应该至少包括以下几个方面的内容：</p><ul><li>提交概要信息：简明扼要地用一句话说明这个改动实现了哪些功能，修复了哪些问题；</li><li>提交详细信息：详细说明改动的细节和改动方式，是否有潜在的风险和遗留问题等；</li><li>提交关联需求：是哪次变更导致的这次提交修改，还需要添加上游系统编号以关联提交和原始变更。</li></ul><p>一套标准化的规则和行为习惯，可以降低协作过程中的沟通成本，一次性把事情做对，这也是标准和规范的重要意义。</p><p><strong>标准化是自动化的前提，自动化又是 DevOps 最核心的实践。</strong></p><h3 id="2-将一切纳入版本控制"><a href="#2-将一切纳入版本控制" class="headerlink" title="2. 将一切纳入版本控制"></a>2. 将一切纳入版本控制</h3><p>软件源代码、配置文件、测试编译脚本、流水线配置、环境配置、数据库变更等等，你能想到的一切，皆有版本皆要被纳入管控。</p><p>这是因为，软件本身就是一个复杂的集合体，任何变更都可能带来问题，所以，全程版本控制赋予了我们全流程追溯的能力，并且可以快速回退到某个时间点的版本状态，这对于定位和修复问题是非常重要的。</p><p><strong>如果这个产物可以通过其他产物来重现，那么就可以作为制品管理，而无需纳入版本控制。</strong>如软件包可以通过源代码和工具重新打包生成，那么，代码、工具和打包环境就需要纳入管控，而生成的软件包可以作为制品。</p><h3 id="3-全流程可追溯"><a href="#3-全流程可追溯" class="headerlink" title="3. 全流程可追溯"></a>3. 全流程可追溯</h3><p>在出现问题时，就要追溯当时的全部数据，像软件源代码、测试报告、运行环境等等。</p><p>对于配置管理来说，除了追溯能力以外，还有一个重要的价值，就是记录关联和依赖关系。</p><h3 id="4-单一可信数据源"><a href="#4-单一可信数据源" class="headerlink" title="4. 单一可信数据源"></a>4. 单一可信数据源</h3><p>对于软件开发来说，必须要有统一的管控：</p><ul><li>对于代码来说，要有统一的版本控制系统，不能代码满天飞；</li><li>对于版本来说，要有统一的渠道，不能让人随便本地打个包就传到线上去了；</li><li>对于开发依赖的组件来说，要有统一的源头，不能让来路不明的组件直接集成到系统中。这不仅对于安全管控来说至关重要，对于企业内部的信息一致性也是不可或缺的。</li></ul><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><p>分支策略就是软件协作模式和发布模式的风向标。</p><h3 id="主干开发，分支发布"><a href="#主干开发，分支发布" class="headerlink" title="主干开发，分支发布"></a>主干开发，分支发布</h3><p>在这种分支策略下，开发团队共享一条主干分支，所有的代码都直接提交到主干分支上，主干分支就相当于是一个代码的全量合集。在软件版本发布之前，会基于主干拉出一条以发布为目的的短分支。</p><p><img src="/assets/images/ops/devops/wiybm_tbd.png" alt="img"></p><p>需要注意的两点：</p><ul><li><p><strong>以发布为目的。</strong>这条分支存在的意义不是开发新功能，而是对现有功能进行验收，并在达到一定的质量标准后对外发布</p></li><li><p><strong>短分支。</strong>这条发布分支一般不会存在太长时间，只要经过回归验证，满足发布标准后，就可以直接对外发布，这时，这条分支的历史使命也就结束了。只要在主干分支和发布分支并行存在的时间段内，所有发布分支上的改动都需要同步回主分支，这也是我们不希望这条分支存在时间过长的原因，因为这会导致重复工作量的线性累计。</p></li></ul><p>优势：</p><ol><li>对于研发团队来说，只有一条主线分支，不需要在多条分支间切换。</li><li>在发布分支拉出之后，主干分支依然处于可集成状态，研发节奏可以保持在一个相对平稳的状态。</li><li>发布分支一般以版本号命名，清晰易懂，线上哪个版本出了问题，就在哪个分支上修复。</li></ol><p>缺点：</p><ol><li><strong>它对主线分支的质量要求很高。</strong>如果主线分支出了问题，就会 block 所有开发团队的工作。对于一个百人团队、每日千次的提交规模来说，如果不对提交加以约束，这种情况的发生频率就会非常高。</li><li><strong>它对团队协作的节奏要求很高。</strong>如果主线分支上的功能没有及时合入，但是业务方又坚持要在指定版本上线这个功能，这就会导致发布分支“难产”。甚至有些时候，会被迫允许部分未开发完成的功能在发布分支上继续开发，这会给发布分支的质量和稳定性造成很大的挑战。</li><li><strong>在主线和发布分支并存期间，有可能会导致两边提交不同步的情况。</strong>比如，发布分支修复了一个线上问题，但是由于没有同步回主线，导致同样的问题在下一个版本中复现。测试出来的问题越多，这种情况出现的概率就越大，更不要说多版本并存的情况了。</li></ol><p>这些问题的解决方法包括以下几点：</p><ol><li>建立提交的准入门禁，不允许不符合质量标准的代码合入主线。</li><li>采用版本火车的方式，加快版本的迭代速度，功能“持票上车”，如果跟不上这个版本就随下个版本上线。另外，可以采用功能开关、热修复等手段，打破版本发布的固定节奏，以一种更加灵活的方式对外发布。</li><li>通过自动化手段扫描主线和发布分支的差异，建立一种规则。比如 Hotfix 必须主线和发布分支同时提交，或者发布分支上线后，由专人反向同步等</li></ol><h3 id="分支开发，主干发布"><a href="#分支开发，主干发布" class="headerlink" title="分支开发，主干发布"></a>分支开发，主干发布</h3><p>当开发接到一个任务后，会基于主干拉出一条特性开发分支，在特性分支上完成功能开发验证之后，通过 Merge request 或者 Pull request 的方式发起合并请求，在评审通过后合入主干，并在主干完成功能的回归测试</p><p><img src="/assets/images/ops/devops/wiybm_slfb.png" alt="img"></p><p>根据特性和团队的实际情况，还可以进一步细分为两种情况：</p><ul><li>每条特性分支以特性编号或需求编号命名，在这条分支上，只完成一个功能的开发；</li><li>以开发模块为单位，拉出一条长线的特性分支，并在这条分支上进行开发协作。</li></ul><p><strong>两者的区别就在于特性分支存活的周期，拉出时间越长，跟主干分支的差异就越大，分支合并回去的冲突也就越大。</strong>所以，对于长线模式来说，要么是模块拆分得比较清晰，不会有其他人动这块功能，要么就是保持同主干的频繁同步。<strong>随着需求拆分粒度的变小，短分支的方式其实更合适。</strong></p><p><strong>优点：</strong></p><ul><li>分支开发相对比较独立，不会因为并行导致互相干扰。同时，特性只有在开发完成并验收通过后才会合入主干，对主干分支的质量起到了保护作用；</li><li>随着特性分支的流行，在这种模式下，分支成了特性天然的载体。一个特性所关联的所有代码可以保存在一条特性分支上，这为以特性为粒度进行发布的模式来说提供了一种新的可能性。也就是说，如果你想要发布哪个特性，就可以直接将特性分支合并到发布分支上，这就让某一个特性变得“可上可下”，而不是混在一大堆代码当中，想拆也拆不出来。</li></ul><p>特性发布虽然看起来很好，但是有三个前置条件：第一个是特性拆分得足够小，第二是有强大的测试环境作支撑，可以满足灵活的特性组合验证需求，第三是要有一套自动化的特性管理工具。</p><p>缺点：</p><ol><li>非常考验团队特性拆分的能力。如果一个特性过大，会导致大量并行开发的分支存在，分支的集成周期拉长，潜在的冲突也会增多。另外，分支长期存在也会造成跟主线差异过大的问题。所以，特性的粒度和分支存活的周期是关键要素。根据经验来看，分支存活的周期一般不要超过一周。</li><li>对特性分支的命名规范要求很高。由于大量特性分支的拉出，整个代码仓库会显得非常乱。面对一大堆分支，谁也说不清到底哪个还活着，哪个已经没用了。所以，如果能够跟变更管理系统打通，自动化创建分支就最好了。</li><li>特性分支的原子性和完整性，保证一个特性的关联改动需要提交到一条分支上，而不是到处都是。同时，特性分支上的提交也需要尽量清晰，典型的就是原子性提交。</li></ol><h3 id="主干开发，主干发布"><a href="#主干开发，主干发布" class="headerlink" title="主干开发，主干发布"></a>主干开发，主干发布</h3><p>团队只有一条分支，开发人员的代码改动都直接集成到这条主干分支上，同时，软件的发布也基于这条主干分支进行。</p><p><img src="/assets/images/ops/devops/wiybm_cd.png" alt="img"></p><p>Facebook 最早采用的也是主干开发、分支发布的策略，每天固定发布两次。但是，随着业务发展的压力增大，团队对于发布频率有了更高的要求，这种分支策略已经无法满足每天多次发布的需求了。于是，他们开始着手改变分支策略，从主干开发、分支发布的模式，演变成了主干开发、主干发布的模式。</p><p>为了保证主干分支的质量，自动化验收手段是必不可少的，因此，每一次代码提交都会触发完整的编译构建、单元测试、代码扫描、自动化测试等过程。在代码合入主干后，会进行按需发布，先是发布到内部环境，也就是只有 Facebook 的员工才能看到这个版本，如果发现问题就立刻修复，如果没有问题，再进一步开放发布给 2% 的线上生产用户，同时自动化检测线上的反馈数据。直到确认一切正常，才会对所有用户开放。</p><p>最后，通过分支策略和发布策略的整合，注入自动化质量验收和线上数据反馈能力，最终将发布频率从固定的每天 2 次，提升到每天多次，甚至实现了按需发布的模式。Facebook最新的分支策略如图所示：</p><p><img src="/assets/images/ops/devops//GIYNPgGn5SctXdIGAAAAAAAkALkybj0JAAAB.jpg" alt="img"></p><p><strong>推荐： 主干开发结合特性分支的模式</strong></p><p>团队共享一条开发主干，特性开发基于主干拉出特性分支，快速开发验收并回归主干，同时，在特性分支和主干分别建立不同的质量门禁和自动化验收能力。</p><p>这样做的好处在于，可以加快代码集成频率，特性相对独立清晰，并且主干分支又可以保持一定的质量水平。不过，在执行的过程中，你需要遵守以下原则：</p><ol><li>团队共享一条主干分支；</li><li>特性分支的存活周期要尽量短，最好不要超过 3 天；</li><li>每天向主干合并一次代码，如果特性分支存在超过 1 天，那么每天都要同步主干代码；</li><li>谨慎使用功能开关等技术手段，保持代码干净和历史清晰；</li><li>并行分支越少越好，如果可能的话，尽量采用主干发布。</li></ol><h2 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h2><p>CI 是 Continuous Integration 的缩写，也就是我们熟悉的持续集成，顾名思义，这里面有两个关键的问题：集成什么东西？为什么要持续？要回答这两个问题，就得从 CI 诞生的历史说起了。</p><p>CI 本身源于肯特·贝克（Kent Beck）在 1996 年提出的极限编程方法（ExtremeProgramming，简称 XP）。顾名思义，极限编程是一种软件开发方法，作为敏捷开发的方法之一，目的在于通过缩短开发周期，提高发布频率来提<br>升软件质量，改善用户需求响应速度。</p><p>关于 CI 的定义，我在这里引用一下马丁·福勒（Martin Fowler）的一篇博客中的内容，这也是当前最为业界公认的定义之一：</p><blockquote><p> CI 是一种软件开发实践，团队成员频繁地将他们的工作成果集成到一起（通常每人每天至少提交一次，这样每天就会有多次集成），并且在每次提交后，自动触发运行一次包含自动化验证集的构建任务，以便尽早地发现集成问题。</p></blockquote><p>践行 CI的三个问题：</p><ol><li><p>每一次代码提交，是否都会触发一次完整的流水线？</p></li><li><p>每次流水线是否会触发自动化的测试环节？</p></li><li><p>如果流水线出现了问题，是否能够在 10 分钟之内修复？</p></li></ol><h3 id="第一阶段：每次提交触发完整的流水线"><a href="#第一阶段：每次提交触发完整的流水线" class="headerlink" title="第一阶段：每次提交触发完整的流水线"></a>第一阶段：每次提交触发完整的流水线</h3><p>第一个阶段的关键词是：<strong>快速集成</strong>。这是对 CI 核心理念的最好诠释，也就是集成速度做到极致，每次变更都会触发 CI。</p><p>如果想做到每次提交都触发持续集成的话，首先就需要打通版本控制系统和持续集成系统</p><p>实施提交触发流水线，还需要一些前置条件。</p><ol><li><p>统一的分支策略。</p><p>​    既然 CI 的目的是集成，那么首先就需要有一条以集成为目的的分支。这条分支可以是研发主线，也可以是专门的集成分支，一旦这条分支上发生任何变更，就会触发相应的 CI 过程。</p></li><li><p>清晰的集成规则。</p><p>​    对于研发特性分支而言，目的主要是快速验证和反馈，那么速度就是不可忽视的因素，所以这个层面的持续集成，主要以验证打包和代码质量为主；而对于系统集成分支而言，它的目的不仅是验证打包和代码质量，还要关注接口和业务层面的正确性，所以集成的步骤会更加复杂，成本也会随之上升。所以，根据分支策略选择合适的集成规则，对于 CI的有效运转来说非常重要。</p></li><li><p>标准化的资源池。</p><p>​    首先，资源池需要实现环境标准化，也就是任何任务在任何节点都具备可运行的能力，这个能力就包括了工具、配置等一系列要素。如果 CI 任务在一个节点可以运行，跑到另外一个节点就运行失败，那么 CI 的公信力就会受到影响。<br>​    另外，资源池的并发吞吐量应该可以满足集中提交的场景，可以动态按需初始化的资源池就成了最佳选择。当然，同时还要兼顾成本因素，因为大量资源的投入如果没有被有效利用，那么造成的浪费是巨大的。</p></li><li><p>足够快的反馈周期。</p><p>​    越是初级 CI，对速度的敏感性就越强。一般来讲，如果 CI 环节超过 10～15 分钟还没有反馈结果，那么研发人员就会失去耐心，所以 CI 的运行速度是一个需要纳入监控的重要指标。对于不同的系统而言，要约定能够容忍的 CI 最大时长，如果超过这个时长，同样会导致 CI 失败。所以，这就需要环境、平台、开发团队共同维护。</p></li></ol><h3 id="第二阶段：每次流水线触发自动化测试"><a href="#第二阶段：每次流水线触发自动化测试" class="headerlink" title="第二阶段：每次流水线触发自动化测试"></a>第二阶段：每次流水线触发自动化测试</h3><p>第二个阶段的关键词是：<strong>质量内建</strong>。实际上，CI 的目的是尽早发现问题，这些问题既包括构建失败，也包括质量不达标，比如测试不通过，或者代码规约静态扫描等不符合标准。</p><ol><li><p>匹配合适的测试活动。</p><p>​    对于不同层级的 CI 而言，同样需要根据集成规则来确定需要注入的质量活动。比如，最初级的提交集成就不适合那些运行过于复杂、时间太长的测试活动，快速的代码检查和冒烟测试就足以证明这个版本已经达到了最基本的要求。而对于系统层的集成来说，质量要求会更高，这样一来，一些接口测试、UI 测试等就可以纳入到 CI 里面来。</p></li><li><p>树立测试结果的公信度。</p><p>​    自动化测试的目标是帮助研发提前发现问题，但是，如果因为自动化测试能力自身的缺陷或者环境不稳定等因素，造成了 CI 的大量失败，那么，这个 CI 对于研发来说就可有可无了。所以，我们要对 CI 失败进行分类分级，重点关注那些异常和误报的情况，并进行相应的持续优化和改善。</p></li><li><p>提升测试活动的有效性。</p><p>考虑到 CI 对于速度的敏感性，那么如何在最短的时间内运行最有效的测试任务，就成了一个关键问题。显然，大而全的测试套件是不合时宜的，只有在基础功能验证的基础上，结合与本次 CI 的变更点相关的测试任务，发现问题的概率才会大大提升。所以，根据 CI 变更，自动识别匹配对应的测试任务也是一个挑战。</p></li></ol><h3 id="第三阶段：出了问题可以在第一时间修复"><a href="#第三阶段：出了问题可以在第一时间修复" class="headerlink" title="第三阶段：出了问题可以在第一时间修复"></a>第三阶段：出了问题可以在第一时间修复</h3><p>利用现有的开源工具和框架快速搭建一套 CI 平台并不困难，<strong>真正让 CI 发挥价值的关键，还是在于团队面对持续集成的态度，以及团队内是否建立了持续集成的文化。</strong></p><p>在CI 的修复时间中，<strong>人不是关键，建立机制才是关键。</strong></p><p>什么是机制呢？<strong>机制就是一种约定，人们愿意遵守这样的行为，并且做了会得到好处。</strong>对于CI 而言，保证集成主线的可用性，其实就是团队成员间的一种约定。这不在于谁出的问题谁去修复，而在于我们是否能够保证 CI 的稳定性，足够清楚问题的降级路径，并且主动关注、分析和推动问题解决。</p><p>另外，团队要建立清晰的规则，比如 10 分钟内没有修复则自动回滚代码，比如当 CI“亮红灯”的时候，团队不再提交新的代码，因为在错误的基础上没有办法验证新的提交，这时需要集体放下手中的工作，共同恢复 CI 的状态。</p><h2 id="自动化测试"><a href="#自动化测试" class="headerlink" title="自动化测试"></a>自动化测试</h2><p>自动化测试要解决什么问题？</p><p>产品交付速度的提升，给测试工作带来了很大的挑战。一方面，测试时间被不断压缩，以前三天的测试工作要在一天内完成。另一方面，需求的变化也给测试工作的开展带来了很大的不确定性。这背后核心的问题是，<strong>业务功能的累加导致测试范围不断扩大，但这跟测试时长的压缩是矛盾的。</strong>说白了，就是要测试的内容越来越多，但是测试的时间却越来越短。</p><p>要想提升测试效率，自然就会联想到自动化手段。</p><p>自动化测试适用于以下几种典型场景：</p><ol><li>有大量机械的重复操作，并且会反复执行的场景，比如批量的回归测试；</li><li>有明确的设计规范且相对稳定的场景，比如接口测试；</li><li>大批量、跨平台的兼容性测试，比如覆盖多种版本和多种机型的测试，几十个机型还可以接受，如果覆盖成百上千个机型，就只能依靠自动化了；</li><li>长时间不间断执行的测试，比如压力测试、可用性测试等。</li></ol><p>自动化测试建设也面临着一些问题:</p><ol><li><p>投入产出比：很多需求基本上只会上线一次（比如促销活动类需求），那么，实现自动化测试的成本要比手动测试高得多，而且以后也不会再用了，这显然有点得不偿失。</p></li><li><p>上手门槛：自动化测试依赖代码方式实现，要开发一套配置化的测试框架和平台，对架构设计和编码能力都有很大的要求。但是，测试人员的编码能力一般相对较弱。</p></li><li><p>维护成本高：无论是测试环境、测试用例还是测试数据，都需要随着需求的变化不断进行调整，否则就很容易因为自动化测试过时，导致执行失败。</p></li><li><p>测试设备投入高：比如，移动 App 的测试需要有大量的手机资源，想要覆盖所有的手机型号、操作系统版本，本身就不太现实。更何况，有限的机器还经常被测试人员拿去做本地调试，这就进一步加剧了线上测试没有可用资源的情况。</p></li></ol><h3 id="自动化测试的设计"><a href="#自动化测试的设计" class="headerlink" title="自动化测试的设计"></a>自动化测试的设计</h3><p>介绍一下经典的测试三角形。这个模型描述了从单元测试、集成测试到 UI测试的渐进式测试过程。越是靠近底层，用例的执行速度就越快，维护成本也越低。而在最上层的 UI 层，执行速度要比单元测试和接口测试要慢，比手工测试要快，相应的维护成本要远高于单元测试和接口测试</p><p><img src="/assets/images/ops/devops/image-20200902103530850.png" alt="image-20200902103530850"></p><p>这样看来，从靠近底层的单元测试入手是一个投入产出相对比较高的选择。但实际上，单元测试的执行情况因公司而异，有的公司能做到 80% 的覆盖率，但有的公司却寸步难行。毕竟，单元测试更多是由开发主导的，开发领导的态度就决定了运行的效果。但不可否认的是，单元测试还是非常必要的，尤其是针对核心服务，比如核心交易模块的覆盖率。当然，好的单元测试需要研发投入大量的精力。</p><p>对于 UI 层来说，执行速度和维护成本走向了另外一个极端，这也并不意味着就没有必要投入 UI 自动化建设。<strong>UI 层是唯一能够模拟用户真实操作场景的端到端测试</strong>，页面上的一个按钮可能触发内部几十个函数调用，和单元测试每次只检查一个函数的逻辑不同，UI 测试更加关注模块集成后的联动逻辑，<strong>是集成测试最有效的手段。</strong></p><p>在实际应用中，UI 自动化可以帮助我们节省人工测试成本，提高功能测试的测试效率。不过，它的缺点也是比较明显的：<strong>随着敏捷迭代的速度越来越快，UI 控件的频繁变更会导致控件定位不稳定，提高了用例脚本的维护成本。</strong></p><p>对于基于 Web 的应用来说，我更推荐椭圆形模型，也就是以中间层的 API接口测试为主，以单元测试和 UI 测试为辅。你可以参考一下分层自动化测试模型图。</p><p><img src="/assets/images/ops/devops/image-20200902104308158.png" alt="image-20200902104308158"></p><h3 id="自动化测试的开发"><a href="#自动化测试的开发" class="headerlink" title="自动化测试的开发"></a>自动化测试的开发</h3><p>有效的自动化测试离不开工具和平台的支持。以接口测试为例，最早都是通过 cURL、Postman、JMeter 等工具单机执行的。但是，一次成功的接口测试，除了能够发起服务请求之外，还需要前置的测试数据准备和后置的测试结果校验。对于企业的实际业务来说，不仅需要单接口的执行，还需要相对复杂的多接口，而且带有逻辑的执行，这就依赖于调用接口的编排能力，甚至是内建的 Mock 服务。</p><p>不仅如此，测试数据、用例、脚本的管理，测试过程中数据的收集、度量、分析和展示，以及测试报告的发送等，都是一个成熟的自动化测试框架应该具备的功能。</p><h3 id="自动化测试结果分析"><a href="#自动化测试结果分析" class="headerlink" title="自动化测试结果分析"></a>自动化测试结果分析</h3><p>那么，我们该如何衡量自动化测试的结果呢？当前比较常用的方式是覆盖率，不过问题是，测试覆盖率提升就能发现更多的缺陷吗？</p><p>在实际项目中，手工测试发现的缺陷数量要比自动化测试发现的缺陷数量多得多。自动化测试更多是在帮助守住软件质量的底线，尤其是应用在回归测试中，自动化测试可以确保工作正常的已有功能不会因为新功能的引入而带来质量回退。可以这么说，<strong>如果自动化测试覆盖率足够高，那么软件质量一定不会差到哪儿去。</strong></p><p>关于测试误报，是指由于非开发代码变更导致的自动化测试用例执行失败的情况。业界对于误报率的普遍定义是：</p><blockquote><p> 自动化测试误报率 = 非开发变更引入的问题用例数量 / 测试失败的用例数量</p></blockquote><p><strong>测试误报率是体现自动化测试稳定性的一个核心指标。</strong>对于不同测试类型和产品形态，误报的的原因有很多。比如测试环境的网络不稳定导致的连接超时、测试脚本和测试工具本身的固有缺陷导致的执行失败、测试数据不齐备、测试资源不可用等等。</p><p>如何解决自动化测试并给出了测试结果，但还是需要人工审查判断之后，才能将真正的问题上报缺陷系统的问题？这就要依赖于自动化测试结果的分析啦。</p><ol><li><p>对自动化测试的问题进行分类。你要弄清楚一次失败是环境问题、网络问题、功能变更，还是系统缺陷？你需要将失败的用例归纳到这些分类之中。当一个类别的问题非常多的时候，你可以考虑进行拆分，比如网络问题，你可以拆分为网络不可达、延迟超时、域名解析错误等等。</p></li><li><p>增加已有分类的自动识别能力。比如，对于捕获到的常见异常，可以根据异常信息自动上报到对应的错误分类，从而简化人工识别和归类错误的工作量。</p></li><li><p>提升自动化测试工具和环境的健壮性，对已知问题增加一定的重试机制。</p></li><li><p>持续积累和丰富错误分类，有针对性地开展改进工作，从而不断提升自动化测试的稳定性。</p></li></ol><h2 id="内建质量"><a href="#内建质量" class="headerlink" title="内建质量"></a>内建质量</h2><p><strong>不应该将质量依赖于检验工作，因为检验工作既昂贵，又不可靠。最重要的是，检验工作并不直接提升产品质量，只是为了证明质量有缺陷。</strong>而正确的做法是将质量内建于整个流程之中，并通过有效的控制手段来证明流程自身的有效性。</p><p>内建质量有两个核心原则：</p><ul><li>问题发现得越早，修复成本就越低；</li><li>质量是每个人的责任，而不是质量团队的责任。</li></ul><h3 id="内建质量的实施思路"><a href="#内建质量的实施思路" class="headerlink" title="内建质量的实施思路"></a>内建质量的实施思路</h3><p><strong>在需求环节，可以定义清晰的需求准入规则</strong>，比如需求的价值衡量指标是否客观、需求的技术可行性是否经过了验证、需求的依赖是否充分评估、需求描述是否清晰、需求拆分是否合理、需求验收条件是否明确等等。</p><p><strong>在开发阶段，代码评审和持续集成就是一个非常好的内建质量的实践。</strong>在代码评审中，要尽量确认编码是否和需求相匹配，业务逻辑是否清晰。另外，通过一系列的自动化检查机制，来验证编码风格、风险、安全漏洞等。</p><p><strong>在测试阶段，可以通过各类自动化测试，以及手工探索测试，覆盖安全、性能、可靠性等，来保障产品质量</strong>；在部署和发布阶段，可以增加数据库监控、危险操作扫描、线上业务监控等多种手段。</p><p><strong>研发环节作为整个软件产品的源头，是内建质量的最佳选择。</strong></p><h3 id="内建质量的实施步骤"><a href="#内建质量的实施步骤" class="headerlink" title="内建质量的实施步骤"></a>内建质量的实施步骤</h3><h4 id="第一步：选择适合的检查类型"><a href="#第一步：选择适合的检查类型" class="headerlink" title="第一步：选择适合的检查类型"></a>第一步：选择适合的检查类型</h4><p><strong>选择投入产出比相对比较高的检查类型，是一种合理的策略。</strong>比如代码风格与缺陷漏洞相比，检查缺陷漏洞显然更加重要，因为一旦发生代码缺陷和漏洞，就会引发线上事故。所以，这么看来，如果是客户端业务，Infer 扫描就可以优先实施起来。虽然我们不能忽视编码风格问题，但这并不是需要第一时间强制执行的。</p><h4 id="第二步：定义指标并达成一致"><a href="#第二步：定义指标并达成一致" class="headerlink" title="第二步：定义指标并达成一致"></a>第二步：定义指标并达成一致</h4><p><strong>指标项是针对检查类型所采纳的具体指标，</strong>比如单元测试覆盖率这个检查项，可采纳的指标就包括行、指令、类、函数等。那么，我们要以哪个为准呢？这个一般需要同研发负责人达成一致，并兼顾行业的一些典型做法，比如单测行覆盖率就是一个比较好的选择。</p><p><strong>参考值的定义是一门艺术。</strong>对于不同的项目，甚至是同一个项目的不同模块来说，我们很难用“一刀切”的方式定义数值。我比较推荐的做法是将静态指标和动态指标结合起来使用。</p><p><strong>静态指标就是固定值</strong>，对于漏洞、安全等问题来说，采取零容忍的态度，只要存在就绝不放过。<strong>而动态指标是以考查增量和趋势为主</strong>，比如基线值是 100，你就可以将参考值定义成小于等于 100，也就是不允许增加。你还可以根据不同的问题等级，定义不同的参考值，比如严格检查致命和阻塞问题，其余的不做限制。</p><p>最后，对于这个指标，你一定要跟研发团队达成共识，也就是说，团队要能够认可并且执行下去。所以，定义指标的时候要充分采纳对方的建议。</p><h4 id="第三步：建立自动化执行和检查能力"><a href="#第三步：建立自动化执行和检查能力" class="headerlink" title="第三步：建立自动化执行和检查能力"></a>第三步：建立自动化执行和检查能力</h4><p><strong>按照快速失败的原则，质量门禁的生效节点要尽量靠近指标数据的产生环节。</strong>比如，如果要检查编码风格，最佳的时间点是在研发本地的 IDE 中进行，其次是在版本控制系统中进行并反馈结果，而不是到了最后发布的时间点再反馈失败。</p><p>现代持续交付流水线平台都具备质量门禁的功能，常见的配置和生效方式有两种：</p><ul><li>在持续交付平台上配置规则，也就是不同指标和参考值组合起来，形成一组规则，并将规则关联到具体的执行任务中。这样做的好处是，各个生成指标数据的子系统只需要将数据提供给持续交付平台就行了，至于门禁是否通过，完全依靠持续交付平台进行判断。另外，一般配置规则的都是质量人员，提供这样一个单独的入口，可以简化配置成本。</li><li>在各个子系统中配置质量门禁。比如，在 UI 自动化测试平台上配置门禁的指标，当持续交付平台调用 UI 自动化测试的时候，直接反馈门禁判断的结果。如果检查不通过，则流水线直接失败。</li></ul><h4 id="第四步：定义问题处理方式"><a href="#第四步：定义问题处理方式" class="headerlink" title="第四步：定义问题处理方式"></a>第四步：定义问题处理方式</h4><p>一般来说，质量门禁都具有强制属性，也就是说，如果没有达到检查指标，就会立即停止并给予反馈。</p><p>在实际执行的过程中，质量门禁的结果可能存在多种选项，比如失败、告警、人工确认等。这些都需要在制定规则的时候定义清楚，通过一定的告警值和人工确认方式，可以对质量进行渐进式管控，以达到持续优化的目标。</p><p>另外，你需要对所有软件交付团队成员宣导质量规则和门禁标准，并明确通知方式、失败的处理方式等。否则，检查出问题却没人处理，这个门禁就形同虚设了。</p><h4 id="第五步：持续优化和改进"><a href="#第五步：持续优化和改进" class="headerlink" title="第五步：持续优化和改进"></a>第五步：持续优化和改进</h4><p>无论是检查能力、指标、参考值，还是处理方式，只有在运行起来后才能知道是否有问题。所以，在推行的初期，也应该具备一定程度的灵活性，比如对指标规则的修订、指标级别和参考值的调整等，<strong>核心目标不是为了通过质量门禁，而是为了质量提升，这才是最重要的。</strong></p><h3 id="内建质量的常见问题"><a href="#内建质量的常见问题" class="headerlink" title="内建质量的常见问题"></a>内建质量的常见问题</h3><table><thead><tr><th>常见问题</th><th>处理建议</th></tr></thead><tbody><tr><td>虽然有质量门禁，但是并没有强制生效。</td><td>分析不强制的原因，选择核心检查项启用强制规则，比如Critical和Blocker级别的问题，必须要解决。</td></tr><tr><td>规则有效性存在争议。</td><td>重新评审规则库，支持规则库自定义或者分级调整。在评审规则库时，核心就是要有务实的态度和开放的心态。务实是对真正对团队有用的规则达成共识，开放是允许团队针对规则提出意见。</td></tr><tr><td>采用人工审批的方式绕过门禁。</td><td>尽量减少让不了解详情的人员进行审批，因为这样做除了出问题一起背锅，并没有什么实质作用。</td></tr><tr><td>质量规则长期不更新。</td><td>建立定期质量规则更新机制，根据实际执行效果不断优化。</td></tr><tr><td>检查时间过长。</td><td>调整扫描频率和检查项内容，优化检查效率。</td></tr><tr><td>检查失败率高。</td><td>优化系统的稳定性。</td></tr><tr><td>质量数据丢失。</td><td>对每一次的执行数据进行归档，保证历史数据可见。</td></tr></tbody></table><h2 id="技术债务"><a href="#技术债务" class="headerlink" title="技术债务"></a>技术债务</h2><p>技术债务，就是指团队在开发过程中，为了实现短期目标选择了一种权宜之计，而非更好的解决方案，所要付出的代价。这个代价就是团队后续维护这套代码的额外工作成本，并且只要是债务就会有利息，债务偿还得越晚，代价也就越高。</p><p>如何对代码的技术债务进行分类呢？我们可以借用“Sonar Code QualityTesting Essentials”一书中的代码“七宗罪”，也就是<strong>复杂性、重复代码、代码规范、注释有效性、测试覆盖度、潜在缺陷和系统架构</strong>七种典型问题。你可以参考一下这七种类型对应的解释和描述：</p><table><thead><tr><th>类型</th><th>影响</th></tr></thead><tbody><tr><td>不能均匀分布的复杂性</td><td>较高的圈复杂度需要更多的测试才能覆盖到全路径，导致潜在的功能质量风险。</td></tr><tr><td>重复代码</td><td>重复代码是最严重的问题，会导致潜在缺陷。另外，重复也会带来维护成本的增加。</td></tr><tr><td>不合适的注释</td><td>代码的注释没有明确标准。缺少关键环节的注释或者是注释难以理解，都会导致代码的可读性变差。</td></tr><tr><td>违反代码规范</td><td>影像团队基于共同的规范进行写作，会增加潜在的风险。</td></tr><tr><td>缺乏单元测试</td><td>单元测试不足会影响团队对代码的信心，增加重构成本，通过测试覆盖率对其进行度量。</td></tr><tr><td>缺陷和潜在的缺陷</td><td>缺陷和潜在缺陷是最直接影响代码质量的要素，要尽可能地发现并修复。</td></tr><tr><td>设计和系统架构</td><td>设计和系统架构受限于当时的资源条件，可能无法满足后续产品的发展需求，所以需要持续演进。</td></tr></tbody></table><p>技术债务最直接的影响就是内部代码质量的高低。如果软件内部质量很差，会带来 3 个方面的影响：</p><ol><li><p>额外的研发成本</p></li><li><p>不稳定的产品质量</p></li><li><p>难以维护的产品</p></li></ol><h3 id="如何量化技术债务？"><a href="#如何量化技术债务？" class="headerlink" title="如何量化技术债务？"></a>如何量化技术债务？</h3><p>软件开发不像是银行贷款，技术债务看不见摸不着，所以，我们需要一套计算方法把这种债务量化出来。目前业界比较常用的开源软件，就是 SonarQube。在 SonarQube 中，技术债是基于 SQALE 方法计算出来的。关于SQALE，全称是 Software QualityAssessment based on Lifecycle Expectations，这是一种开源算法。</p><p>Sonar 通过将不同类型的规则，按照一套标准的算法进行识别和统计，最终汇总成一个时间，也就是说，要解决扫描出来的这些问题，需要花费的时间成本大概是多少，从而对代码质量有一种直观的认识。</p><p>计算出来的技术债务会因为开启的规则数量和种类的不同而不同。</p><p>另外，在 Sonar 中，还有一个更加直观的指标来表示代码质量，这就是 SQALE 级别。SQALE 的级别为 A、B、C、D、E，其中 A 是最高等级，意味着代码质量水平最高。级别的算法完全是基于技术债务比例得来的。简单来说，就是<strong>根据当前代码的行数，计算修复技术债务的时间成本和完全重写这个代码的时间成本的比例。</strong></p><blockquote><p>技术债务比例 = 修复已有技术债务的时间 / 完全重写全部代码的时间</p></blockquote><h3 id="解决方法和原则"><a href="#解决方法和原则" class="headerlink" title="解决方法和原则"></a>解决方法和原则</h3><p>解决技术债务，有哪些步骤呢？</p><ol><li>共识：团队内部要对技术债务的危害、解决项目的目标、规则的选择和制定达成一致意见。</li><li>可见：通过搭建开源的 Sonar 平台，将代码扫描整合进持续交付流水线中，定期或者按需执行，让技术债务变得可视化和可量化。不仅如此，Sonar 平台还能针对识别出来的问题，给出建议的解决方法，这对于团队快速提升编码水平，大有帮助。</li><li>止损：针对核心业务模块，对核心指标类型，比如 vulnerability，缺陷的严重和阻塞问题设定基线，也就是控制整体数量不再增长。</li><li>改善：创建技术优化需求，并在迭代中留出一定的时间修复已有问题，或者采用集中突击的方式搞定大头儿，再持续改进。</li></ol><p>在解决技术债务的过程中，要遵循 4 条原则。</p><ol><li>让技术债务呈良性下降趋势。一种好的趋势意味着一个好的起点，也是团队共同维护技术债务的一种约定。</li><li>优先解决高频修改的问题。技术债务的利息就是引入新功能的额外成本，那么对于高频修改的模块来说，这种成本会快速累积，这也就意味着修复的产出是最大的。至于哪些代码是高频修改的，只要通过分析版本控制系统就可以看出来。</li><li>在新项目中启动试点。如果现有的代码过于庞大，不可能在短时间内完成修复，那么你可以选择控制增长，同时在新项目中试点执行，一方面磨合规则的有效性，另一方面，也能试点质量门禁、IDE 插件集成等自动化流程。</li><li>技术债务无法被消灭，也不要等到太晚。只要还在开发软件项目，技术债务就基本上无法避免，所以不需要一下子把目标定得太高，循序渐进就行了。但同时，技术债务的累积也不是无穷无尽的，等到再也无法维护的时候就太迟了。</li></ol><p>制定规则的建议：</p><p>第一，参考代码质量平台的默认问题级别。一般来说，阻塞和严重的问题的优先级比一般问题更高，这也是基于代码质量平台长时间的专业积累得出的结论。</p><p>第二，你可以参考业界优秀公司的实践经验，比如很多公司都在参考阿里巴巴的 Java 开发手册，京东也有自己的编码规约。</p><p>影响比较大的问题类型，建议你优先进行处理：</p><ul><li>大量重复代码；</li><li>类之间的耦合严重；</li><li>方法过于复杂；</li><li>条件判断嵌套太多；</li><li>缺少必要的异常处理；</li><li>多表关联和缺少索引；</li><li>代码风险和缺陷；</li><li>安全漏洞。</li></ul><h2 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h2><p><strong>环境管理的挑战</strong></p><p>1.环境种类繁多</p><p>2.环境复杂性上升</p><p>3.环境一致性难以保证</p><p>4.环境交付速度慢</p><p>5.环境变更难以追溯</p><p>解决这些问题的方法就是是 基础设施即代码。可以这么说，如果没有采用基础设施即代码的实践，DevOps 一定走不远。</p><p><strong>基础设施即代码</strong></p><p>基础设施即代码就是用一种描述性的语言，通过文本管理环境配置，并且自动化完成环境配置的方式。典型的就是以 CAPS 为代表的自动化环境配置管理工具，也就是 Chef、Ansible、Puppet 和 Saltstacks 四个开源工具的首字母缩写。</p><p>首先， <strong>通过将所有环境的配置过程代码化，每个环境都对应一份配置文件，可以实现公共配置的复用。</strong></p><p>其次，环境的配置过程，完全可以使用工具自动化批量完成。你只需要引用对应环境的配置文件即可，剩下的事情都交给工具。</p><p>最后，既然环境配置变成了代码，自然可以直接纳入版本控制系统中进行管理，享受版本控制的福利。任何环境的配置变更都可以通过类似 Git 命令的方式来实现，不仅收敛了环境配置的入口，还让所有的环境变更都完全可追溯。</p><p>基础设施即代码的实践，通过人人可以读懂的代码将原本复杂的技术简单化，这样一来，即便是团队中不懂运维的角色，也能看懂和修改这个过程。这不仅让团队成员有了一种共同的语言，还大大减少了不同角色之间的依赖，降低了沟通协作成本。这也是基础设施即代码的隐形价值所在，特别符合 DevOps 所倡导的协作原则。</p><p>在大多数公司，部署上线的工作都是由专职的运维团队来负责，开发团队只要将测试通过的软件包提供给运维团队就行了。所以，<strong>开发和运维的自然边界就在于软件包交付的环节，只有打通开发环节的软件集成验收的 CI 流水线和运维环节的应用部署 CD 流水线上线，才能真正实现开发运维的一体化。</strong>而当版本控制系统遇上基础设施即代码，就形成了一种绝妙的组合，那就是 <strong>GitOps</strong>。</p><p><strong>开发运维打通的 GitOps 实践</strong></p><p>顾名思义，GitOps 就是<strong>基于版本控制系统 Git 来实现的一套解决方案</strong>，核心在于基于 Git这样一个统一的数据源，通过类似代码提交过程中的拉取请求的方式，也就是 Pull/Request，来完成应用从开发到运维的交付过程，让开发和运维之间的协作可以基于 Git 来实现。</p><p>虽然 GitOps 最初是基于容器技术和 Kubernetes 平台来实现的，但它的理念并不局限于使用容器技术，实际上，它的核心在于通过代码化的方式来描述应用部署的环境和部署过程。</p><p>在 GitOps 中，<strong>每一个环境对应一个环境配置仓库</strong>，这个仓库中包含了应用部署所需要的一切过程。比如，使用 Kubernetes 的时候，就是应用的一组资源描述文件，比如部署哪个版本，开放哪些端口，部署过程是怎样的。</p><p>GitOps的部署流程图</p><p><img src="/assets/images/ops/devops/image-20200907104436525.png" alt="image-20200907104436525"></p><p>  以测试环境为例的主要流程：</p><ol><li>开发人员提交新的代码改动到 Git 仓库，这会自动触发持续集成流水线。</li><li>经过一系列的构建、测试和检查环节，并最终通过持续集成流水线之后，就会生成一个新版本的应用，并上传到制品库中。</li><li>然后自动针对测试环境的配置仓库创建一个代码合并请求。</li><li>开发或者测试人员可以通过接受合并的方式，将这段环境变更配置合入主干，并再一次自动化地触发部署流水线，将新版本的应用部署到测试环境中。</li></ol><p><strong>GitOps 的好处究竟有哪些呢？</strong></p><ul><li>环境配置的共享和统一管理</li><li>每一次的变更和部署过程也同样由版本控制系统进行记录。</li></ul><p><strong>开发环境的治理实践</strong></p><p>可以采用基础设施即代码的方法，生成一个包含全部工具依赖的Docker 镜像，并分发给开发团队。在开发时仅需要拉起一个容器，将代码目录挂载进去，就可以生成一个完全标准化的研发环境。当工具版本升级时，可以重新制作一个新的镜像，开发本地拉取后，所有的工具就升级完成了，这大大简化了研发环境的维护成本。</p><p>关于如何解决开发本地测试的问题，在 Jenkins 社区也有一些相关的实践。</p><p>比如，你基于 Kubernetes 创建了一套最小测试环境，按照正常过程来说，如果改动一行代码，你需要经过代码提交、打包镜像、上传制品、更新服务器镜像等，才能开始调试。但如果你使用KSync工具，这些过程统统可以省略。KSync 可以帮你建立本地工作空间和远端容器目录的关联，并自动同步代码。也就是说，只要在本地 IDE 里面修改了一行代码，保存之后，KSync 就可以帮你把本地代码传到线上的容器中，对于类似 Python 这样的解释型语言来说特别省事。</p><p>谷歌也开源了一套基于容器开发自动部署工具Skaffold，跟 KSync 类似，使用 Skaffold命令就可以创建一套 Kubernetes 环境。当本地修改一行代码之后，Skaffold 会自动帮你重新生成镜像文件，推送远端，并部署生效，让代码开发变得所见即所得。研发只需要专注于写代码这件事情，其余的全部自动化，这也是未来 DevOps 工程实践的一个发展方向。</p><h2 id="部署管理"><a href="#部署管理" class="headerlink" title="部署管理"></a>部署管理</h2><p><strong>部署</strong>是一组技术实践，表示通过技术手段，将本次开发测试完成的功能实体（比如代码、二进制包、配置文件、数据库等）应用到指定环境的过程，包括开发环境、预发布环境、生产环境等。部署的结果是对服务器进行变更，但是这个变更结果不一定对外可见。</p><p><strong>发布</strong>，也就是 Release，更偏向一种业务实践，也就是将部署完成的功能正式生效，对用户可见和提供服务的程。</p><p>DevOps 模式下，<strong>质量思想</strong>发生了转变。简单概括就是：<strong>要在保障一定的质量水平的前提下，尽量加快发布节奏，并通过低风险发布手段，以及线上测试和监控能力，尽早地发现问题，并以一种最简单的手段来快速恢复。</strong></p><p><strong>一定的质量水平</strong></p><p>对于互联网这种快速迭代的业务来说，大家都习惯了默认会出问题，所以在圈定测试范围和测试覆盖的基础上，只要完成严重问题的修复即可发布，低级别的问题可以在后续的众测和灰度的环节继续处理。</p><p>所以，与定义一个发布质量标准相比，更重要的随着 DevOps 的推广，扭转团队的质量观念。<strong>质量不再是测试团队自身的事情，而是整个交付团队的事情。</strong>如果出现了线上问题，团队要一起来定位和修复，并且反思如何避免类似的问题再次发生，从失败中学习。</p><p><strong>低风险的发布手段</strong></p><p>既然发布是一件不可回避的高风险事情，那么，为了降低发布活动的风险，就需要有一些手段了。典型的包括以下几种：蓝绿部署，灰度发布和暗部署。</p><ol><li>蓝绿部署就是为应用准备两套一模一样的环境，一套是蓝环境，一套是绿环境，每次只有一套环境提供线上服务。这里的蓝和绿，只是用于区分两套环境的标志而已。在新版本上线时，先将新版本的应用部署到没有提供线上服务的环境中，进行上线前验证，验证通过后就达到了准备就绪的状态。在发布时间点，只要将原本指向线上环境的路由切换成另外一套环境，整个发布过程就完成了。</li><li>灰度发布，也叫金丝雀发布。与蓝绿部署相比，灰度发布更加灵活，成本也更低，所以，在企业中是一种更为普遍的低风险发布方式。灰度发布有很多种实现机制，最典型的就是采用一种渐进式的滚动升级来完成整个应用的发布过程。当发布新版本应用时，根据事先设计好的灰度计划，将新应用部署到一定比例的节点上。当用户流量打到这部分节点的时候，就可以使用新的功能了。</li><li>随着 A/B 测试的兴起，暗部署的方式也逐渐流行起来。所谓<strong>暗部署，就是在用户不知道的情况下进行线上验证的一种方法。</strong>比如后端先行的部署方式，把一个包含新功能的接口发布上线，这个时候，由于没有前端导向这个接口，用户并不会真实地调用到这个接口。当用户进行了某些操作后，系统会将用户的流量在后台复制一份并打到新部署的接口上，以验证接口的返回结果和性能是否符合预期。</li></ol><p><strong>线上测试和监控</strong></p><p>如何做线上验证呢？比较常见的，有三种手段。</p><ol><li><p>采用灰度发布、用户众测等方式，逐步观察用户行为并收集用户数据，以验证新版本的可用性是否符合预期。</p><p>在互联网产品中，<strong>埋点是一种最常用的产品分析和数据采集方法</strong>，也是数据驱动决策的主要依据之一。它的价值就在于，根据预先设计的收集和监控数据的方法，采集用户的行为、产品质量、运营数据等多维度的数据。</p></li><li><p>用户反馈。</p><p>除了自动化的采集数据之外，用户主动的反馈也是获取产品信息的第一手资料。而用户反馈的渠道有很多，公司里面一般都有用户运营和舆情监控系统，用于按照“关键字”等自动爬取各个主流渠道的产品信息。一旦发现负面的反馈，就第一时间进行止损。</p></li><li><p>使用线上流量测试。</p><p>最常用的就是将线上真实的用户流量复制下来，以实时或者离线的方式回放到预发布环境中用于功能测试。</p></li></ol><p><strong>快速恢复</strong></p><p>初步对问题进行分析定位后，你可以有两种选择：向前修复和向后回滚。</p><p><strong>向前修复就是快速修改代码并发布一个新版本上线，向后回滚就是将系统部署的应用版本回滚到前一个稳定版本。</strong></p><p>在出现问题系统可以自动修复, 就是故障自愈。故障自愈的第一步，就要做好服务降级和兜底策略。</p><p>服务降级就是指，在流量高峰的时候，将非主路径上的功能进行临时下线，保证业务的可用性。典型的做法就是通过功能开关的方式来手动或自动地屏蔽一些功能。</p><p>兜底策略是指，当极端情况发生时，比如服务不响应、网络连接中断，或者调用服务出现异常的时候，也不会出现崩溃。常见的做法就是缓存和兜底页面，以及前端比较流行的骨架屏等。</p><h2 id="混沌工程"><a href="#混沌工程" class="headerlink" title="混沌工程"></a>混沌工程</h2><p>混沌工程作为软件领域的一门新兴学科，就和它的名字一样，让很多人感到非常“混沌”。</p><p>那么，混沌工程究竟是从何而来，又是要解决什么问题呢？我们先来看看混沌原则网站对混沌工程的定义：</p><blockquote><p>Chaos Engineering is the discipline of experimenting on a distributed system inorder to build confidence in the system’s capability to withstand turbulent conditions in production.</p></blockquote><blockquote><p>混沌工程是一门在分布式系统上进行实验的学科，目的是建立人们对于复杂系统在生产环境中抵御突发事件的信心。</p></blockquote><p>简单来说，混沌工程要解决的，就是复杂环境下的分布式系统的反脆弱问题。那么，我们所要面对的“复杂的分布式”的真实世界是怎样的呢？</p><p>随着微服务、容器化等技术的兴起，业务驱动自组织团队独立发布的频率越来越高，再加上架构的不断更新演进，可以说，几乎没有人能完整地梳理清楚一套系统的服务间调用关系，这就让复杂系统变成了一个“黑洞”。不管外围如何敲敲打打，都很难窥探到核心问题。</p><p>区别于以往的方式，混沌工程采取了一种更加积极的方式，换了一个思路主动出击。那就是，<strong>尽可能在这些故障和缺陷发生之前，通过一系列的实验，在真实环境中验证系统在故障发生时的表现。</strong>根据实验的结果来识别风险问题，并且有针对性地进行系统改造和安全加固，从而提升对于整个系统可用性的信心。</p><p><strong>服务可用性实践</strong></p><p>故障演练就是针对以往发生过的问题进行有针对性地模拟演练。通过事先定义好的演练范围，然后人为模拟事故发生，触发应急响应预案，快速地进行故障定位和服务切换，并观察整个过程的耗时和各项数据指标的表现。</p><p>故障演练针对的大多是可以预见到的问题，比如机器层面的物理机异常关机、断电，设备层面的磁盘空间写满、I/O 变慢，网络层面的网络延迟、DNS 解析异常等。这些问题说起来事无巨细，但基本上都有一条清晰的路径，有明确的触发因素，监控事项和解决方法。</p><p><strong>从业务层面来说，面对多变的环境因素，完善的服务降级预案和系统兜底机制也是必不可少的</strong>。在业务压力比较大的时候，可以适当地屏蔽一些对用户感知不大的服务，比如推荐、辅助工具、日志打印、状态提示等，保证最核心流程的可用性。另外，适当地<strong>引入排队机制</strong>也能在一定程度上分散瞬时压力。</p><p><strong>必须要强调的是，在引入混沌工程的实践之前，首先需要确保现有的服务已经具备了弹性模式，并且能够在应急响应预案和自动化工具的支撑下尽早解决可能出现的问题。</strong></p><h3 id="混沌工程的原则"><a href="#混沌工程的原则" class="headerlink" title="混沌工程的原则"></a>混沌工程的原则</h3><p>混沌工程的五大原则：建立稳定状态的假设、真实世界的事件、在生产中试验、持续的自动化实验、最小影响范围。</p><p><strong>建立稳定状态的假设</strong></p><p>关于系统的稳定状态，就是说，有哪些指标可以证明当前系统是正常的、健康的。实际上，无论是技术指标，还是业务指标，现有的监控系统都已经足够强大了，稍微有一点抖动，都能在第一时间发现这些问题。</p><table><thead><tr><th>指标类型</th><th>指标示例</th></tr></thead><tbody><tr><td>业务核心指标</td><td>用户数、活跃用户数、新增用户数、订单量、GMV、平均客单价、转化率、订单成功率、订单取消率、订单退货率、商品和商家数量</td></tr><tr><td>业务访问指标</td><td>UV、PV、点击率、首页到达率、商品到达率、评论到达率</td></tr><tr><td>用户体验指标</td><td>用户满意度、用户投诉数量、用户反馈数量、订单好评率、订单差评率</td></tr><tr><td>系统指标</td><td>QPS、TPS、CPU使用率、CPU负载、内存使用率、网络连接数、平均响应时长、404数量</td></tr></tbody></table><p><strong>真实世界的事件</strong></p><p>真实世界的很多问题都来源于过往踩过的“坑”，即便是特别不起眼的事件，都会带来严重的后果。</p><p>我们无法模拟所有的异常事情，<strong>投入产出比最高的就是选择重要指标</strong>（比如设备可用性、网络延迟，以及各类服务器问题），进行有针对性地实验。另外，可以结合类似全链路压测等手段，从全局视角测试系统整体运作的可用性，通过和稳定状态的假设指标进行对比，来识别潜在的问题。</p><p><strong>在生产中实验</strong></p><p><strong>真实世界的问题，只有在生产环境中才会出现。</strong>一个小规模的预发布环境更多的是验证系统行为和功能符合产品设计，也就是从功能的角度出发，来验证有没有新增缺陷和质量回退。<br>但是，系统的行为会根据真实的流量和用户的行为而改变。比如，流量明星的一则消息就可能导致微博的系统崩溃，这是在测试环境很难复现的场景。</p><p>但客观来说，在生产环境中进行实验，的确存在风险，这就要求实验范围可控，并且具备随时停止实验的能力。还是最开始的那个原则，如果系统没有为弹性模式做好准备，那么就不要开启生产实验。</p><p>还以压测为例，我们可以随机选择部分业务模块，并圈定部分实验节点，然后开启常态化压测。通过定期将线上流量打到被测业务上，观察突发流量下的指标表现，以及是否会引发系统雪崩，断路器是否生效等，<strong>往往在没有准备的时候才能发现真实问题。这种手段作为混沌工程的一种实践</strong>，已经普遍应用到大型公司的在线系统之中了。</p><p><strong>持续的自动化实验</strong></p><p><strong>自动化是所有重复性活动的最佳解决方案。</strong>通过自动化的实验和自动化结果分析，我们可以保证混沌工程的诸多实践可以低成本、自动化地执行。正因为如此，以混沌工程为名的工具越来越多。</p><p>比如，商业化的混沌工程平台 Gremlins 就可以支持不可用依赖、网络不可达、突发流量等场景。阿里也开源了他们的混沌工具ChaosBlade，缩短了构建混沌工程的路径，引入了更多的实践场景。另外，开源的Resilience4j和 Hystrix也都是非常好用的工具。无论是自研，还是直接采用，都可以帮助你快速上手。</p><p><strong>最小的影响范围</strong></p><p>混沌工程实践的原则就是不要干扰真实用户的使用，所以，在一开始将实验控制在一个较小的范围内，是非常有必要的，这样可以避免由于实验失控带来的更大问题。</p><h2 id="度量"><a href="#度量" class="headerlink" title="度量"></a>度量</h2><p>度量不是目的，而是手段，也就是说度量的目标是“做正确的事”，而度量的手段是“正确地做事”。</p><h3 id="如何定义指标？"><a href="#如何定义指标？" class="headerlink" title="如何定义指标？"></a>如何定义指标？</h3><p>好的指标大多具备一些典型的特征。</p><ol><li><p>明确受众。</p><p>指标不能脱离受众而单独存在，在定义指标的同时，要定义它所关联的对象，也就是这个指标是给谁看。</p></li><li><p>直指问题。</p><p>一看到这个指标，就能意识到问题所在，并自然而然地进行改进，而不是看了跟没看见一样，也不知道具体要做什么。</p></li><li><p>量化趋势。</p><p>按照 SMART 原则，好的指标应该是可以衡量的，而且是可以通过客观数据来自证的。</p></li><li><p>充满张力。</p><p>指标不应该孤立存在，而是应该相互关联构成一个整体。好的指标应该具有一定的张力，向上可以归并到业务结果，向下可以层层分解到具体细节。这样通过不同维度的数据抽取，可以满足不同视角的用户需求。</p></li></ol><h3 id="定义指标有哪些原则？"><a href="#定义指标有哪些原则？" class="headerlink" title="定义指标有哪些原则？"></a>定义指标有哪些原则？</h3><ol><li>全局指标优于局部指标：过度的局部优化可能对整体产出并无意义，从而偏离了度量的核心，也就是提升交付速度和交付质量。</li><li>综合指标优于单一指标：从单一维度入手会陷入只见树木不见森林的困境，综合指标更加客观。所以，要解决一个问题，就需要一组指标来客观指引。</li><li>结果指标优于过程指标：首先要有结果指标，以结果为导向，以过程为途径，一切过程指标都应该归结到结果指标。</li><li>团队指标优于个人指标：优先考核团队指标而非个人指标，团队共享指标有助于形成内部合力，减少内部的割裂。</li><li>灵活指标优于固化指标：指标的设立是为了有针对性地实施改进，需要考虑业务自身的差异性和改进方向，而非简单粗暴的“一刀切”，并且随着团队能力的上升，指标也需要适当的调整，从而不断挑战团队的能力。</li></ol><h3 id="哪些指标最重要？"><a href="#哪些指标最重要？" class="headerlink" title="哪些指标最重要？"></a>哪些指标最重要？</h3><ol><li><p>交付效率</p><p><strong>需求前置时间：</strong>从需求提出到完成整个研发交付过程，并最终上线发布的时间。对业务方和用户来说，这个时间是最能客观反映团队交付速度的指标。这个指标还可以进一步细分为需求侧，也就是从需求提出、分析、设计、评审到就绪的时长，以及业务侧，也就是研发排期、开发、测试、验收、发布的时长。对于价值流分析来说，这就代表了完整的价值流时长。<br><strong>开发前置时间：</strong>从需求进入排期、研发真正动工的时间点开始，一直到最终上线发布的时长。它体现的是研发团队的交付能力，也就是一个需求进来后，要花多久才能完成整个开发过程。</p></li><li><p>交付能力</p><p><strong>发布频率：</strong>单位时间内的系统发布次数。原则上发布频率越高，代表交付能力越强。这依赖于架构结构和团队自治、独立发布的能力。每个团队都可以按照自己的节奏安全地发布，而不依赖于关联系统和发布窗口期的约束。<br><strong>发布前置时间：</strong>指研发提交一行代码到最终上线发布的时间，是团队持续交付工程能力的最直观的考查指标，依赖于全流程自动化的流水线能力和自动化测试能力。这也是DevOps 状态报告中的核心指标之一。<br><strong>交付吞吐量：</strong>单位时间内交付的需求点数。也就是，单位时间内交付的需求个数乘以需求颗粒度，换算出来的点数，它可以体现出标准需求颗粒度下的团队交付能力。</p></li><li><p>交付质量</p><p><strong>线上缺陷密度：</strong>单位时间内需求缺陷比例，也就是平均每个需求所产生的缺陷数量，缺陷越多，说明需求交付质量越差。<br><strong>线上缺陷分布：</strong>所有缺陷中的严重致命等级缺陷所占的比例。这个比例的数值越高，说明缺陷等级越严重，体现了质量的整体可控性。<br><strong>故障修复时长：</strong>从有效缺陷提出到修复完成并上线发布的时间。一方面，这个指标考查了故障定位和修复的时间，另外一方面，也考查了发布前置时间，只有更快地完成发布上线过程，才能更快地修复问题。</p></li></ol><h3 id="如何开启度量工作？"><a href="#如何开启度量工作？" class="headerlink" title="如何开启度量工作？"></a>如何开启度量工作？</h3><p>在企业内部开启度量工作，可以分为四个步骤。</p><h4 id="第-1-步：细化指标。"><a href="#第-1-步：细化指标。" class="headerlink" title="第 1 步：细化指标。"></a>第 1 步：细化指标。</h4><p>一个完整的指标，除了定义之外，还需要明确指标名、指标描述、指标级别（团队级 / 组织级）、指标类型、适用场景范围及目标用户、数据采集方式和标准参考值。</p><p>以交付指标为例，我汇总了一份细化后的指标内容，你可以参考下表。其实不仅仅是核心结果指标，只要是在度量体系内定义的指标，都需要进行细化。</p><p><img src="/assets/images/ops/devops/image-20200908113702895.png" alt="image-20200908113702895"></p><h4 id="第-2-步：收集度量数据"><a href="#第-2-步：收集度量数据" class="headerlink" title="第 2 步：收集度量数据"></a>第 2 步：收集度量数据</h4><p>度量指标需要客观数据的支撑，而数据往往都来源于各个不同的平台。所以，在定义指标的时候，你需要评估是否有足够的客观数据来支撑这个指标的衡量。</p><p>需要从流程和平台两个层面入手解决。比如，一方面，从流程层面制定研发操作规范，让每一名研发人员都清楚在什么时间点需要改变需求卡片状态；另一方面，建设平台能力，提供易用性的方式辅助研发，甚至自动流转需求状态。</p><h4 id="第-3-步：建立可视化平台。"><a href="#第-3-步：建立可视化平台。" class="headerlink" title="第 3 步：建立可视化平台。"></a>第 3 步：建立可视化平台。</h4><p>度量指标毕竟是要给人看的，度量数据也需要有一个地方可以收集和运算，这就依赖于度量可视化平台的建设了。</p><h4 id="第-4-步：识别瓶颈并持续改进。"><a href="#第-4-步：识别瓶颈并持续改进。" class="headerlink" title="第 4 步：识别瓶颈并持续改进。"></a>第 4 步：识别瓶颈并持续改进。</h4><p>当数据做到了可信和可视化之后，团队面临的问题和瓶颈会自然而然浮现出来。</p><h2 id="持续改进"><a href="#持续改进" class="headerlink" title="持续改进"></a>持续改进</h2><p>DevOps 做到什么程度，就算是实现转型落地了？那么，我的回答是，<strong>核心就是团队已经具备了持续改进的能力，而不只是简简单单地引入了几个工具，建立了几个度量指标而已</strong></p><p>持续改进的意义到底是什么呢？为什么一切活动的终极目标都是持续改进呢？</p><p>这是因为，每家公司面临的问题都不一样，从 0 到 1 的过程相对比较简单，可以对照着工程实践，快速地引入工具，建立流程，补齐能力短板。但是，从 1 到 N 的过程，就需要团队根据业务需要，自行识别改进目标了。</p><p>谈到持续改进，有一个非常著名的方法体系，叫作 PDCA，也称为<strong>戴明环</strong>。没错，你从名称就能看出，这套方法体系同样来自于质量管理大师戴明博士。PDCA 是四个英文单词的缩写，也就是 <strong>Plan（计划）、Do（实施）、Check（检查）和 Action（行动）</strong>。</p><p>PDCA 提供了一套结构化的实施框架，任何一项改进类工作，都可以划分为这四个实施阶段。<strong>通过 PDCA 循环的不断迭代，驱动组织进入一种良性循环，不断识别出新的待改进问题。</strong>针对这些问题，首先要进行根因分析，制定具体的实施计划。然后，不定期地检查实施的结果和预期目标是否一致。最后，要对改进结果进行复盘，把做得好的地方保留下来，把做得不好的地方纳入下一阶段的循环中，继续改进。</p><p><strong>构建持续改进的核心，就在于构建一个学习型组织。</strong></p><h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><h4 id="鼓励正向回溯和总结"><a href="#鼓励正向回溯和总结" class="headerlink" title="鼓励正向回溯和总结"></a>鼓励正向回溯和总结</h4><p>从失败中学习是我们从小就懂的道理。一个团队对待故障的态度，很大程度上就反映了他们对于持续改进的态度。系统出现故障是谁都不愿意遇到的事情，但在真实世界中，这是没法避免的。</p><p>故障回溯并不一定以确定责任为第一要务，<strong>更重要的是，要识别系统流程中的潜在问题和漏洞，并通过后续机制来进行保障</strong>，比如增加测试用例、增加产品走查事项等等。</p><h4 id="预留固定时间进行改进"><a href="#预留固定时间进行改进" class="headerlink" title="预留固定时间进行改进"></a>预留固定时间进行改进</h4><p>在团队的日常迭代中，事先给改进类工作预留一部分时间，或者是在业务相对不那么繁忙的时候（比如大促刚刚结束，团队在调整状态的时候），在改进工作上多花些时间。</p><p>这些工作量主要用于解决非功能需求、技术改进类问题，比如修复技术债务、单元测试用例补充、度量识别出来的改进事项等。通过将这部分改进时间固定下来，可以培养团队持续改进的文化。</p><p>我比较推荐的做法是，在团队的 Backlog 中新增一类任务，专门用于记录和跟踪这类持续改进的内容。在迭代计划会议上，对这类问题进行分析，并预估工作量，保证团队有固定的时间来应对这些问题。</p><h4 id="在团队内部共享业务指标"><a href="#在团队内部共享业务指标" class="headerlink" title="在团队内部共享业务指标"></a>在团队内部共享业务指标</h4><p>对于业务的指标和表现，需要尽可能地在团队内部做到透明，让团队成员可以接触真实世界的用户反馈和评价，以及业务的度量信息。</p><p>在一个新功能开发完成上线之后，要能实时查看这个需求的上线状态。如果需求分析时已经关联了业务考核指标，那么，同样可以将该业务关联的指标数据进行展示。这样，研发就会知道自己交付的内容有多少问题，用户的真实反馈是怎样的，从而促使团队更多地站在用户的视角思考问题。</p><p>除了业务指标，DevOps 的指标体系也应该对内部公开透明。大家可以查看自己所在团队的表现，以及在公司内部的整体水平。</p><h4 id="激励创造性，并将价值最大化"><a href="#激励创造性，并将价值最大化" class="headerlink" title="激励创造性，并将价值最大化"></a>激励创造性，并将价值最大化</h4><p>在团队成员的绩效目标中，增加对团队贡献和技术创新的要求，在团队内部鼓励创新类工作。另外，在团队内部建立对应的选拔和激励机制，为好的想法投入资源，把它们变成可以解决类似问题的工具。</p><p>很多公司也开始注意到这种内部知识复用的重要性，所以，无论是代码库开源，还是公共基础组件的市的建设，甚至是公司级的平台治理系统，都可以帮助你快速地复用已有的能力，避免一直重复造轮子。</p><h2 id="DevOps-平台"><a href="#DevOps-平台" class="headerlink" title="DevOps 平台"></a>DevOps 平台</h2><p>企业DevOps平台建设的三个阶段</p><h3 id="阶段一：从无到有"><a href="#阶段一：从无到有" class="headerlink" title="阶段一：从无到有"></a>阶段一：从无到有</h3><p>在这个阶段，企业的 DevOps 平台建设处于刚刚起步的状态，在整个交付过程中，还有大量的本地操作和重复性的操作。<br>另外，企业内部一般也没有一个成体系的工具团队，来专门负责平台能力建设。那么，对于这个阶段，我给你的建议是：<strong>引入开源工具和商业工具，快速补齐现有的能力短板。</strong></p><p>所谓能力短板，其实就是当前交付工具链体系中缺失的部分，尤其是高频操作，或者是涉及多人协作的部分，比如，需求管理、持续集成等。</p><p>如何选择工具？</p><p>选择工具的核心原则就是<strong>选择主流工具</strong></p><ul><li>需求管理工具 Jira；</li><li>知识管理工具 Confluence；</li><li>版本控制系统 GitLab；</li><li>持续集成工具 Jenkins；</li><li>代码质量工具 SonarQube；</li><li>构建工具 Maven/Gradle；</li><li>制品管理 Artifactory/Harbor；</li><li>配置管理工具 Ansible；</li><li>配置中心 Apollo；</li><li>测试工具 RF/Selenium/Appium/Jmeter/TestNG；</li><li>安全合规工具 BlackDuck/Fortify；<br>……</li></ul><p>为什么商业工具也是可选项？</p><p>商业工具的优势一直都存在，比如，专业性、安全性、扩展性、技术支持力度等。其实，很多开源工具都有商业版本。</p><p>选择商业工具的理由有很多，不选的理由大多就是一个字：贵。针对这个问题，我要说的是，要分清一笔支出到底是成本，还是投资。</p><p>就跟购买黄金一样，虽然也花了钱，但这是一笔投资，未来可以保值和增值，甚至是变现。对于商业工具来说，也是同样的道理。如果一款商业工具可以大幅提升团队效率，最后的产出可能远超最开始的投资。如果我们组建一个团队，仿照商业工具，开发一套自研工具，重复造轮子的成本也可能一点不少。所以，重点就是要看怎么算这笔账。</p><h3 id="阶段二：从小到大"><a href="#阶段二：从小到大" class="headerlink" title="阶段二：从小到大"></a>阶段二：从小到大</h3><p>经过了第一个阶段，企业交付链路上的工具基本都已经齐全了。团队对于工具的需求开始从够用到好用进行转变。另外，随着业务发展，团队扩大，差异化需求也成了摆在面前的问题。再加上，人和数据都越来越多，工具的重要性与日俱增。</p><p>那么，工具的稳定性、可靠性，以及大规模使用的性能问题，也开始凸显出来。对于这个阶段，我给你的建议是：使用半自建工具和定制商业工具，来解决自己的问题。</p><p>所谓半自建工具，大多数情况下，还是基于开源工具的二次开发，或者是对开源工具进行一次封装，在开源工具上面实现需要的业务逻辑和交互界面。</p><p>那么，半自建工具有哪些注意事项呢？虽然各个领域的工具职能千差万别，但从我的经验来看，主要有两点：设计时给扩展留出空间；实现时关注元数据治理。</p><h3 id="阶段三：从繁到简"><a href="#阶段三：从繁到简" class="headerlink" title="阶段三：从繁到简"></a>阶段三：从繁到简</h3><p>到了第三个阶段，恭喜你已经在 DevOps 平台建设方面有了一定的积累，在各个垂直领域也积累了成功案例。那么，在这个阶段，我们要解决的主要问题有 3 点：</p><ul><li><p>平台太多。做一件事情，需要各种切来切去；</p></li><li><p>平台太复杂。想要实现一个功能，需要对相关人员进行专业培训，他们才能做对；</p></li><li><p>平台价值说不清。比如，使用平台，能带来多大价值？能给团队和业务带来多大贡献？</p></li></ul><p>对于这个阶段，我给你的建议是：<strong>使用整合工具来化繁为简，统一界面，简化操作，有效度量。</strong></p><p>整合工具，就是包含了开源工具、半自研工具、商业工具的集合。</p><p>你要提供的不再是一个工具，而是一整套的解决方案；不是解决一个问题，而是解决交付过程中方方面面的问题。</p><p><strong>企业工具平台治理</strong></p><p>如果最开始没有一个顶层规划，到了这个时候，企业内部大大小小的工具平台应该有很多。你需要做的第一步，就是<strong>平台化治理工作</strong>。</p><p>第一条建议是比较温和可行的，那就是，找到<strong>软件交付的主路径</strong>。用一个平台覆盖这条主路径，从而串联各个单点上的能力，让一些真正好的平台能够脱颖而出。而要做到这个事情，就需要持续交付流水线了。</p><p><strong>打造自服务的工具平台</strong></p><p>到了这个阶段，自服务就成了平台建设的核心理念。</p><p>所谓自服务，就是用户可以自行登录平台实现自己的操作，查看自己关心的数据，获取有效的信息。</p><p>而想要实现自服务，简化操作是必经之路。说白了，如果一件事情只要一键就能完成，这才是真正地实现了自服务。</p><p>这么说可能有点夸张。但是，打破职能间的壁垒，实现跨职能的赋能，依靠的就是平台的自<br>服务能力。很多时候，当你在埋怨“平台设计得这么简单，为啥还是有人不会用”的时候，<br>其实这只能说明一个问题，就是平台依然不够简单。</p><p><strong>指导平台建设的核心理念</strong></p><ul><li>标准化：一切皆有规则，一切皆有标准；</li><li>自动化：干掉一切不必要的手工操作环节，能一键完成的，绝不操作两次；</li><li>服务化：面向用户设计，而不是面向专家设计，让每个人都能在没有外界依赖的前提下，完成自己的工作；</li><li>数据化：对数据进行收集、汇总、分析和展示，让客观数据呈现出来，让数据指导持续改进。</li></ul><h2 id="DevOps产品设计"><a href="#DevOps产品设计" class="headerlink" title="DevOps产品设计"></a>DevOps产品设计</h2><p>DevOps 产品设计体验的五个层次：战略存在层、能力圈层、资源结构层、角色框架层和感知层。</p><h3 id="第一个层次：战略存在层"><a href="#第一个层次：战略存在层" class="headerlink" title="第一个层次：战略存在层"></a>第一个层次：战略存在层</h3><p>希望用户通过这个产品得到什么？显然，目标用户和痛点问题的不同，会从根本上导致两套 DevOps 产品之间相距甚远。</p><p>DevOps 产品的战略定位：<strong>效率，质量，成本和安全。</strong>归根结底,产品的任何功能都是要为战略服务的.</p><p><strong>明确目标用户，定义刚性需求，服务于典型场景，并最终在某一个点上突出重围，这就是我们在准备做 DevOps 产品的时候首先要想清楚的问题。</strong></p><h3 id="第二个层次：能力圈层"><a href="#第二个层次：能力圈层" class="headerlink" title="第二个层次：能力圈层"></a>第二个层次：能力圈层</h3><p>战略很好，但是不能当饭吃。为了实现战略目标，我们需要做点什么，这就是需要产品化的能力。所谓产品化，就是将一个战略或者想法通过产品分析、设计、实验并最终落地的过程。</p><p>明确哪些是自己产品的核心竞争力，而哪些是我们的边界和底线，现阶段是不会去触碰的。当我们用这样一个圈子把自己框起来的时候，至少在短期内，目标是可以聚焦的。</p><p>当然，随着产品的价值体现，资源会随之而扩充，这个时候，我们就可以调整、扩大自己的能力圈。但说到底，这些能力都是为了实现产品战略而存在的，这一点永远不要忘记。</p><p>所谓<strong>主航道，就是产品的核心能力，直接反射了产品战略的具体落地方式。</strong>对于流水线产品来说，这个能力来源于对软件交付过程的覆盖，而不论你将来开发任何产品，这条主路径都是无法回避的。那么，产品就有了茁壮成长的环境和土壤。而<strong>护城河就是你这个产品的不可替代性，或者是为了替代你的产品需要付出的高额代价。</strong></p><h3 id="第三个层次：资源结构层"><a href="#第三个层次：资源结构层" class="headerlink" title="第三个层次：资源结构层"></a>第三个层次：资源结构层</h3><p>资源这个事儿吧，就像刚才提到的，永远是稀缺的，但这对于所有人来说都是公平的。所以，<strong>对资源的整合和调动能力就成了核心竞争力。</strong></p><p>产品蕴含的资源除了这些看得见、摸得着的机器以外，还有很多方面，比如，硬实力方面的，像速度快、机器多、单一领域技术沉淀丰富，又比如，强制性的，像审批入口、安全规则，还有软性的用户习惯，数据积累等等。</p><p>对于内部 DevOps 产品来说，还有一项资源是至关重要的，那就是<strong>领导支持</strong>。</p><h3 id="第四个层次：角色框架层"><a href="#第四个层次：角色框架层" class="headerlink" title="第四个层次：角色框架层"></a>第四个层次：角色框架层</h3><p>要站在用户的角度来看待问题，要在他们当时的场景下，去解决他们的问题，而不是远远地观望着，甚至以上帝视角俯视全局。</p><p><strong>不要让你的产品只有专业人士才会使用。</strong></p><p><strong>产品应该提供抽象能力屏蔽很多细节，而不是暴露很多细节，甚至，好的产品自身就是使用说明书。</strong>这一点，在注意力变得格外稀缺的现在，重要性不可忽视。</p><h3 id="第五个层次：感知层"><a href="#第五个层次：感知层" class="headerlink" title="第五个层次：感知层"></a>第五个层次：感知层</h3><p>让不专业的人做专业的事情，结果可想而知，好多产品功能的设计都堪称是“反人类”的。</p><p>关于这个层次，我提供两点建议：</p><ul><li>多跟前端工程师交流。现在的前端框架已经非常成熟了，基于模板，我们可以快速地搭建出一个平台。而且，模板的框架自身，也蕴含着很多的设计思想。</li><li>多学习一些基本的设计原则。你可以参考Element 官网上的设计理念章节，里面谈到了一致、反馈、效率和可控四个方面，每个方面又涉及很多细节。参照着成熟的产品，再对照这些基本设计理念，你放心，你会进步神速的。</li></ul><h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><p>流水线是持续交付中最核心的实践，也是持续交付实践最直接的体现。</p><h3 id="十大特征"><a href="#十大特征" class="headerlink" title="十大特征"></a>十大特征</h3><p><strong>特性一：打造平台而非能力中心</strong></p><p>与其他 DevOps 平台相比，流水线平台有一个非常典型的特征，那就是，它是唯一一个贯穿软件交付端到端完整流程的平台。正因为这样，流水线平台承载了整个软件交付过程方方面面的能力，比如，持续集成能力、自动化测试能力、部署发布能力，甚至是人工审批的能力等。</p><p>将持续交付流水线平台和垂直业务平台分开，并定义彼此的边界。</p><p>所谓的<strong>垂直业务平台，就是指单一专业领域的能力平台</strong>，比如自动化测试平台、代码质量平台、运维发布平台等等，这些也是软件交付团队日常打交道最频繁的平台。</p><p><strong>流水线平台只专注于流程编排、过程可视化，并提供底层可复用的基础能力</strong>。比如，像是运行资源池、用户权限管控、任务编排调度流程等等。</p><p>垂直业务平台则专注于专业能力的建设、一些核心业务的逻辑处理、局部环节的精细化数据管理等。垂直业务平台可以独立对外服务，也可以以插件的形式，将平台能力提供给流水线平台。</p><p><strong>特性二：可编排和可视化</strong></p><p>所谓的流程可编排能力，就是指用户可以自行定义软件交付过程的每一个步骤，以及各个步骤之间的先后执行顺序。说白了，就是“我的模块我做主，我需要增加哪些交付环节，我自己说了算”。</p><p>流程可编排，需要平台前端提供一个可视化的界面，来方便用户定义流水线过程。典型的方式就是，将流水线过程定义为几个阶段，每个阶段按顺序执行。在每个阶段，可以按需添加步骤，这些步骤可以并行执行，也可以串行执行。</p><p><strong>特性三：流水线即代码</strong></p><p>流水线代码化的好处不言而喻：借助版本控制系统的强大功能，流水线代码和业务代码一样纳入版本控制系统，可以简单追溯每次流水线的变更记录。</p><p>流水线即代码大大地简化了流水线的配置成本，和原子一样，是构成现代流水线的另外一个支柱。</p><p><strong>特性四：流水线实例化</strong></p><p>首先，流水线需要支持参数化执行。<br>通过输入不同的参数，控制流水线的运行结果，甚至是控制流水线的执行过程。</p><p>其次，流水线的每一次执行，都可以理解为是一个实例化的过程。</p><p>每个实例基于执行时间点的流水线配置，生成一个快照，这个快照不会因为流水线配置的变更而变更。如果想要重新触发这次任务，就需要根据当时的快照运行，从而实现回溯历史的需求。</p><p>最后，流水线需要支持并发执行能力。</p><p>这就是说，流水线可以触发多次，生成多个运行实例。这考察的不仅是流水线的调度能力、队列能力，还有持久化数据的管理能力。</p><p><strong>特性五：有限支持原则</strong></p><p>流水线的设计目标，应该是满足大多数、常见场景下的快速使用，并提供一定程度的定制化可扩展能力，而不是满足所有需求。</p><p>流水线设计要提供有限的可能性，而非穷举所有变量因素。</p><p>用户的差异化诉求，该如何满足呢？其实，这很简单，你可以在平台中提供一些通用类原子能力，比如，执行自定义脚本的能力、调用 http 接口的能力、用户自定义原子的能力，等等。只要能提供这些能力，就可以满足用户的差异化需求了。</p><p><strong>特性六：流程可控</strong></p><p>流水线可以为了满足不同阶段的业务目标而存在，并且每条流水线上实现的功能都不相同。为了达到这个目的，流水线需要支持多种触发方式，比如定时触发、手动触发、事件触发等。其中，事件触发就是实现持续集成的一个非常重要的能力。</p><p>除了多种触发方式以外，流水线还需要支持人工审批。这也就是说，每个阶段的流转可以是自动的，上一阶段完成后，就自动执行下一阶段；也可以是手动执行的，必须经过人为确认才能继续执行，这里的人为确认需要配合权限的管控。</p><p><strong>特性七：动静分离配置化</strong></p><p>动静分离就是一种配置化的实现方式。这就是指，将需要频繁调整或者用户自定义的内容，保存在一个静态的配置文件中。然后，系统加载时通过读取接口获取配置数据，并动态生成用户可见的交互界面。</p><p><strong>特性八：快速接入</strong></p><p>在建设流水线平台的时候，能否快速地实现外部平台能力的接入，就成了一个必须要解决的问题。</p><p>经典的解决方式就是提供一种插件机制，来实现平台能力的接入。</p><p>实际上，接入成本的高低，直接影响了平台能力的拓展，而流水线平台支持的能力多少，就是平台的核心竞争力。</p><p>首先，流水线平台需要定义一套标准的接入方式。以接口调用类型为例，接入平台需要提供一个任务调用接口、一个状态查询接口以及一个结果上报接口。</p><ul><li>任务调用接口：用于流水线触发任务，一般由接入平台定义和实现。对于比较成熟的平台来说，这类接口一般都是现成的。接口调用参数可以直接转换成原子的参数，一些平台的配置化信息（比如接口地址、接口协议等），都可以定义在原子的数据结构中。</li><li>状态查询接口：用于流水线查询任务的执行状态，获取任务的执行进度。这个接口也是由接入平台定义和实现的，返回的内容一般包括任务状态和执行日志等。</li><li>数据上报接口：用于任务将执行结果上报给流水线平台进行保存。这个接口由流水线平台定义，并提供一套标准的数据接口给到接入方。接入方必须按照这个标准接口上报数据，以简化数据上报的过程。</li></ul><p><strong>特性九：内建质量门禁</strong></p><p>内建质量的两大原则：</p><ul><li>问题发现得越早，修复成本就越低；</li><li>质量是每个人的责任，而不是质量团队的责任。</li></ul><p>毫无疑问，持续交付流水线是内建质量的最好阵地，而具体的展现形式就是质量门禁。通过在持续交付流水线的各个阶段注入质量检查能力，可以让内建质量真正落地。</p><p>在流水线平台上，要完成质量规则制定、门禁数据收集和检查，以及门禁结果报告的完整闭环。质量门禁大多数来源于垂直业务平台，比如，UI 自动化测试平台就可以提供自动化测试通过率等指标。只有将用于门禁的数据上报到流水线平台，才能够激活检查功能。</p><p><strong>特性十：数据聚合采集</strong></p><p>当平台的能力以原子的形式接入流水线之后，流水线需要有能力获取本次执行相关的结果数据，这也是在平台对接的时候，务必要求子系统实现数据上报接口的原因。至于上报数据的颗粒度，其实并没有一定之规，原则就是满足用户对最基本的结果数据的查看需求。</p><h2 id="建设数据度量平台"><a href="#建设数据度量平台" class="headerlink" title="建设数据度量平台"></a>建设数据度量平台</h2><p>建设数据度量平台的核心价值，也就是让软件交付过程变得可视化。</p><p>在平台建设的时候，需要关注事前、事中和事后三个阶段的事情。</p><ul><li><strong>事前就是要对指标的定义达成共识</strong>。这里的指标要细化到数据源和详细的计算公式层面，即便没有度量平台，也可以计算出相应的结果；</li><li><strong>事中就是平台建设方面</strong>，面对多数据源平台可以采用采集器插件的方式灵活适配，建议使用 HBase 等非关系型数据库进行数据存储，可以利用现有的前端组件来实现可视化界面展示。</li><li><strong>事后就是数据的运营和规则落地</strong>。只有度量数据能够反映出问题，并驱动团队改进，度量才有意义。</li></ul><h2 id="案例-三个月完成千人规模的产品要怎么做"><a href="#案例-三个月完成千人规模的产品要怎么做" class="headerlink" title="案例: 三个月完成千人规模的产品要怎么做"></a>案例: 三个月完成千人规模的产品要怎么做</h2><h3 id="项目启动"><a href="#项目启动" class="headerlink" title="项目启动"></a>项目启动</h3><p>在项目启动会上，团队达成了两个非常关键的结论：一个是系统方案选型；另一个是建立协作机制。</p><p>首先，由于时间紧任务重，我们决定使用更易于协作的前后端分离的开发模式</p><p>技术框架方面，由于大家对前后端分离的模式达成了共识，我们就采用Python+Django+VUE 的方式来做。</p><p>在项目协作方面，我等会儿会专门提到，由于团队成员分散在北京、上海两地，彼此之间不够熟悉和信任，所以，建立固定的沟通机制就非常重要。</p><p><strong>建立沟通机制</strong></p><ul><li>一次是面向全员的。一方面同步项目的最新进展，另一方面，也给大家一些紧迫感，让大家觉得“其他人都在按照计划执行，自己也不能落后”。</li><li>另外一次是面向跨地域骨干的。这主要还是为了增进联系，并且对一些核心问题进行二次的进展确认。不拉上全员，也是为了避免过多地浪费项目成员的时间。</li></ul><p>最后，项目毕竟还是有一些技术风险的，所以还需要启动预研。<strong>预研项目的一些技术风险。</strong></p><p>项目启动阶段要重点关注的几件事情：</p><ul><li>明确项目目标，树立团队的信心；</li><li>沟通开发模式和技术架构选型，以快速开发和简单上手为导向；</li><li>建立沟通渠道，保持高频联系；</li><li>识别项目的技术风险，提前开启专项预研。</li></ul><h3 id="开发策略"><a href="#开发策略" class="headerlink" title="开发策略"></a>开发策略</h3><p>首先，就是研发环境容器化。</p><p>其次，就是选择分支策略。虽然 DevOps 倡导的是主干开发，但是我们还是选择了“三分支”的策略，因为我们搭建了三套环境。</p><h3 id="开发协作流程"><a href="#开发协作流程" class="headerlink" title="开发协作流程"></a>开发协作流程</h3><p>在工具层面，我们使用了 Jira。</p><p>在 Jira 里面，我们采用了精益看板加上迭代的方式，基本上两周一个迭代，保持开发交付的节奏。</p><p>需求统一纳入 Backlog 管理，当迭代开始时，就拖入待开发状态，研发挑选任务启动开发，并进入开发中。当开发完成后，也就意味着功能已经在测试环境部署。这个时候，就可以等待功能验收。只有在验收通过之后，才会发布到预发布环境。并经过二次验收后，最终上线发布给用户。</p><p><strong>开发流程</strong></p><p><img src="/assets/images/ops/devops/image-20200911115807613.png" alt="image-20200911115807613"></p><p><img src="/assets/images/ops/devops/image-20200911115824783.png" alt="image-20200911115824783"></p><p><strong>明确原则和规范</strong></p><p>对于一个新组建的团队来说，规则是消除分歧和误解的最好手段，所以一定要让这些规则足够得清晰易懂。</p><p><strong>“3-2-1”原则</strong></p><p><strong>3：创建任务三要素</strong></p><ul><li>有详细的问题说明和描述</li><li>有清晰的验收标准</li><li>有具体的经办人和迭代排期</li></ul><p><strong>2：处理任务两要素</strong></p><ul><li>在开发中，代码变更要关联 Jira 任务号</li><li>在开发完成后，要添加 Jira 注释，说明改动内容和影响范围</li></ul><p><strong>1：解决任务一要素</strong></p><ul><li>问题报告人负责任务验收关闭</li></ul><p>当然，团队规则远不止这几条。你要打造自己团队内部的规则，并且反复地强调规则，帮助<br>大家养成习惯。这样一来，你会发现，研发效率提升和自组织团队都会慢慢成为现实。</p><p>除此之外，你也不要高估人的主动性，期望每个人都能自觉地按照规则执行。定期和及时的提醒就非常必要。比如，每天增加定时邮件通知，告诉大家有哪些需求需要验收，有哪些可以上线发布，尽量让每个人都明白应该去哪里获取最新的信息。</p><p>另外，每次开周会时，都要强调规则的执行情况，甚至每天的站会也要按需沟通。只有保持短促、高频的沟通，才能产生理想的效果。</p><h3 id="产品运营策略"><a href="#产品运营策略" class="headerlink" title="产品运营策略"></a>产品运营策略</h3><p>团队不仅要做得好，还要善于运营和宣传，而这又是技术团队的一大软肋。</p><p><strong>建立内部用户沟通群</strong>，在产品初期尽量选择一些活跃的种子用户来试用。那些特别感兴趣、愿意尝试新事物、不断给你提建议的都是超级用户。这些用户未来都是各个团队中的“星星之火”，在项目初期，你一定要识别出这些用户。</p><p>另外，每一次上线都发布一个 release notes，并通过邮件和内部沟通群的方式通知全员，一方面可以宣传新功能，另一方面，也是很重要的一方面，就是<strong>保持存在感的刷新。</strong></p><p><strong>内部建立 OnCall 机制</strong>，每周团队成员轮值解决一线用户的问题，既可以保证问题的及时收敛，也能让远离用户的开发真真切切地听到用户的声音。</p><p>平台运营就跟打广告是一样的，越是在人流最大、关注度最高的地方打广告，效果也就越好。每个公司一般都有类似的首页，比如公司内部的技术首页、技术论坛、日常办公的 OA系统等等，这些地方其实都会有宣传的渠道和入口。你要做的就是找到这个入口，并联系上负责这个渠道的人员。</p><p>另一个方法有些取巧，但对于技术团队来说，也非常适用，那就是通过技术分享的渠道来宣传产品。</p><p><img src="/assets/images/ops/devops/image-20200911120423420.png" alt="image-20200911120423420"></p><h3 id="团队文化建设"><a href="#团队文化建设" class="headerlink" title="团队文化建设"></a>团队文化建设</h3><p>无论什么样的工具、流程、目标，最终都是依靠人来完成的。如果忽略对人的关注，就等同于本末倒置，不是一个成熟的团队管理者应该做的事情。</p><ol><li>让专业的人做专业的事情</li><li>抓大放小，适当地忽略细节</li></ol><h2 id="开源工具"><a href="#开源工具" class="headerlink" title="开源工具"></a>开源工具</h2><h3 id="端到端流水线解决方案"><a href="#端到端流水线解决方案" class="headerlink" title="端到端流水线解决方案"></a>端到端流水线解决方案</h3><p><img src="/assets/images/ops/devops/image-20200914110423050.png" alt="image-20200914110423050"></p><ul><li><p>需求管理 - Jira</p></li><li><p>代码管理 - GitLab</p></li><li><p>代码质量 - SonarQube</p></li><li><p>环境管理 - Kubernetes</p></li></ul><h2 id="Devops工程师必备的技能"><a href="#Devops工程师必备的技能" class="headerlink" title="Devops工程师必备的技能"></a>Devops工程师必备的技能</h2><h3 id="DevOps-技能发展路线图"><a href="#DevOps-技能发展路线图" class="headerlink" title="DevOps 技能发展路线图"></a>DevOps 技能发展路线图</h3><p><img src="https://cdn.jsdelivr.net/gh/kamranahmedse/developer-roadmap@master/translations/chinese/img/devops-map.png" alt="devops-map"></p><h3 id="DevOps-工程师的岗位职责"><a href="#DevOps-工程师的岗位职责" class="headerlink" title="DevOps 工程师的岗位职责"></a>DevOps 工程师的岗位职责</h3><p>除了基础的岗位职责外，还需额外关注 3 个方面</p><ol><li>工具平台开发, 工具是自动化的载体，而自动化可以说是 DevOps 的灵魂。</li><li>流程实践落地,理念和实践的宣导，内部员工的培训，持续探索和发现流程的潜在优化点，这些也都<br>是 DevOps 工程师要考虑的事情。</li><li>技术预研试点, 结合公司的实际情况，评估潜在的工具和解决方案, 开展 DevOps 的理念宣导和技术培训，鼓动领导参加行业的大会，</li></ol><h3 id="DevOps-工程师的主要技能"><a href="#DevOps-工程师的主要技能" class="headerlink" title="DevOps 工程师的主要技能"></a>DevOps 工程师的主要技能</h3><p>DevOps 工程师的核心能力模型: </p><p>其中，能力模型分为两个方面：专业能力和通用能力。</p><p>专业能力也就是常说的硬实力，是IT 从业人员身上的特有能力，比如软件工程师会写代码，就跟导演会拍电影，司机会开车一样。而通用能力，更加接近于软实力，这些能力并不局限于某一个岗位或者职业，是所有人都应该努力培养的能力。很多时候，当硬实力到达天花板之后，软实力的差异将决定一个人未来的高度，这一点非常重要。</p><p><strong>软实力</strong></p><ol><li>沟通能力，在推动 DevOps 落地的过程中，你需要同时具备向上沟通、向下沟通和横向沟通的能力。</li><li>同理心，共享目标,共担责任,这种同理心也是弥合团队分歧，建立良好的协作文化所必需的能力。</li><li>学习能力，在有限的时间里快速学习新的技能，并且有意愿主动地改进提升，也是一种能力。</li></ol><p><strong>硬实力</strong></p><ol><li>代码能力，代码能力包含两个方面，分别是脚本语言能力和高级语言编程能力。</li><li>自动化能力，无论是开源工具，还是自研工具，工具与工具之间的链路打通也是自动化的重要因素。</li><li>IT 基础能力，对于基础概念，还是需要既知其然，也知其所以然。</li><li>容器云能力，在云时代，基于容器技术的应用开发和部署方式，都是DevOps 工程师必须了解的。</li><li>业务和流程能力，企业需要的不仅仅是一个工具，而是工具所关联的一整套解决方案，其中最重要的就是业务流程。对于 DevOps 工程师来说，要有能力发现当前流程中的瓶颈点，并且知道一个更加优化的流程应该是怎样的。</li></ol><h3 id="学习路径"><a href="#学习路径" class="headerlink" title="学习路径"></a>学习路径</h3><p>基于过往在公司内部推行 DevOps 的经验，以及当前行业的发展趋势，我有几条建议送给你：</p><ol><li><p>集中强化代码能力</p></li><li><p>培养跨职能领域核心能力</p></li><li><p>DevOps 核心理念和业务思维</p></li><li><p>潜移默化的软实力建设</p></li><li><p>勤练习，多总结</p></li></ol><h2 id="推荐读物"><a href="#推荐读物" class="headerlink" title="推荐读物"></a>推荐读物</h2><p><strong>报告</strong></p><p>​    《DevOps 状态报告》</p><p>​    关注点：1.看趋势， 2.看模型，3看实践</p><p>​    <a href="https://pan.baidu.com/s/1W7-_et-wulD7AueBU2KTow">https://pan.baidu.com/s/1W7-_et-wulD7AueBU2KTow</a> 提取码：mgl1</p><p><strong>书籍</strong></p><blockquote><p>电子读物可以去 微信读书 APP中搜索</p></blockquote><ul><li><p>关于DevOps 工程实践</p><p>《持续交付》&amp;《持续交付 2.0》</p></li><li><p>关于管理实践和精益方面</p><p>《精益创业》&amp;《 Scrum 精髓》&amp;《精益产品开发》&amp;《精益开发与看板方法》</p></li><li><p>关于DevOps 的全貌以及核心理论体系和实践</p><p>《DevOps 实践指南》&amp;《Accelerate：加速》</p></li></ul><p><strong>小说</strong></p><p>​    《凤凰项目》&amp;《人月神话》&amp;《目标》</p><p><strong>大会，网站和博客</strong></p><ul><li><a href="https://events.itrevolution.com/">DEOS</a> ：DevOps国际峰会，以案例总结著称；</li><li><a href="https://devopsdays.org/">DevOpsDays</a>：大名鼎鼎的DevOpsDays社区；</li><li><a href="https://thenewstack.io/">TheNewStack</a> ：综合性网站，盛产高质量的电子书；</li><li><a href="https://devops.com/">DevOps.com</a> ：综合性网站；</li><li><a href="https://dzone.com/">DZone</a> ： 综合性网站，盛产高质量的电子书；</li><li><a href="https://devblogs.microsoft.com/devops/">Azure DevOps</a>：综合性网站，盛产高质量的电子书；</li><li><a href="https://www.martinfowler.com/bliki/">Martin Fowler</a> ：Martin Fowler的博客；</li><li><a href="https://www.cloudbees.com/devops">CloudBees Devops</a> ：Jenkins背后的公司的博客。</li></ul><hr><blockquote><p>本文是对  极客时间 的 &lt;&lt; DevOps实战笔记 &gt;&gt; 的总结。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins 凭证管理, 看着一篇就够了~</title>
      <link href="2020/05/15/jenkins-ping-zheng-guan-li/"/>
      <url>2020/05/15/jenkins-ping-zheng-guan-li/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><p>许多三方网站和应用可以与Jenkins交互，如Artifact仓库，基于云的存储系统和服务等. 在Jenkins中添加/配置credentials，Pipeline项目就可以使用 credentials 与三方应用交互</p><h2 id="Credential-类型"><a href="#Credential-类型" class="headerlink" title="Credential 类型"></a>Credential 类型</h2><p>参考： <a href="https://jenkins.io/zh/doc/book/using/using-credentials/">https://jenkins.io/zh/doc/book/using/using-credentials/</a></p><p><strong>Jenkins可以存储以下类型的credentials:</strong></p><ul><li><p>Secret text - API token之类的token (如GitHub个人访问token)</p></li><li><p>Username and password - 可以为独立的字段，也可以为冒号分隔的字符串：username:password(更多信息请参照 处理 credentials)</p></li><li><p>Secret file - 保存在文件中的加密内容</p></li><li><p>SSH Username with private key - SSH 公钥/私钥对</p></li><li><p>Certificate - a PKCS#12 证书文件 和可选密码</p></li><li><p>Docker Host Certificate Authentication credentials.</p></li></ul><h2 id="Credential-安全"><a href="#Credential-安全" class="headerlink" title="Credential 安全"></a>Credential 安全</h2><p>为了最大限度地提高安全性，在Jenins中配置的 credentials 以加密形式存储在Jenkins 主节点上（用Jenkins ID加密），并且 <code>只能通过 credentials ID</code> 在Pipeline项目中获取</p><p>这最大限度地减少了向Jenkins用户公开credentials真实内容的可能性，并且阻止了将credentials复制到另一台Jenkins实例</p><h2 id="Credential-创建"><a href="#Credential-创建" class="headerlink" title="Credential 创建"></a>Credential 创建</h2><ul><li><p>选择适合的凭证类型</p><p>  <img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201027222335.png"></p></li><li><p>创建 “Username and password” 凭证<br>  <img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201027223010.png"></p></li><li><p>创建 “SSH Username with private key” 凭证</p><p>  <img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201027222917.png"></p></li></ul><h3 id="Credential-ID-定义"><a href="#Credential-ID-定义" class="headerlink" title="Credential ID 定义"></a>Credential ID 定义</h3><ul><li><p>在 ID 字段中，必须指定一个有意义的<code>Credential ID</code>- 例如 jenkins-user-for-xyz-artifact-repository。注意: 该字段是可选的。 如果您没有指定值, Jenkins 则Jenkins会分配一个全局唯一ID（GUID）值。</p></li><li><p><strong>请记住：</strong> 一旦设置了credential ID，就不能再进行更改。</p></li></ul><h2 id="Credential-使用"><a href="#Credential-使用" class="headerlink" title="Credential 使用"></a>Credential 使用</h2><p>参考： <a href="https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#handling-credentials">https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#handling-credentials</a></p><p>存储在Jenkins中的credentials可以被使用：</p><ol><li><p>适用于Jenkins的任何地方 (即全局 credentials),</p></li><li><p>通过特定的Pipeline项目/项目 (在 处理 credentials 和 使用Jenkinsfile部分了解更多信息),</p></li><li><p>由特定的Jenkins用户 (如 Pipeline 项目中<a href="https://jenkins.io/zh/doc/book/blueocean/creating-pipelines/">创建 Blue Ocean</a>的情况).</p><ul><li>Blue Ocean 自动生成一个 SSH 公共/私有密钥对, 确保 SSH 公共/私有秘钥对在继续之前已经被注册到你的Git服务器</li></ul></li></ol><p>实际使用中，下面几个场景会用到creential</p><ul><li>gitlab 访问、API调用</li><li>jenkins slave 创建</li></ul><h3 id="Credential-相关插件"><a href="#Credential-相关插件" class="headerlink" title="Credential 相关插件"></a>Credential 相关插件</h3><p><strong>注意：</strong> 上述 Credential 类型都依赖于 jenkins插件，同样jenkins pipeline 也需要这些插件的安装以支持代码片段</p><ul><li><p>Credentials Binding： <a href="https://plugins.jenkins.io/credentials-binding/">https://plugins.jenkins.io/credentials-binding/</a></p><ul><li><p><strong>For secret text, usernames and passwords, and secret files</strong></p><pre class="line-numbers language-bash"><code class="language-bash">environment <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>MAGE_REPO_CREDENTIALS <span class="token operator">=</span> credentials<span class="token punctuation">(</span><span class="token string">'COMPOSER_REPO_MAGENTO'</span><span class="token punctuation">)</span>COMPOSER_AUTH <span class="token operator">=</span> <span class="token string">""</span><span class="token string">"&amp;#123;"</span>http-basic<span class="token string">": &amp;#123;   "</span>repo.magento.com<span class="token string">": &amp;#123;       "</span>username<span class="token string">": "</span>$<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;env.MAGE_REPO_CREDENTIALS_USR&amp;#125;",</span>       <span class="token string">"password"</span><span class="token keyword">:</span> <span class="token string">"$&amp;#123;env.MAGE_REPO_CREDENTIALS_PSW&amp;#125;"</span>   <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125; &amp;#125;"""</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>For other credential types</strong></p><pre class="line-numbers language-bash"><code class="language-bash">withCredentials<span class="token punctuation">(</span><span class="token punctuation">[</span>usernamePassword<span class="token punctuation">(</span>credentialsId: <span class="token string">'amazon'</span>, usernameVariable: <span class="token string">'USERNAME'</span>, passwordVariable: <span class="token string">'PASSWORD'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>// available as an <span class="token function">env</span> variable, but will be masked <span class="token keyword">if</span> you try to print it out any <span class="token function">which</span> way// note: single quotes prevent Groovy interpolation<span class="token punctuation">;</span> expansion is by Bourne Shell, <span class="token function">which</span> is what you wantsh <span class="token string">'echo <span class="token variable">$PASSWORD</span>'</span>// also available as a Groovy variable<span class="token keyword">echo</span> USERNAME// or inside double quotes <span class="token keyword">for</span> string interpolation<span class="token keyword">echo</span> <span class="token string">"username is <span class="token variable">$USERNAME</span>"</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>Jenkins Plain Credentials Plugin: <a href="https://plugins.jenkins.io/plain-credentials/">https://plugins.jenkins.io/plain-credentials/</a></p><p>  <img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201027224420.png"></p></li><li><p>SSH Credentials: <a href="https://plugins.jenkins.io/ssh-credentials/">https://plugins.jenkins.io/ssh-credentials/</a></p></li></ul><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ul><li><p>为了便于管理和使用， 强烈建议使用统一的约定来指定credential ID</p></li><li><p>建议使用类似下面的format做为credential ID， 便于jenkinsfile开发时直接使用，同时在”描述“里写清楚credential的作用</p><p>  <code>gitlab-api-token、gitlab-private-key、gitlab-userpwd-pair、harbor-xxx-xxx</code></p><p>  <img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201027221956.png"></p></li></ul><p><strong>实践：</strong></p><ul><li><p>如下所示，将凭证使用统一的ID命名之后，便于复用，凭证定义一次，可多次，多个地方统一使用，无论是后期维护，复用都非常方便！</p><pre class="line-numbers language-shell"><code class="language-shell">    environment &#123;        // HARBOR="harbor.devopsing.site"        HARBOR_ACCESS_KEY = credentials('harbor-userpwd-pair')        SERVER_ACCESS_KEY = credentials('deploy-userpwd-pair')            &#125;    .....    docker login --username=$&#123;HARBOR_ACCESS_KEY_USR&#125; --password=$&#123;HARBOR_ACCESS_KEY_PSW&#125; $&#123;HARBOR&#125;    sshpass -p "$&#123;SERVER_ACCESS_KEY_PSW&#125;" ssh -o StrictHostKeyChecking=no $&#123;SERVER_ACCESS_KEY_USR&#125;@$&#123;DEPLOY_SERVER&#125; "$runCmd"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins, CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Agile, CI/CD, DevOps</title>
      <link href="2020/03/27/agile-cicd-devops/"/>
      <url>2020/03/27/agile-cicd-devops/</url>
      
        <content type="html"><![CDATA[<p>随着DevOps理念的普及与扩散，可能会被一大堆名字概念搞的莫名其妙，理清它们之间的关系可以帮助团队知道DevOps如何落地，改善工作流程。</p><p><strong>Here’s a quick and easy way to differentiate agile, DevOps, and CI/CD:</strong></p><ul><li>Agile focuses on processes highlighting change while accelerating delivery.</li><li>CI/CD focuses on software-defined life cycles highlighting tools that emphasize automation.</li><li>DevOps focuses on culture highlighting roles that emphasize responsiveness.</li></ul><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020224951.png"></p><h2 id="Agile-Development"><a href="#Agile-Development" class="headerlink" title="Agile Development"></a>Agile Development</h2><ul><li>拥抱变化</li><li>快速迭代</li></ul><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020225036.png"></p><h2 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI /CD"></a>CI /CD</h2><p>CI/CD 都体现了如今快节奏市场中的文化和发展原则，旨在缩短开发周期、提高软件交付效率以及实现全流程的自动化。同时，两者都有着共同的目标：让软件开发更少地依赖于手动执行的任务，在此基础上使得软件的发布更加频繁、更加安全可靠。由于有着相同的目标，因此持续集成和持续交付并非相互排斥的, 只是它们的应用范围有所不同。</p><ul><li>CI：持续集成（CONTINUOUS INTEGRATION）</li><li>CD：持续部署（CONTINUOUS DEPLOYMENT）</li><li>CD：持续交付（CONTINUOUS DELIVERY）</li></ul><h3 id="持续集成CI（Continuous-Integration）"><a href="#持续集成CI（Continuous-Integration）" class="headerlink" title="持续集成CI（Continuous Integration）"></a>持续集成CI（Continuous Integration）</h3><p>参考大师的定义: <a href="http://www.martinfowler.com/articles/continuousIntegration.html">http://www.martinfowler.com/articles/continuousIntegration.html</a></p><p>持续集成（CI）是在源代码变更后自动检测、拉取、构建和（在大多数情况下）进行单元测试的过程</p><ul><li><p>对项目而言，持续集成（CI）的目标是确保开发人员新提交的变更是好的， 不会发生break build; 并且最终的主干分支一直处于可发布的状态，</p></li><li><p>对于开发人员而言，要求他们必须频繁地向主干提交代码，相应也可以即时得到问题的反馈。实时获取到相关错误的信息，以便快速地定位与解决问题<br><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020225142.png"></p></li></ul><p>显然这个过程可以大大地提高开发人员以及整个IT团队的工作效率，避免陷入好几天得不到好的“部署产出”，影响后续的测试和交付。</p><h3 id="持续交付-（Continuous-Delivery）"><a href="#持续交付-（Continuous-Delivery）" class="headerlink" title="持续交付 （Continuous Delivery）"></a>持续交付 （Continuous Delivery）</h3><p>持续交付在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「预发布环境」（production-like environments）中。交付给质量团队或者用户，以供评审。如果评审通过，代码就进入生产阶段 持续交付并不是指软件每一个改动都要尽快部署到产品环境中，它指的是任何的代码修改都可以在任何时候实时部署。<br><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020225203.png"></p><p>强调：<br>1、手动部署<br>2、有部署的能力，但不一定部署</p><h3 id="持续部署（Continuous-Deployment）"><a href="#持续部署（Continuous-Deployment）" class="headerlink" title="持续部署（Continuous Deployment）"></a>持续部署（Continuous Deployment）</h3><p>代码通过评审之后，自动部署到生产环境中。持续部署是持续交付的最高阶段。 </p><p>强调<br>1、持续部署是自动的<br>2、持续部署是持续交付的最高阶段<br>3、持续交付表示的是一种能力，持续部署则是一种方式</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020225227.png"></p><ul><li>DEV Development environment -开发环境，用于开发者调试使用</li><li>FAT Feature Acceptance Test environment  -功能验收测试环境，用于软件测试者测试使用</li><li>UAT User Acceptance Test environment  -用户验收测试环境，用于生产环境下的软件测试者测试使用</li><li>PRO Production environment -生产环境</li></ul><p>通过CD可以加快软件交付速度，目标用户可以在几天或几周内就收到修复后的功能与新增的功能，而无需等待数月后才更新。CD的部署频率也加快了整个流程中的反馈循环。最新版本真的解决了预期的问题吗？是否满足了用户的需求？用户就可以快速地验收并作出判断，而IT团队也可以在问题影响到开发周期之前就解决反馈的问题。持续的反馈循环使得用户与IT团队更紧密地合作，以确保能准确的理解与满足他们的需求。整个交付过程进度可视化，方便团队人员与客户了解项目的进度。</p><ul><li><p>持续集成可确保代码库中始终保持最新的代码，同时可以快速集成来自多个开发人员的代码，并确保这些代码可在多个环境中协同工作。它通常有助于减少错误并通过自动化流程来减少手动任务。CI可以实现代码的自动构建与测试，减少开发中的Bug。因此，CI适用于那些过度依赖手动任务和复杂构建过程的企业。</p></li><li><p>持续交付适用于需要缩短开发周期，更快地为目标用户提供软件的企业。CD降低了部署新软件或升级已有软件的难度，且实现了全流程的自动化，因此您的团队无需手动执行复杂繁琐的任务，从而加快反馈速度，来确保您增加的功能真正地满足用户的需求。</p></li></ul><p>此外，也有不少人认为CI是CD的前提与基础，没有CI就不能实现CD。这种说法也是比较流行的，其思路如下图。因此，不管是哪种说法，CI与CD都是DevOps工具中不可或缺的理念与方法。</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020225243.png"></p><p><strong>持续交付与持续部署，到底谁应该包含谁 ?</strong></p><p>持续部署是自动化的将一切变更放到生产环境，而持续交付则有判断决策过程，并直接说“In order to do Continuous Deployment you must be doing Continuous Delivery.”</p><blockquote><p>“Continuous Delivery is sometimes confused with Continuous Deployment.Continuous Deploymentmeans that every change goes through the pipeline and automatically gets put into production, resulting in many production deployments every day. Continuous Delivery just means that you are able to do frequent deployments but may choose not to do it, usually due to businesses preferring a slower rate of deployment. In order to do Continuous Deployment you must be doing Continuous Delivery.”</p></blockquote><p>对持续交付与持续部署的关系，Martin也承认两个概念容易造成困惑，持续部署代表将所有变更自动通过流水线推到生产环境，持续交付则意味着你有能力这样做，但可以基于业务选择不这样做。</p><p>所以我不觉得两者有谁包含谁，两者在这个层面讲，一个是技术领域，一个是业务领域。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><p><a href="https://www.atlassian.com/continuous-delivery/principles/continuous-integration-vs-delivery-vs-deployment">Continuous integration vs. continuous delivery vs. continuous deployment</a></p></li><li><p><a href="https://dzone.com/articles/continuous-integration-vs-continuous-delivery">Continuous Integration vs. Continuous Delivery</a></p></li><li><p><a href="https://www.mindtheproduct.com/what-the-hell-are-ci-cd-and-devops-a-cheatsheet-for-the-rest-of-us/">The Product Managers’ Guide to Continuous Delivery and DevOps</a></p></li><li><p><a href="https://theagileadmin.com/what-is-devops/">What Is DevOps?</a></p></li><li><p><a href="https://www.mabl.com/blog/what-is-cicd">What is CI/CD?</a></p></li><li><p><a href="https://www.synopsys.com/blogs/software-security/agile-cicd-devops-difference/">What’s the difference between agile, CI/CD, and DevOps</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What is DevOps ?</title>
      <link href="2020/02/27/what-is-devops/"/>
      <url>2020/02/27/what-is-devops/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近几年”DevOps”这个关键词经常出现在项目开发当中，特别是随着微服务/容器/cloud在项目中的大范围应用，你不想知道都很难。作为一个伴随CI/CD到DevOps一路走来的工程师，我将分几个部分漫话DevOps以及相关的概念，作为软件开发工程师，你需要知道并且开始践行DevOps, 它应该成为你职业素养的一部分。</p><p>笔者是在2015年左右开始听说“DevOps”这个名词，最早听说并实践的一直是CI/CD （后面会介绍它们之间的关系），从CI/CD开始，你会更容易理解DevOps倡导的文化。</p></blockquote><h2 id="What-is-DevOps"><a href="#What-is-DevOps" class="headerlink" title="What is DevOps"></a>What is DevOps</h2><p><strong>DevOps 是一组用于促进开发和运维人员之间协作的过程、方法和系统的统称。</strong></p><p>Wikipedia对DevOps的定义是：</p><blockquote><p>DevOps是软件开发、运维和质量保证三个部门之间的沟通、协作和集成所采用的流程、方法和体系的一个集合。 它是人们为了及时生产软件产品或服务，以满足某个业务目标，对开发与运维之间相互依存关系的一种新的理解。 …… DevOps并不仅仅关注软件部署，它是部门间沟通协作的一组流程和方法。</p></blockquote><p>DevOps是Development和Operations的组合，是一种方法论，是一组过程、方法与系统的统称，用于促进应用开发、应用运维和质量保障（QA）部门之间的沟通、协作与整合。以期打破传统开发和运营之间的壁垒和鸿沟  </p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232721.png"></p><p>从下图中，可以看到Dev 和Ops 关注的点是不同的，并且有各自的利益和关注点，沟通必然存在障碍。<strong>一个想快速迭代，一个想稳定；一个不关心怎么部署运维，一个不清楚开发架构；由此带来的就是效率的低下，以及相互的抱怨，但是完整的项目并不是仅仅代码写完就完事了，质量/稳定/运维才是更重要的。</strong></p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232740.png"></p><p>DevOps 提倡通过一系列的技术和工具降低开发和运维人员之间的隔阂，实现从开发到最终部署的全流程自动化，从而达到开发运维一体化。通过将 DevOps 的理念引入到整个系统的开发过程中，能够显著提升软件的开发效率，使得各个团队减少时间损耗，更加高效地协同工作，缩短软件交付的周期，更加适应当今快速发展的互联网时代。下面这个DevOps能力图，良好的闭环可以大大增加整体的产出</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232754.png"></p><h2 id="DevOps-与传统开发方式"><a href="#DevOps-与传统开发方式" class="headerlink" title="DevOps 与传统开发方式"></a>DevOps 与传统开发方式</h2><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232821.png"></p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232836.png"></p><h2 id="Why-is-DevOps"><a href="#Why-is-DevOps" class="headerlink" title="Why is DevOps"></a>Why is DevOps</h2><p>猛得听上去，DevOps很抽象，你可能会问以前没有DevOps不是一样开发交付吗？为什么是DevOps?<br>瀑布开发，敏捷开发都听过吧？DevOps你可以理解为新的开发模型，是文化和技术的方法论，需要公司在组织文化上的变革。</p><p>DevOps早在十年前就有人提出来，但是，为什么这两年才开始受到越来越多的企业重视和实践呢？因为DevOps的发展是独木不成林的，现在有越来越多的技术支撑。<strong>微服务架构理念、容器技术使得DevOps的实施变得更加容易，计算能力提升和云环境的发展使得快速开发的产品可以立刻获得更广泛的使用。</strong><br>因为技术在发展，项目的开发过程也需要适应新的技术和框架，微服务那么多，容器可能上千个，你怎么快速部署/维护？</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201020232921.png"></p><h2 id="DevOps-的好处"><a href="#DevOps-的好处" class="headerlink" title="DevOps 的好处"></a>DevOps 的好处</h2><ul><li>依托自动化工具把开发、测试、发布、部署的过程整合，实现高度自动化与高效交付。</li><li>在保证产品质量的前提下快速、频繁地发布产品。</li><li>能够即使获得用户反馈，并快速响应。</li><li>最大限度地减少风险，降低代码的出错率。</li><li>高质量的软件发布标准。整个交付过程标准化、可重复、可靠。</li><li>整个交付过程进度可视化，方便团队人员了解并控制项目进度。</li><li>团队协作更高效。</li></ul><h2 id="DevOps-带来的变革"><a href="#DevOps-带来的变革" class="headerlink" title="DevOps 带来的变革"></a>DevOps 带来的变革</h2><ul><li>角色分工：打破传统团队隔阂，让开发、运维紧密结合，高效协作</li><li>研发：专注研发、高度敏捷、持续集成</li><li>产品交付：高质量、快速、频繁、自动化、持续交付</li></ul><p>简单的说，<strong>DevOps=团队文化+流程+工具</strong></p><p>团队文化的意思很简单，就是<strong>你的团队要知道并认可DevOps理念</strong>；然后就要通过<strong>具体的流程和工具</strong>来实现这个理念。</p><p>后续，我会一点点根据自己的心得体会，慢慢总结分享对DevOps的理解</p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续集成实践中的思考</title>
      <link href="2020/02/20/chi-xu-ji-cheng-shi-jian-zhong-de-si-kao/"/>
      <url>2020/02/20/chi-xu-ji-cheng-shi-jian-zhong-de-si-kao/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近在看到ThoughtWorks的一篇技术文章提到“几项与持续集成相关的反模式”, 结合自己的实践体会特别有深切体会，所以记录下来</p></blockquote><h2 id="持续集成的反模式"><a href="#持续集成的反模式" class="headerlink" title="持续集成的反模式"></a>持续集成的反模式</h2><p>最需要被点名批评的现象莫过于“持续集成剧场”了：</p><blockquote><p>很多开发者只是简单的搭建了持续集成服务器就以为在做“持续集成”，但他们实际上会遗失持续集成的关键优点而导致失败。常见的失败模式包括：虽然在一个共享的主分支上运行持续集成，但是代码提交不频繁，所以集成并没有真正的“持续”。以及在一个测试覆盖率不足，甚至是长期状态为红的情况下进行构建；或者在功能分支上运行持续集成，这会导致持续隔离。</p></blockquote><p>简而言之，这些团队并没有真正体会到持续集成的好处，而是为了完成上级的任务而演一场“我们在持续集成”的戏——这也正是这个反模式的名字由来。过去十年中，我们在众多刚开始实施持续集成的企业见过这一幕。领导认识到持续集成的好处，<strong>但是推行成了个大问题：推轻了，下面团队不愿动，技术问题解决不了；推重了，下面团队来个上有政策下有对策，领导想看什么就给你演什么——持续集成剧场就此落成。比如说你见过一个表面看起来一直是绿色但是背后连编译都不敢跑的持续集成吗？</strong> 我见过。真是一场好戏。</p><p>为了解决持续集成演戏的问题，一些规模较大的企业开始建设持续集成中心。想法很符合直觉：既然团队自己做持续集成有技术困难、还有可能变成演戏，<strong>那么我就组建一支团队专门帮他们一个个把持续集成跑通、帮他们管理持续集成服务器，</strong>持续集成的运行和统计数据都在这个中央团队手里，下面的团队总没办法演戏了吧？于是，他们又遭遇了第二个持续集成反模式：“所有团队共用一个持续集成实例”。</p><blockquote><p>那些必须使用中心化持续集成服务器的交付团队，常常依赖中心的团队去完成小的配置任务，或者在共享的基础设置和工具中排查问题，这给他们在进度上带来长时间的滞后。</p></blockquote><p>这次是康威定律带来的困难：如果每个团队使用的技术栈配置不同、技术栈配置和管理的职责仍然在每个团队中，那么技术栈演进与持续集成的演进就难免出现节拍不一致。<strong>于是管理着持续集成中心的中央团队开始疲于奔命，帮一个个项目团队修持续集成，而项目团队还感到没有得到足够的支持。</strong></p><p>第三个反模式是“企业级集成测试环境”，这也是很多组织建设持续集成中心的初衷之一：由于能执行完整端到端测试的环境稀缺，各个团队的集成测试无论如何也必须在一个瓶颈处统一调度，所以中心化管理持续集成也就顺理成章。然而，</p><blockquote><p>这些企业集成测试环境通常称为 SIT 或预生产环境）是当下持续交付常见的瓶颈。环境本身很脆弱而且维护成本很高，而这些环境通常存在一些需要由单独的环境管理团队手动配置的组件。在预生产环境的测试给出的反馈慢且不可靠，而且会重复测试那些在隔离的组件上已经测过的功能。</p></blockquote><h2 id="我的体会"><a href="#我的体会" class="headerlink" title="我的体会"></a>我的体会</h2><ol><li><p>对于上面第一个情景，很多时候我们以为有了工具就是持续集成，但是往往那些持续集成并不是那么完美，至少在我看到都是“hardcode”, 可移植性差，不能复用，维护成本高，下一个接手的人需要花时间了解上一个人做的“CI/CD”；因为在一些团队里，并不是很重视这个，认为CI/CD仅仅是个辅助的东西，当然这样跟国内项目的开发周期有关，有时候项目很小，客户催的很急，哪有时间去优化那么好，能用起来再说。当下一个项目来的时候，同样的技术栈的项目还要重新来过一次。</p></li><li><p>毕竟对于开发团队来说，CI/CD是另外一个领域的东西，虽然入门简单（按照网上的教程一个很简单demo就搞定了），但是里面的思想和业务场景需要一个个业务场景的积累，如何优化，如何标准化复用，这并不是简单的事情，其实这也是DevOps要解决的一个个痛点。</p></li><li><p>那么我们建个专业的团队做这个事情吧，就是第二个场景提到的事情，其实这也是我目前正在进行中的场景，但是随着业务开展，严格意义上还没有人用，我们就发现你搞出来了，不见得有人会用，不同的业务，不同的技术栈，你需要和Dev团队密切沟通，需要DevOps团队有广阔的技术视野，如果服务众多个不同业务团队，你可能会发现自己被动的成为了“那个业务项目的一员”；另外沟通的成本其实也不低，想法是好的有个专业的团队，但是落地不是那么容易，这不是一个人，一个团队能解决的问题。</p></li><li><p>那么如何解决这个困境？ 我认为需要企业自上而下，推广这种文化，可以从一个项目开始做推广，小步快跑，将“标准化规则”慢慢建立起来，比如分支的管理，依赖管理，CI/CD与不同技术栈的集成标准化，环境问题（内部环境,线上环境），最后衍生出来一个标准化的CI/CD平台。最后的场景是，Dev团队只关注于业务，他们只需要基于一个CI/CD模板，填写必要的环境参数等，剩下的事情不需要他们管，对于他们是透明的，他们只需要产出是什么，比如仓库，邮件通知等等。</p></li><li><p>所有的”快速复用，持续交付”都是基于大家形成的一个标准流程，没有标准，就没有”复用”，就没有快速的迭代，最后还是”半人工”的低效工作。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【读书】进化</title>
      <link href="2019/11/16/dushu-jinhua/"/>
      <url>2019/11/16/dushu-jinhua/</url>
      
        <content type="html"><![CDATA[<h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><p>最近在看这本《进化-运维技术变革与实践探索》，结合自己的一些实践，有些心得体会，并且摘录了我认为重要的或者有同感的内容。</p><ul><li><a href="https://time.geekbang.org/column/intro/63">https://time.geekbang.org/column/intro/63</a></li></ul><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>持续交付看似一个简单的工具链打通，却需要突破诸多障碍-组织上，工具上，文化上</p><pre><code>- 组织上，必须打破部门墙，否则工具链肯定连不起来- 工具平台能力上，涉及多个方面：项目管理，需求管理，环境管理，配置管理，部署管理，测试管理，监控管理，服务治理</code></pre><p><strong>IT及运维的成熟度分为几个阶段:</strong></p><pre><code>1. 职能阶段: IT和运维作为独立的成本中心存在，其职能在于高效地交付一系列相对有限的核心运维能力2. 内部赋能阶段：IT 和运维专注于实现流畅的内部流程和操作规范，并持续改进，同时被动响应从业务线来的各种需求。这个阶段的运维团队追求的是以IT为中心的由内到外、自下而上的价值趋向，表现和结果3. 贡献阶段：IT 和运维团队在完成自身的营运常态化之后，可以致力于解决业务问题，积极引导IT和运维资源及服务朝着业务目标前进，成为专注于业务的运维团队。这个阶段的运维视角也发生了根本的转变，变成了以业务为导向的由外到内，自上而下的视角4. 差异化阶段：IT和运维团队同其他不同领域的业务团队积极合作，相互融合来持续交付新的产品，服务以及差异化的运营，团队能够敏捷完成产品和服务创新。这这个阶段，IT 和运维已经成为业务本身5. 转型阶段：IT 和运维团队成为持续业务改造的核心，甚至可以被用来重新定义市场和竞争规则。在这个阶段，IT和运维将成为企业的核心竞争优势</code></pre><p>运维能力是整体技术架构能力的体现，运维层面爆发的问题或故障一定是因为整体技术架构中存在问题，割裂两者，单纯看技术架构或运维都是毫无意义的</p><p>跳出运维看运维，从架构角度看运维，这种运维思路上的转变，远比单纯提升运维技术更有价值。从全局角度来看运维，考虑如何打造和体现整个技术架构的运维能力，而不是”运维”的运维能力</p><p>软件架构的目的，是将构建和维护所需的人力资源见到最低    - From 《架构整洁之道》</p><p><strong>运维接触更多的是软件生命周期中的运行维护阶段:</strong></p><ul><li><p>持续交付</p><ul><li>持续集成</li><li>持续部署</li><li>持续发布</li></ul></li><li><p>持续运维</p><ul><li>运行数据分析</li><li>体验数据分析</li><li>预案演练</li><li>故障复查</li></ul></li><li><p>持续反馈和改进</p><ul><li>效率提升</li><li>性能优化</li><li>稳定性提升</li><li>体验提升</li><li>成本控制</li></ul></li><li><p>架构优化</p><ul><li>更加高效稳定地支持业务快速发展</li></ul></li></ul><h2 id="1-运维的本质"><a href="#1-运维的本质" class="headerlink" title="1. 运维的本质"></a>1. 运维的本质</h2><p>规划以<strong>应用</strong>为核心的运维体系</p><pre><code>1. 应用业务模型  -从运维角度，属于业务范畴，不用关注太多2. 应用管理模型- 应用自身属性：应用名，功能信息，责任人，Git地址，部署结构（代码路径，日志路径，以及各类配置文件路径），启停方式，健康检测方式3. 应用运行时所依赖的基础设施和组件- 资源层面： 物理机，虚拟机，容器，HTTP服务（IP,DNS服务）- 基础组件：数据库，缓存，消息队列，存储</code></pre><p>1） 建立各个基础设施和组件的数据模型，同时识别出它们的唯一标识  （以缓存为例，namespace，容量，分区）</p><p>2） 设别出基础设施及组件可以与应用名AppName建立关联关系的属性</p><ul><li>场景1： 资源没有生命周期管理，没有建立和应用之间的关系</li><li>场景2：没有同意应用名，使得各个平台之间形成孤岛</li></ul><h2 id="2-运维体系建设"><a href="#2-运维体系建设" class="headerlink" title="2. 运维体系建设"></a>2. 运维体系建设</h2><p><strong>标准先行！！！</strong></p><p>标准化的过程实际山就是对象的识别和建模过程。形成统一的对象模型之后，各方在统一的认识下展开有效协同，然后针对不同的运维对象，抽取出它们对应的运维场景，接下来才是运维场景的自动化实现。</p><p>运维脱离对象，就没有任何意义。同样，没有理清楚对象，运维自然不得章法。</p><p><strong>标准化步骤：</strong></p><pre><code>1) 识别对象2) 识别对象属性3) 识别对象关系4) 识别对象场景a) 基础设施标准化    1) 识别对象：服务器，网络，IDC，机柜，存储，配件等    2) 识别对象属性：服务器（SN序列号，IP,厂商）；硬件配置（CPU,内存，硬盘，网卡，PCIE, BIOS）; 网络设备(厂商，型号，参数等)    3) 识别对象关系：服务器所在机柜； 虚拟机所在宿主机；机柜所在IDC 等。。拓扑结构    4) 识别对象场景： 服务器为例，日常操作：采购，入库，安装，配置，上线，下线，维修。。可视化/查询/拓扑/动态展示/级联关系/健康状态b) 应用层面的标准化    1) 识别对象：微服务在“设计阶段”被识别和确认    2) 识别对象属性：一个应用是业务逻辑的抽象    ○ 业务属性    ○ 运维属性        i. 应用元数据属性：应用名，Owner，所属业务，功能说明等        ii. 应用代码属性：语言，版本，GitLab地址        iii. 应用的部署模式： 软件包/容器        iv. 应用的目录信息，日志目录/运维脚本目录/安装目录等        v. 应用的运行脚本，如启停，监控检测脚本        vi. 应用运行时的配置参数，如端口，JVM 参数等    3) 识别对象关系        i. 应用与基础设施        ii. 应用与应用之间关系 -e.g. API依赖        iii. 应用与中间件关系    4) 识别应用场景：持续集成，持续发布，扩容，缩容，监控，容量评估，压测，限流降级  </code></pre><p><strong>运维职责：</strong></p><pre><code>- 基础架构标准化    --&gt;-选型- 基础架构服务标准化       - 基于基础架构工具原生能力进行“封装”，e.g. 创建/申请容量，扩容/缩容，服务发现/访问路由配置，监控指标，主备切换能力1. 参与制定基础架构标准并对标准进行强制约束2. 基础架构的服务化平台开发    - 平台自主化，让开发人员依赖平台能力自助完成对基础组件的需求，二不是依赖运维人员    - 如果不朝着“服务化”方向发展，运维将始终被拖累在基础组件的运维操作上</code></pre><p>应用运维体系建设： 从应用的生命周期的视角看</p><pre><code>1. 应用的创建阶段：应用需要用到哪些基础服务，在架构设计和编码阶段就要确定下来2. 应用的研发阶段：应用的持续集成体系3. 应用的上线阶段：申请应用所需服务器资源，发布软件包使其上线4. 应用的运行阶段（最核心，最重要）： 各项运行指标 -监控/报警体系      - 业务需求不断变化，需要不断“迭代更新”线上应用，依然依赖研发阶段的持续集成，并最终与线上发布形成持续交付这样的闭环体系      - 应用之间的依赖管理和链路追踪的场景      - 外部业务量的各种异常变化 （双11， 热点事件，服务器/IDC/数据库 故障） -线上稳定性保障5. 应用的销毁阶段： 清理资源，取决于最前面应用与基础服务关系模型分析和建设是否到位</code></pre><h2 id="3-配置管理数据库（CMDB）"><a href="#3-配置管理数据库（CMDB）" class="headerlink" title="3. 配置管理数据库（CMDB）"></a>3. 配置管理数据库（CMDB）</h2><p>当识别出运维对象之间的关系，并形成了统一的标准之后，就需要通过某个信息管理平台“固化”，这就是CMDB (Configuration Management DataBase).</p><p>CMDB源于20世纪80年代末的ITIL，源于传统IT运维阶段，但发扬光大确实新兴的互联网行业。</p><p>CMDB 是一个”高度定制化”的体系, 没有统一的标准。</p><p>传统运维阶段，更多是以“设备”为核心进行管理；但是到了互联网技术阶段，核心变成了“应用”</p><pre><code>- 应用名---应用配置信息- IP--资源信息 </code></pre><p>二者通过“应用名-IP”的对应关系联系在一起</p><p>CMDB是运维的基石，但是需要把精力放在运维的核心“应用”上来 - CMDB是面向“资源”的管理，应用配置是面向“应用”的管理</p><p>CMDB中如何落地应用，以及如何建立应用集群分组<br>    - 产品线 -业务团队-应用<br>    - 多环境/多IDC/多服务分组</p><p>应用-集群服务分组-资源</p><h2 id="4-运维组织架构与模式"><a href="#4-运维组织架构与模式" class="headerlink" title="4. 运维组织架构与模式"></a>4. 运维组织架构与模式</h2><pre><code>1. 运维基础平台体系建设 -CMDB,DNS管理，资源管理，偏运维自身体系建设2. 分布式中间件的服务化建设3. 持续交付体系建设 -依赖于上面两个基础体系的建设4. 稳定性体系建设 -快速定位/快付故障恢复/评估扩容5. 技术运营体系建设 -标准，指标，规则和流程  -意识</code></pre><p>跨团队协作 -1. 运维团队主动出击，沟通推进； 2. 上层支持`</p><p>Google SRE 运维模式</p><p>对SRE职责定义-负责可用性，时延，性能，效率，变更管理，监控，应急响应和容量管理等相关工作。—-&gt;”效率” 和“稳定”</p><p>CRE/云计算/AI -新的挑战 -应用运维的转型</p><h2 id="5-持续交付"><a href="#5-持续交付" class="headerlink" title="5. 持续交付"></a>5. 持续交付</h2><p>配置管理</p><pre><code>- 版本控制- 依赖管理    ○ Mavn/Ant/Gradle  建立本地Maven 源，构建时候优先从本地获取依赖包，本地源没有对应依赖时，从公网下载，同时缓存到本地- 软件配置    ○ 代码配置 -与代码运行时业务逻辑有关    ○ 应用配置 -与环境有关 （部署环境/不同机房：平台类为主；私有部署到不同客户）        § 构建配置：编程语言，构建方式。。        § 部署配置：日志目录，脚本目录。。        § 运行配置：应用启停，服务上下线，健康监测方式等        § 应用运行时与基础组件关系：依赖的数据库，缓存，消息队列等。- 环境配置 -持续交付的重中之重，最复杂的部分</code></pre><p>多环境配置管理</p><pre><code>- 开发环境- 集成环境- 预发环境- Beta环境（灰度，金丝雀）- 线上环境</code></pre><p>环境配置管理主要时针对应用对于基础设施和基础服务依赖关系的配置管理</p><p>解决方案</p><pre><code>1. 多个配置文件，构建时替换    a. 开发环境： dev_config.properties    b. 预发环境：pre_config.properties    c. 线上环境：online_cofnig.properties    这三个配置文件里的“配置项”时相同的，根据不同环境，值时不同的。 构建时，根据选定的环境对配置文件进行替换- 优点：简单直接，适合配置项变化不大情况- 缺点：没多出一个环境，就要加一个配置文件，如果配置项不断变化，管理很麻烦； 不同环境单独构建，多次打包2. 占位符（Placeholder）模板模式- 配置项的值用“变量”替换- 只保留一个config.properties；但是变量的值可能要多份- 没有解决只打包一次问题3. AutoConfig 方案- 阿里巴巴开发的Webx框架中的一个工具包，继承了Maven的配置管理方式，同时可以作为插件直接与Maven配合工作    ○ 配置校验：对与替换的值做校验，提前发现问题    ○ 只打包一次    ○ 需要基于AutroConfig 做二次开发</code></pre><p>比较敏感的配置信息（如用户名，Token，密码等）不允许放在配置文件，跟不允许明文方式</p><p>多环境建设</p><pre><code>- 1. 线下环境分类建设    ○ 不必建设多个相同的，尽量最小化    ○ 开发/测试使用环境冲突，同一应用不同版本/项目团队冲突集成测试环境- 最大程度与线上版本同步，也为开发测试环境和项目环境提供部分依赖服务开发测试环境- 偏向日常的需求开发，联调和功能验证，以最小化原则进行建设项目环境- 适用于多团队多个项目，遵循最小化原则，项目启动分配资源，结束时回收资源技术点： 网段规划（每个环境独立网段）；服务化框架的单元化调用；DNS访问策略；自动化管理- 2. 线上环境建设    ○ 生产环境- 无法百分之百模拟真实的用户场景    ○ Beta环境    ○ 预发环境    ○ 办公室生产环境</code></pre><p>持续交付流水线</p><pre><code>- 持续交付建立在上面多环节以及配置管理的基础上1. 项目需求分解- 确定多个应用的联调，测试和最终发布的计划和协同，依赖关系2. 代码提交方式 -分支策略选择3. 应用的构建  - 静态语言/动态语言    ○ 配置文件如何打包？构建时，确认部署的环境    ○ 使用docker作为编译环境</code></pre><p>发布策略- 蓝绿发布，灰度发布（金丝雀），滚动发布</p>]]></content>
      
      
      <categories>
          
          <category> 读书 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SRE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DevOps 我们都在路上</title>
      <link href="2019/11/15/hello-devops/"/>
      <url>2019/11/15/hello-devops/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么会有这个博客"><a href="#为什么会有这个博客" class="headerlink" title="为什么会有这个博客"></a>为什么会有这个博客</h2><p>工作很多年了，一直从事与持续交付，版本上线发布相关的工作，从最初连什么是“daily build”都不知道，到慢慢接触到持续集成，devops等，随着经验的积累，对devops有了一定的理解，也确定了自己今后的专注的方向。随之而来，SRE，运维慢慢进入我的视野，对于产品上线后的保障监控，我还是新手，也在慢慢学习。近几年云计算和容器的发展，促进了运维的发展，这些都是我看好的方向。</p><p>所以希望对过去的经验和知识进行总结，分享出来，这些都来自于平时在OneNote，有道笔记的积累，算是对过去知识体系的重新梳理。</p><h2 id="后面会写点什么"><a href="#后面会写点什么" class="headerlink" title="后面会写点什么"></a>后面会写点什么</h2><p>主要会围绕DevOps/Cloud相关话题展开，也会涉及其他技术栈、工具。同时也会同步分享到公众号【DevOps在路上】</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20200928223309.jpg"></p><p><strong>微信公众号【DevOps在路上】</strong></p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20200928230236.jpeg"></p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DevOps 工具</title>
      <link href="2019/10/02/devops-gong-ju/"/>
      <url>2019/10/02/devops-gong-ju/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20200928233152.png" alt="devops-tools"></p><h2 id="版本控制-amp-协作开发"><a href="#版本控制-amp-协作开发" class="headerlink" title="版本控制&amp;协作开发"></a>版本控制&amp;协作开发</h2><ul><li><p>版本控制系统 Git</p><p>  Git 是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。</p></li><li><p>代码托管平台 GitLab</p><p>  GitLab 是一个利用 Ruby on Rails 开发的开源应用程序，实现一个自托管的Git项目仓库，可通过Web界面进行访问公开的或者私人项目。开源中国代码托管平台 git.oschina.net 就是基于 GitLab 项目搭建。</p></li><li><p>代码评审工具 Gerrit</p><p>  Gerrit 是一个免费、开放源代码的代码审查软件，使用网页界面。利用网页浏览器，同一个团队的软件程序员，可以相互审阅彼此修改后的程序代码，决定是否能够提交，退回或者继续修改。它使用 Git 作为底层版本控制系统。</p></li><li><p>版本控制系统 Mercurial</p><p>  Mercurial 是一种轻量级分布式版本控制系统，采用 Python 语言实现，易于学习和使用，扩展性强。</p></li><li><p>版本控制系统 Subversion</p><p>  Subversion 是一个版本控制系统，相对于的 RCS、CVS，采用了分支管理系统，它的设计目标就是取代CVS。互联网上免费的版本控制服务多基于Subversion。</p></li><li><p>版本控制系统 Bazaar</p><p>  Bazaar 是一个分布式的版本控制系统，它发布在 GPL 许可协议之下，并可用于 Windows、GNU/Linux、UNIX 以及 Mac OS 系统。</p></li></ul><h2 id="包-amp-产品管理工具"><a href="#包-amp-产品管理工具" class="headerlink" title="包&amp;产品管理工具"></a>包&amp;产品管理工具</h2><ul><li><p>Chocolatey：Chocolatey是Windows下一款开源的命令行包管理软件 ，简单说这就是Windows的apt-get；</p></li><li><p>WiX Toolset：提供一组最强大的工具集来帮助你创建Windows安装包。该工具集从XML源代码构建你的Windows安装程序包，可以无缝集成到构建过程；</p></li></ul><h2 id="自动化构建和测试"><a href="#自动化构建和测试" class="headerlink" title="自动化构建和测试"></a>自动化构建和测试</h2><ul><li><p>Apache Ant<br>  Apache Ant是一个将软件编译、测试、部署等步骤联系在一起加以自动化的一个工具，大多用于Java环境中的软件开发。</p></li><li><p>Maven<br>  Maven 除了以程序构建能力为特色之外，还提供 Ant 所缺少的高级项目管理工具。由于 Maven 的缺省构建规则有较高的可重用性，所以常常用两三行 Maven 构建脚本就可以构建简单的项目，而使用 Ant 则需要十几行。<br>  事实上，由于 Maven 的面向项目的方法，许多 Apache Jakarta 项目现在使用 Maven，而且公司项目采用 Maven 的比例在持续增长。开源中国的<a href="http://maven.oschina.net/">Maven 库</a></p></li><li><p>Selenium<br>Selenium (SeleniumHQ) 是 thoughtworks公司的一个集成测试的强大工具。</p></li><li><p>PyUnit<br>Python单元测试框架（The Python unit testing framework），简称为PyUnit， 是Kent Beck和Erich Gamma这两位聪明的家伙所设计的 JUnit 的Python版本。</p></li><li><p>QUnit<br>QUnit 是 jQuery 的单元测试框架。</p></li><li><p>JMeter<br>JMeter 是 Apache 组织的开放源代码项目，它是功能和性能测试的工具，100% 的用 java 实现。</p></li><li><p>Gradle<br>Gradle 就是可以使用 Groovy 来书写构建脚本的构建系统，支持依赖管理和多项目，类似 Maven，但比之简单轻便。</p></li><li><p>PHPUnit<br>PHPUnit 是一个轻量级的PHP测试框架。它是在PHP5下面对JUnit3系列版本的完整移植，是xUnit测试框架家族的一员(它们都基于模式先锋Kent Beck的设计)。</p></li></ul><h2 id="持续集成-amp-交付"><a href="#持续集成-amp-交付" class="headerlink" title="持续集成&amp;交付"></a>持续集成&amp;交付</h2><ul><li><p>Jenkins<br>  Jenkins 是一个开源的持续集成工具，使用 Java 编程语言编写的。它有助于实时检测和报告较大代码库中的单一更改。该软件可帮助开发人员快速查找和解决代码库中的问题并自动测试其构建。</p></li><li><p>Travis CI<br>  Travis 是一款流行的 CI 工具，可免费用于开源项目。在托管时，不必依赖任何平台。此 CI 工具为许多构建配置和语言提供支持，如 Node，PHP，Python，Java，Perl 等。</p></li><li><p>GoCD<br>  GoCD 是一个开源的持续集成服务器。它可轻松模拟和可视化复杂的工作流程。此 CI 工具允许持续交付，并为构建 CD Pipeline 提供直观的界面。</p></li><li><p>Bamboo<br>  Bamboo 是一个持续集成的构建服务器，可以自动构建、测试和发布，并可与 JIRA 和 Bitbucket 无缝协作。Bamboo 支持多语言和平台，如 CodeDeply、Ducker、Git，SVN、Mercurial、AWS 及 Amazon S3 bucket</p></li><li><p>GitLab CI<br>  GitLab CI 是 GitLab 的一部分。它是一个提供 API 的 Web 应用程序，可将其状态存储在数据库中。GitLab CI 可以管理项目并提供友好的用户界面，并充分利用 GitLab 所有功能</p></li></ul><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><ul><li><p>Chef<br>  Chef 是一个系统集成框架，为整个架构提供配置管理功能。</p></li><li><p>Puppet<br>  Puppet，您可以集中管理每一个重要方面，您的系统使用的是跨平台的规范语言，管理所有的单独的元素通常聚集在不同的文件，如用户， CRON作业，和主机一起显然离散元素，如包装，服务和文件。</p></li><li><p>RunDeck<br>  RunDeck 是用 Java/Grails 写的开源工具，帮助用户在数据中心或者云环境中自动化各种操作和流程。通过命令行或者web界面，用户可以对任意数量的服务器进行操作，大大降低了对服务器自动化的门槛。</p></li><li><p>Saltstack<br>  Saltstack 可以看做是func的增强版+Puppet的弱化版。使用Python编写。非常好用,快速可以基于EPEL部署。Salt 是一个开源的工具用来管理你的基础架构，可轻松管理成千上万台服务器。</p></li><li><p>Ansible<br>  Ansible 提供一种最简单的方式用于发布、管理和编排计算机系统的工具，你可在数分钟内搞定。Ansible 是一个模型驱动的配置管理器，支持多节点发布、远程任务执行。默认使用 SSH 进行远程连接。无需在被管理节点上安装附加软件，可使用各种编程语言进行扩展。</p></li></ul><h2 id="日志监控"><a href="#日志监控" class="headerlink" title="日志监控"></a>日志监控</h2><ul><li><p>Logstash<br>Logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。</p></li><li><p>CollectD<br>Collectd 是一个守护(daemon)进程，用来收集系统性能和提供各种存储方式来存储不同值的机制。比如以RRD 文件形式。</p></li><li><p>StatsD<br>StatsD 是一个简单的网络守护进程，基于 Node.js 平台，通过 UDP 或者 TCP 方式侦听各种统计信息，包括计数器和定时器，并发送聚合信息到后端服务，例如 Graphite。</p></li><li><p>Nagios<br>Nagios 是一个监视系统运行状态和网络信息的监视系统。Nagios能监视所指定的本地或远程主机以及服务，同时提供异常通知功能等。</p></li><li><p>Ganglia<br>Ganglia 是一个跨平台可扩展的，高 性能计算系统下的分布式监控系统，如集群和网格。它是基于分层设计，它使用广泛的技术，如XML数据代表，便携数据传输，RRDtool用于数据存储和可视化。</p></li><li><p>Sensu<br>Sensu 是开源的监控框架。主要特性：高度可组合；提供一个监控代理，一个事件处理器和文档 APIs；为云而设计；Sensu 的现代化架构允许监控大规模的动态基础设施，能够通过复杂的公共网络监控几千个全球分布式的机器和服务；热情的社区。</p></li><li><p>Zabbix<br>Zabbix 是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。</p></li><li><p>ICINGA<br>ICINGA 项目是 由Michael Luebben、HendrikB?cker和JoergLinge等人发起的，他们都是现有的Nagios项目社区委员会的成员，他们承诺，新的开源项 目将完全兼容以前的Nagios应用程序及扩展功能。</p></li><li><p>Graphite<br>Graphite 是一个用于采集网站实时信息并进行统计的开源项目，可用于采集多种网站服务运行状态信息。Graphite服务平均每分钟有4800次更新操作。</p></li><li><p>Kibana<br>Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作</p></li></ul><h2 id="微服务-容器平台"><a href="#微服务-容器平台" class="headerlink" title="微服务/容器平台"></a>微服务/容器平台</h2><ul><li><p>OpenShift<br>OpenShift 是由红帽推出的一款面向开源开发人员开放的平台即服务(PaaS)。 OpenShift通过为开发人员提供在语言、框架和云上的更多的选择，使开发人员可以构建、测试、运行和管理他们的应用。</p></li><li><p>Cloud Foundry<br>Cloud Foundry 是VMware于2011年4月12日推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发 人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题。</p></li><li><p>Kubernetes<br>Kubernetes 是来自 Google 云平台的开源容器集群管理系统。基于 Docker 构建一个容器的调度服务。该系统可以自动在一个容器集群中选择一个工作容器供使用。其核心概念是 Container Pod。</p></li><li><p>Mesosphere<br>Apache Mesos 是一个集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享，可以运行Hadoop、MPI、Hypertable、Spark。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JumpServer 架构浅解</title>
      <link href="2019/08/16/jumpserver-jia-gou/"/>
      <url>2019/08/16/jumpserver-jia-gou/</url>
      
        <content type="html"><![CDATA[<p>Jumpserver 是一款由python编写开源的跳板机(堡垒机)系统，实现了跳板机应有的功能。基于ssh协议来管理，客户端无需安装agent。完全开源，GPL授权 </p><h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><ul><li><p>设计一个跳转网关，所有登录操作都从网关通过<br>网关具有模拟终端的功能，透明的中转ssh命令，以支持Tab,Ctrl+A,Ctrl-E等快捷键，网关既可以记录操作日志，又可以审计操作命令。</p></li><li><p>设计一个认证模块<br>为了实现认证功能，需要有个认证模块，认证信息存到数据库，用户使用跳板机首先需要认证。</p></li><li><p>设计一个授权框架<br>授权是跳板机不可缺少的部分，授权就是用户和资产的关系，将关系保存的数据库，用户登录主机需要先查授权。</p></li><li><p>设计审计模块<br>审计是为了追踪，我们支持了在线监控，命令统计，录像回放功能，供管理员审查。</p></li><li><p>用户和主机模块<br>跳板机脱离不了用户和主机，所以这两个部分是基本的模块，另外我们将主机模块扩展，实现基本CMDB功能。</p></li><li><p>Web Terminal<br>现在都流行Web操作一切，于是我们又实现了Web Terminal，供用户直接在线链接服务器，这里实现是用了Tornado来完成的，Tornado实现WebSocket特别简单。</p></li></ul><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://upload-images.jianshu.io/upload_images/2504773-75dee68102104552.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="20200526180743745_415773244.png"></p><h2 id="组件说明"><a href="#组件说明" class="headerlink" title="组件说明"></a>组件说明</h2><ul><li><p><strong>Jumpserver</strong> 为管理后台, 管理员可以通过 Web 页面进行资产管理、用户管理、资产授权等操作, 用户可以通过 Web 页面进行资产登录, 文件管理等操作是核心组件（Core）, 使用 Django Class Based View 风格开发，支持 Restful API</p></li><li><p><strong>Luna</strong> 为 Web Terminal Server 前端页面, 用户使用 Web Terminal 方式登录所需要的组件 （ WebTerminalView ）<br>该组件由团队自己通过Angular 实现，Jumpserver 只提供 API，不再负责后台渲染html等。</p></li><li><p><strong>Koko(CoCo)</strong> 为 SSH Server 和 Web Terminal Server 。用户可以使用自己的账户通过 SSH 或者 Web Terminal 访问 SSH 协议和 Telnet 协议资产。KoKo(最新版)是go版本的coco，新的Jumpserver ssh/ws server, 重构了 coco 的 SSH/SFTP 服务和 Web Terminal 服务 （ WebSFTPView ）</p><p>SSH/SFTP/web terminal/web文件管理 （ WebSFTPView ）<br>实现了 SSH Server 和 Web Terminal Server 的组件，提供 SSH 和 WebSocket 接口, 使用 Paramiko 和 Flask 开发</p></li><li><p><strong>Guacamole</strong> 为 RDP 协议和 VNC 协议资产组件, 用户可以通过 Web Terminal 来连接 RDP 协议和 VNC 协议资产 (暂时只能通过 Web Terminal 来访问)<br><a href="http://guacamole.apache.org/">Guacamole</a> Apache 跳板机项目，Jumpserver 使用其组件实现 RDP 功能，Jumpserver 并没有修改其代码而是添加了额外的插件，支持 Jumpserver 调用。</p></li><li><p>Jumpserver-Python-SDK<br><a href="https://github.com/jumpserver/jumpserver-python-sdk">Jumpserver Python SDK</a>，(KoKo)Coco 目前使用该 SDK 与 Jumpserver API 交互。</p><p>为 Jumpserver ssh terminal 和 web terminal封装了一个sdk, 完成和Jumpserver 交互的一些功能</p><ul><li>Service 通用RestApi 接口类</li><li>AppService 增加了app注册等</li><li>UserService 用户使用该类</li></ul></li><li><p><strong>jms-storage-sdk</strong><br>主要作为录像存储的工具类，支持本地或其他cloud存储（e.g. oss）</p></li></ul><h3 id="端口说明"><a href="#端口说明" class="headerlink" title="端口说明"></a>端口说明</h3><ul><li><p>Jumpserver 默认端口为 8080/tcp 配置文件 jumpserver/config.yml</p></li><li><p>KoKo(Coco) 默认 SSH 端口为 2222/tcp, 默认 Web Terminal 端口为 5000/tcp 配置文件在 KoKo(CoCo)/config.yml</p></li><li><p>Guacamole 默认端口为 8081/tcp, 配置文件 /config/tomcat9/conf/server.xml</p></li><li><p>Nginx 默认端口为 80/tcp</p></li><li><p>Redis 默认端口为 6379/tcp</p></li><li><p>Mysql 默认端口为 3306/tcp</p></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/2504773-34fe231919ab8bd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="20200526180806315_1173897932.png"></p><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><h3 id="使用技术"><a href="#使用技术" class="headerlink" title="使用技术"></a>使用技术</h3><ul><li>Python 3.6.1</li><li>Django</li><li>Angular (Luna)</li><li>go （koko）</li><li>Celery  <a href="http://www.celeryproject.org/">http://www.celeryproject.org/</a></li><li>Redis   cache 和 celery broke</li><li>Flower - Celery monitoring tool</li><li>Guacamole (webterminal -RDP)</li><li>websoket 框架 （<a href="https://github.com/kataras/neffos%EF%BC%89">https://github.com/kataras/neffos）</a></li></ul><h3 id="服务启动"><a href="#服务启动" class="headerlink" title="服务启动"></a>服务启动</h3><p><code>./jms start</code> 命令将会下面服务</p><p><img src="https://upload-images.jianshu.io/upload_images/2504773-baf73e869ebd006a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="20200528102354700_861856403.png"></p><ul><li><p>gunicorn  - unix系统的wsgi http服务器，负责jsm-core的http请求</p></li><li><p>Daphne  - 支持HTTP, HTTP2 和 WebSocket 的asgi的服务器，主要处理WebSocket请求</p></li><li><p>celery - 后台异步任务分发处理 -celery_ansible/celery_default<br>简单、灵活且可靠的，处理大量消息的分布式系统；专注于实时处理的异步任务队列，同时也支持任务调度</p></li><li><p>flower - 负责监控 celery worker执行情况</p></li></ul><h2 id="Web-Terminal"><a href="#Web-Terminal" class="headerlink" title="Web Terminal"></a>Web Terminal</h2><ul><li>主要通过Luna，koko 和Guacamole实现</li></ul><h3 id="Luna"><a href="#Luna" class="headerlink" title="Luna"></a>Luna</h3><ul><li><p>打开web terminal link 后，进入luna, luna 会通过api请求jms 的资源列表，进行树状展示</p></li><li><p>当需要进行RDP访问时，会向guacamole进行post请求 <code>/guacamole/api/session/ext/jumpserver/asset/add</code></p></li><li><p>使用 mstsc.js 实现web版的javascript RDP client  -<a href="https://github.com/citronneur/mstsc.js">https://github.com/citronneur/mstsc.js</a> (很老的框架)<br>使用 socket.io 和画布来绑定 mstsc.js 后端。 前端通过 rle.js 文件完成位图的解压缩</p></li><li><p>webterminal 前端由luna 里的html5 canvas 和js 渲染出来</p></li><li><p>Luna 使用了 “guacamole-common-js”: “1.1.0”， 提供了 Guacamole client的实现<br>  <a href="http://guacamole.apache.org/doc/guacamole-common-js/">http://guacamole.apache.org/doc/guacamole-common-js/</a></p><pre class="line-numbers language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>window<span class="token punctuation">"</span></span> <span class="token attr-name">[ngClass]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>&amp;#123;<span class="token punctuation">'</span>active<span class="token punctuation">'</span>:view.active&amp;#125;<span class="token punctuation">"</span></span><span class="token style-attr language-css"><span class="token attr-name"> <span class="token attr-name">style</span></span><span class="token punctuation">="</span><span class="token attr-value"><span class="token property">height</span><span class="token punctuation">:</span> <span class="token number">100%</span></span><span class="token punctuation">"</span></span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>elements-ssh-term</span>    <span class="token attr-name">[view]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view<span class="token punctuation">"</span></span>    <span class="token attr-name">[host]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.host<span class="token punctuation">"</span></span>    <span class="token attr-name">[sysUser]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.user<span class="token punctuation">"</span></span>    <span class="token attr-name">*ngIf</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.type<span class="token punctuation">=</span><span class="token punctuation">=</span><span class="token punctuation">'</span>ssh<span class="token punctuation">'</span><span class="token punctuation">"</span></span>  <span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>elements-ssh-term</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>elements-guacamole</span>    <span class="token attr-name">[view]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view<span class="token punctuation">"</span></span>    <span class="token attr-name">[host]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.host<span class="token punctuation">"</span></span>    <span class="token attr-name">[sysUser]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.user<span class="token punctuation">"</span></span>    <span class="token attr-name">[remoteAppId]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.remoteApp<span class="token punctuation">"</span></span>    <span class="token attr-name">*ngIf</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.type<span class="token punctuation">=</span><span class="token punctuation">=</span><span class="token punctuation">'</span>rdp<span class="token punctuation">'</span><span class="token punctuation">"</span></span>  <span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>elements-guacamole</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>app-sftp</span> <span class="token attr-name">*ngIf</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.type<span class="token punctuation">=</span><span class="token punctuation">=</span><span class="token punctuation">'</span>sftp<span class="token punctuation">'</span><span class="token punctuation">"</span></span> <span class="token attr-name">[host]</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>view.host<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>app-sftp</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="koko-ssh）"><a href="#koko-ssh）" class="headerlink" title="koko(ssh）"></a>koko(ssh）</h3><ul><li><p>老版本coco使用ssh python 库- Paramiko</p></li><li><p>koko 启动时候会注册到jms, 需要配置中 “BOOTSTRAP_TOKEN” 与jump server保持一致, 用于身份认证</p></li><li><p>启动之后将会监听，当有新的ssh terminal窗口打开，就会尝通过websocket 建立ssh 连接 (依赖于Daphne），基于<a href="https://github.com/gorilla/websocket">go的websocket实现</a></p></li><li><p>用户在web terminal 窗口操作时，koko 会对命令解析，和jms里的过滤规则匹配</p></li><li><p>连接中断后，开始上传录像(其实是json文件，记录了时序log)到jumpserver(/data/media)</p></li><li><p>使用了websoket 框架 - <a href="https://github.com/kataras/neffos">https://github.com/kataras/neffos</a></p><p>   <img src="https://upload-images.jianshu.io/upload_images/2504773-a244bfa8cd68b787.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="20200527094248561_866134588.png"></p></li></ul><h3 id="Guacamole-rdp"><a href="#Guacamole-rdp" class="headerlink" title="Guacamole(rdp)"></a>Guacamole(rdp)</h3><ul><li>对Apache Guacamole 进行了改造，主要是Guacamole client/server war包，看不到源码改造</li><li>原生的Guacamole 本身可以单独提供 web terminal 服务，但是部署相对复杂，有单独的postgresql存储机器连接信息</li><li>改造后的Guacamole ()，也需要通过 BOOTSTRAP_TOKEN 注册到 jms</li></ul><h3 id="操作录像回放"><a href="#操作录像回放" class="headerlink" title="操作录像回放"></a>操作录像回放</h3><ul><li><p>操作的录制:   ssh 是由koko基于websocket data完成; rdp 是由Guacamole API 完成</p></li><li><p>操作的回放：由 luna进行 replay 展示的，对ssh 录像(.json) 进行分割处理,使用js渲染成动画;</p><pre><code>&lt;elements-replay-json [replay]=&quot;replay&quot; *ngIf=&quot;replay.type==&#39;json&#39;&quot;&gt;&lt;/elements-replay-json&gt;&lt;elements-replay-guacamole [replay]=&quot;replay&quot; *ngIf=&quot;replay.type==&#39;guacamole&#39;&quot;&gt;&lt;/elements-replay-guacamole&gt;</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> SRE运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JumpServer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown 教程</title>
      <link href="2019/07/02/markdown-guide/"/>
      <url>2019/07/02/markdown-guide/</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>Markdown 是一种简单的、轻量级的标记语法。用户可以使用诸如 * # 等简单的标记符号以最小的输入代价生成极富表现力的文档。</p><p>Markdown具有很多优点：</p><ul><li>写作中添加简单符号即完成排版，所见即所得。让你专注于文字而不是排版。</li><li>格式转换方便，Markdown 的文本你可以轻松转换为 html、pdf等。</li><li>可以保存成纯文本</li></ul></blockquote><h2 id="1-标题"><a href="#1-标题" class="headerlink" title="1. 标题"></a>1. 标题</h2><p>标题能显示出文章的结构。行首插入1-6个# ，每增加一个#表示更深入层次的内容，对应到标题的深度由 1-6 阶。</p><p>注：标准语法一般在#后跟个空格再写文字</p><p><strong>示例：</strong></p><pre class="line-numbers language-text"><code class="language-text">Atx风格# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>除此之外，Markdown还支持另外一种标题展示形式，使用下划线进行文本大小的控制</p><pre class="line-numbers language-text"><code class="language-text">SetText风格这是一级标题===这是二级标题---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用这种方式处理标题仅有两种表现形式，即一级标题和二级标题</p><h2 id="2-字体"><a href="#2-字体" class="headerlink" title="2. 字体"></a>2. 字体</h2><h3 id="2-1-基本样式"><a href="#2-1-基本样式" class="headerlink" title="2.1 基本样式"></a>2.1 基本样式</h3><p>要加粗的文字左右分别用两个<em>号包起来<br> \</em>*加粗**</p><p>要倾斜的文字左右分别用一个<em>号包起来<br>\</em>斜体*</p><p>要倾斜和加粗的文字左右分别用三个<em>号包起来<br>\</em>**斜体加粗***</p><p>要加删除线的文字左右分别用两个<del>号包起来<br>\</del>~删除线~~</p><p>要加删除线的文字左右分别用两个==号包起来<br>==高亮==</p><p><strong>示例：</strong><br><strong>这是加粗的文字</strong><br><em>这是倾斜的文字</em>`<br><strong><em>这是斜体加粗的文字</em></strong><br><del>这是加删除线的文字</del><br>==这是加粗的文字==  </p><h3 id="2-2-常用转义字符"><a href="#2-2-常用转义字符" class="headerlink" title="2.2 常用转义字符"></a>2.2 常用转义字符</h3><p>MarkDown利用了很多特殊符号标识语法，但在需要输入这些符号就需要利用转义字符来控制，避免MarkDown语法解析。</p><pre class="line-numbers language-text"><code class="language-text">\\ 反斜杠\` 反引号\* 星号\_ 下划线\&#123;\&#125; 大括号\[\] 中括号\(\) 小括号\# 井号\+ 加号\- 减号\. 英文句号\! 感叹号<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-添加空格"><a href="#2-3-添加空格" class="headerlink" title="2.3 添加空格"></a>2.3 添加空格</h3><p>跟word等其他编辑器不同，Markdown只能识别一个空格（在半角输入状态下）, 有下面两个解决方案。</p><ul><li><p>手动输入空格 （&amp;nbsp；）。<strong>注意！</strong>此时的分号为英文分号，但是不推荐使用此方法，太麻烦！</p></li><li><p>使用全角空格。即：在全角输入状态下直接使用空格键就ok了</p></li></ul><h3 id="2-4-字体颜色"><a href="#2-4-字体颜色" class="headerlink" title="2.4 字体颜色"></a>2.4 字体颜色</h3><p>使用Markdown的同学最郁闷的地方恐怕就是不能给文字添加颜色了。事实上，Markdown的最初目标就是为纯写作而生的。因此，它并没有考虑文字颜色这一点。所以，单纯使用Markdown设置文字颜色已经做不到了。但你可以这样做：</p><p><strong>示例：</strong><br><font color='#ff0000'>字体颜色</font></p><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3. 代码"></a>3. 代码</h2><p><strong>语法：</strong></p><p><strong>单行代码</strong>：代码之间分别用一个反引号包起来<br>    `代码内容`</p><p><strong>代码块</strong>：代码之间分别用三个反引号包起来，且两边的反引号单独占一行<br>```<br>  代码…<br>  代码…<br>  代码…<br>```</p><p><strong>示例：</strong></p><p>单行代码<br><code>create database hero;</code></p><p>代码块</p><pre class="line-numbers language-shell"><code class="language-shell">    function fun()&#123;         echo "这是一句非常牛逼的代码";    &#125;    fun();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">@requires_authorization<span class="token keyword">class</span> <span class="token class-name">SomeClass</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># A comment</span>    <span class="token keyword">print</span> <span class="token string">'hello world'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-段落-amp-引用"><a href="#4-段落-amp-引用" class="headerlink" title="4. 段落&amp;引用"></a>4. 段落&amp;引用</h2><h2 id="4-1-段落"><a href="#4-1-段落" class="headerlink" title="4.1 段落"></a>4.1 段落</h2><ul><li>换行是在行尾加两个空格 [空格 + 空格 + 回车]</li></ul><h2 id="4-2-引用"><a href="#4-2-引用" class="headerlink" title="4.2 引用"></a>4.2 引用</h2><p>Markdown提供了一个特殊符号&gt;用于段首进行强调，被强调的文字部分将会高亮显示</p><p>在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;，三个&gt;&gt;&gt;，n个…</p><p><strong>示例：</strong></p><blockquote><p>这是引用的内容</p><blockquote><p>这是引用的内容</p><blockquote><blockquote><p>这是引用的内容</p></blockquote></blockquote></blockquote></blockquote><h3 id="4-3-分割线"><a href="#4-3-分割线" class="headerlink" title="4.3 分割线"></a>4.3 分割线</h3><p>三个或者三个以上的 - 或者 * 都可以。</p><h2 id="5-插入图片-amp-链接"><a href="#5-插入图片-amp-链接" class="headerlink" title="5.  插入图片&amp;链接"></a>5.  插入图片&amp;链接</h2><h3 id="5-1-插入图片"><a href="#5-1-插入图片" class="headerlink" title="5.1 插入图片"></a>5.1 插入图片</h3><p><strong>语法：</strong></p><p><strong>Inline</strong> (titles are optional):</p><p><code>![alt text](/path/img.jpg &quot;Title&quot;)</code></p><p><strong>Reference-style:</strong></p><p><code>![alt text][id]</code></p><ul><li>alt- 就是显示在图片下面的文字，相当于对图片内容的解释。</li><li>title- 是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加</li></ul><p><strong>示例：</strong><br><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&fm=27&gp=0.jpg" alt="blockchain" title="区块链"></p><p><img src="https://www.zybuluo.com/static/img/logo.png" alt="cmd-markdown-logo"></p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20200928231653.JPG"></p><p><strong>注： 引用图片和链接的唯一区别就是在最前方添加一个感叹号。</strong></p><h3 id="5-2-插入链接"><a href="#5-2-插入链接" class="headerlink" title="5.2 插入链接"></a>5.2 插入链接</h3><p><strong>Inline:</strong><br><code>An [example](http://url.com/ &quot;Title&quot;)</code></p><p><a href="http://www.baidu.com/">点击跳转至百度</a></p><h4 id="点击跳转至必应"><a href="#点击跳转至必应" class="headerlink" title="点击跳转至必应"></a><a href="http://www.bing.com/" title="必应">点击跳转至必应</a></h4><p><strong>Reference-style labels</strong> (titles are optional):</p><p><code>An [example][id]. Then, anywhere else in the doc, define the link: [id]: http://example.com/  &quot;Title&quot;</code></p><p>I get 10 times more traffic from [Google][1] than from [Yahoo][2] or [MSN][3].</p><p><strong>Email:</strong><br>&lt;&gt;包括的URL或邮箱地址会被自动转换成为超链接</p><p><code>An email &lt;example@example.com&gt; link.</code></p><p><a href="mailto:&#x78;&#120;&#120;&#x78;&#120;&#x78;&#64;&#49;&#x32;&#x36;&#x2e;&#x63;&#x6f;&#x6d;">&#x78;&#120;&#120;&#x78;&#120;&#x78;&#64;&#49;&#x32;&#x36;&#x2e;&#x63;&#x6f;&#x6d;</a></p><h2 id="6-列表"><a href="#6-列表" class="headerlink" title="6. 列表"></a>6. 列表</h2><h2 id="6-1-无序列表"><a href="#6-1-无序列表" class="headerlink" title="6.1 无序列表"></a>6.1 无序列表</h2><p><strong>语法:</strong><br>无序列表用 - + * 任何一种都可以</p><ul><li><p>整理知识，学习笔记</p></li><li><p>发布日记，杂文，所见所想</p><ul><li>撰写发布技术文稿（无序列表内嵌列表空二个空格）</li><li>撰写发布学术论文</li></ul></li></ul><p>注意：- + *跟内容之间都要有一个空格;<strong>整篇文档无序列表符号必须一致</strong></p><h3 id="6-2-有序列表"><a href="#6-2-有序列表" class="headerlink" title="6.2 有序列表"></a>6.2 有序列表</h3><p><strong>语法：</strong><br>数字加点</p><ol><li>整理知识，学习笔记</li><li>发布日记，杂文，所见所想</li><li>撰写发布技术文稿（代码支持）</li><li>撰写发布学术论文（LaTeX 公式支持）</li></ol><p>注意：序号跟内容之间要有空格</p><h3 id="6-3-列表嵌套"><a href="#6-3-列表嵌套" class="headerlink" title="6.3 列表嵌套"></a>6.3 列表嵌套</h3><p>上一级和下一级之间敲三个空格即可</p><ol><li>Fruit<ol><li>Apple</li><li>Orange</li><li>Peach</li><li>Banana</li></ol></li><li>Vegetable</li></ol><h3 id="6-4-列表-引用"><a href="#6-4-列表-引用" class="headerlink" title="6.4 列表+引用"></a>6.4 列表+引用</h3><blockquote><ul><li>整理知识，学习笔记</li><li>发布日记，杂文，所见所想</li><li>撰写发布技术文稿（代码支持）</li><li>撰写发布学术论文（LaTeX 公式支持）</li></ul></blockquote><ul><li><p><input disabled="" type="checkbox">  支持以 PDF 格式导出文稿</p></li><li><p><input disabled="" type="checkbox">  改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率</p></li><li><p><input checked="" disabled="" type="checkbox">  新增 Todo 列表功能</p></li><li><p><input checked="" disabled="" type="checkbox">  修复 LaTex 公式渲染问题</p></li><li><p><input checked="" disabled="" type="checkbox">  新增 LaTex 公式编号功能</p></li><li><p>段落一</p><blockquote><p>This module implements a number of iterator building blocks inspired by constructs from APL, Haskell, and SML. Each has been recast in a form suitable for Python.</p></blockquote></li><li><p>段落二</p><blockquote><p>区块标记二</p></blockquote></li></ul><h2 id="7-表格"><a href="#7-表格" class="headerlink" title="7. 表格"></a>7. 表格</h2><p><strong>语法：</strong></p><pre class="line-numbers language-text"><code class="language-text">表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>注：三个短横杠左右的冒号用于控制对齐方式，只放置左边冒号表示文字居左，只放置右边冒号表示文字居右，如果两边都放置冒号表示文字居中。</p><p>示例：</p><pre class="line-numbers language-text"><code class="language-text">姓名|技能|排行:--|:--|:--刘备|哭|大哥关羽|打|二哥张飞|骂|三弟<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text"><code class="language-text">| 项目        | 价格   |  数量  || --------   | -----:  | :----:  || 计算机     | \$1600 |   5     || 手机        |   \$12   |   12   || 管线        |    \$1    |  234  |<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VS Code 使用</title>
      <link href="2019/02/27/vscode-usage/"/>
      <url>2019/02/27/vscode-usage/</url>
      
        <content type="html"><![CDATA[<h2 id="Tips-总结"><a href="#Tips-总结" class="headerlink" title="Tips 总结"></a>Tips 总结</h2><h3 id="1-VSCode显示空格和tab符号"><a href="#1-VSCode显示空格和tab符号" class="headerlink" title="1. VSCode显示空格和tab符号"></a>1. VSCode显示空格和tab符号</h3><p>1.打开setting,在搜索框中输入<code>renderControlCharacters</code>,选中勾选框,即可显示tab</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/renderControlCharacters.JPG" alt="picgo"></p><p>2.在搜索框中输入<code>renderWhitespace</code>,选择all,即可显示空格.</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/renderWhitespace.JPG"></p><h2 id="插件扩展"><a href="#插件扩展" class="headerlink" title="插件扩展"></a>插件扩展</h2><ul><li><a href="https://marketplace.visualstudio.com/VSCode">https://marketplace.visualstudio.com/VSCode</a></li></ul><h3 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h3><pre class="line-numbers language-text"><code class="language-text">- Markdown Preview Enhanced    预览与展示，以pdf文档样式的效果来显示内容，默认配置- Markdown Toc    生成目录，需要配置参数- Markdown PDF    可以简单地将编写的.md文件转换成PDF等格式的文件，设置常用配置- Markdownlint    语法规整和风格检查- Markdown Preview Github Stying    使用Github样式来渲染Markdown，朴素简洁- Markdown All in One    功能组合包，包含了书写Markdown需要用到的常用功能和设置（键盘快捷方式，目录，自动预览等），默认配置<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Common"><a href="#Common" class="headerlink" title="Common"></a>Common</h3><pre class="line-numbers language-text"><code class="language-text">- Chinese (Simplified) Language Pack for Visual Studio Code：中文界面- Git History    提供可视化的 Git 版本树管理，可通过命令面板或界面按钮激活- GitLens    增强内置Git 功能, 显示丰富的git日志，文件历史、行历史等- Visual Studio IntelliCode    微软官方提供的基于 AI 辅助的自动补全功能，支持 Python、TypeScript/JavaScript和Java语言- TabNine    强大的 AI 辅助智能补全，支持几乎所有编程语言- Code Spell Checker    代码拼写检查, 检查代码中的单词拼写错误并给出错误拼写单词的建议- Settings Sync   使用GitHub Gist同步多台计算机上的设置，代码段，主题，文件图标，启动，键绑定，工作区和扩展- Code Runner    万能语言运行环境, 不用搭建各种语言的开发环境，选中一段代码直接运行，非常适合学习或测试各种开发语言- Docker    管理本地容器- filesize    在状态栏中显示当前文件大小，点击后还可以看到详细创建、修改时间- vscode-icons    文件图标，实现对各种文件类型的文件前的图标进行优化显示，，可以直接通过文件的图标快速知道文件类型- Rainbow Brackets    为圆括号，方括号和大括号提供彩虹色- Bracket Pair Colonizer 2    彩虹括号，使用彩虹色区分标注不同的括号对- Indent-Rainbow    用四种不同颜色交替着色文本前面的缩进- Log File Highlighter    日志文件高亮，主要是针对 INFO、WARN、ERROR 高亮，方便查看日志文件- TODO Highlight    高亮显示代码中的 TODO、FIXME 及其他注解- Atuo Rename Tag    修改 html 标签，自动帮你完成头部和尾部闭合标签的同步修改- RegExp Preview and Editor    通过命令面板启动，在分栏页面中编辑正则表达式，并以数据流图可视化显示正则语法结构<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Office"><a href="#Office" class="headerlink" title="Office"></a>Office</h3><pre class="line-numbers language-text"><code class="language-text">- PDF: vscode-pdf    直接打开浏览pdf格式的二进制文件Draw.io Integration绘制流程图、脑图和UML图，新建扩展名为 .drawio、.dio 、.drawio.svg 文件即可进入编辑- https://github.com/hediet/vscode-drawio- https://marketplace.visualstudio.com/items?itemName=hediet.vscode-drawio<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Remote-Development"><a href="#Remote-Development" class="headerlink" title="Remote Development"></a>Remote Development</h3><pre class="line-numbers language-text"><code class="language-text">- Remote Development  https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack- Remote - SSH：基于 SSH 的远程开发- Remote - Containers：基于 Docker 容器的远程开发- Remote - WSL：基于 Windows Subsystem for Linux(wsl) 的远程开发<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h3><pre class="line-numbers language-text"><code class="language-text">- Beautify 代码格式化（Javascript, JSON, CSS, Sass, and HTML）- ESLint 代码检查，关注语法规则和代码风格，可以用来保证写出语法正确、风格统一的代码。- Prettier 严格基于规则的代码格式化程序, 解析代码并使用自定义规则重新打印代码，从而实现风格一致- SonarLint<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Language"><a href="#Language" class="headerlink" title="Language"></a>Language</h3><pre class="line-numbers language-text"><code class="language-text">### JavaJava Extension Pack- Debugger for Java- Language Support for Java(TM) by Red Hat- Visual Studio IntelliCode- Maven for Java- Java Test Runner- Java Dependency ViewerSpring Boot Extension Pack- Spring Boot Tools- Spring Boot Dashboard- Spring Initializer Java SupportCheckStyle for JavaJava DecompilerLombok Annotations Support### Python- Python Extension Pack- python snippets- pylint### Bash- Bash IDE- shellman- Shell-format- Bash Debug### Jenkins- JenkinsFile Support- Groovy Lint, Format and Fix<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VSCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用私有gitlab搭建gitbook持续集成</title>
      <link href="2019/01/27/gitbook-gitlab/"/>
      <url>2019/01/27/gitbook-gitlab/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><p>在项目实践中，团队需要对用到的知识技术进行总结，即便于分享，也利于传承，而gitbook就是个不错的选择，使用gitbook-cli 对Markdown文档进行编译，生成静态文件，再通过web服务器（e.g. nginx）对外提供服务。</p><p>gitbook和gitlab搭建持续集成，可实现文档的即时更新，这也是我在DevOps实践的一部分。</p><ul><li><p><a href="https://www.gitbook.com/">https://www.gitbook.com</a></p></li><li><p><a href="https://github.com/GitbookIO/gitbook">https://github.com/GitbookIO/gitbook</a></p></li></ul><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/pics/20201016234543.png"></p><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><h3 id="1-安装-Node-js"><a href="#1-安装-Node-js" class="headerlink" title="1. 安装 Node.js"></a>1. 安装 Node.js</h3><p>gitbook 是一个基于 Node.js 的命令行工具，下载安装 <a href="https://nodejs.org/en/">Node.js</a>，安装完成之后，你可以使用下面的命令来检验是否安装成功。</p><p><code>$ node -v</code></p><h3 id="2-安装-gitbook"><a href="#2-安装-gitbook" class="headerlink" title="2. 安装 gitbook"></a>2. 安装 gitbook</h3><p>输入下面的命令来安装 gitbook</p><p><code>npm install gitbook-cli -g</code></p><p>安装完成之后，你可以使用下面的命令来检验是否安装成功</p><p><code>$ gitbook -V</code></p><p>更多详情请参照 <a href="https://github.com/GitbookIO/gitbook/blob/master/docs/setup.md">gitbook 安装文档</a> 来安装 gitbook</p><h3 id="3-安装-Gitlab-Runner"><a href="#3-安装-Gitlab-Runner" class="headerlink" title="3. 安装 Gitlab Runner"></a>3. 安装 Gitlab Runner</h3><p>下载二进制包</p><p><code>sudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64</code></p><p>添加执行权限</p><p><code>sudo chmod +x /usr/local/bin/gitlab-runner</code></p><p>(可选)如果使用Docker，安装Docker</p><p><code>curl -sSL https://get.docker.com/ | sh</code></p><p>创建 GitLab CI 用户</p><p><code>sudo useradd --comment &#39;GitLab Runner&#39; --create-home gitlab-runner --shell /bin/bash</code></p><p>以Service方式安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> gitlab-runner <span class="token function">install</span> --user<span class="token operator">=</span>gitlab-runner --working-directory<span class="token operator">=</span>/home/gitlab-runner<span class="token function">sudo</span> gitlab-runner start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-注册Runner"><a href="#4-注册Runner" class="headerlink" title="4. 注册Runner"></a>4. 注册Runner</h3><ul><li><a href="https://docs.gitlab.com/runner/install/linux-manually.html">Runner安装</a>    </li><li><a href="https://docs.gitlab.com/runner/register/index.html">Runner注册</a></li></ul><p>运行以下命令</p><p><code>sudo gitlab-runner register</code></p><p>输入GitLab 实例 URL <code>Please enter the gitlab-ci coordinator URL</code></p><p>输入Gitlab注册的token (Gitlab admin权限才能看见)</p><p><code>Please enter the gitlab-ci token for this runner     xxx</code></p><p>输入Runner描述，后面可在Gitlab UI上更新</p><p><code>Please enter the gitlab-ci description for this runner</code></p><p>输入Runner Tag，后面可在Gitlab UI上更新</p><p><code>Please enter the gitlab-ci tags for this runner (comma separated):</code></p><p>选择Runner executor</p><p> <code>Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:     shell</code></p><h2 id="gitbook-配置"><a href="#gitbook-配置" class="headerlink" title="gitbook 配置"></a>gitbook 配置</h2><h3 id="1-目录结构"><a href="#1-目录结构" class="headerlink" title="1. 目录结构"></a>1. 目录结构</h3><pre class="line-numbers language-text"><code class="language-text">        .        ├── book.json        ├── README.md        ├── SUMMARY.md        ├── chapter-1/        |   ├── README.md        |   └── something.md        └── chapter-2/            ├── README.md            └── something.md<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>README.md<br>gitbook第一页内容是从文件 README.md 中提取的。如果这个文件名没有出现在 SUMMARY 中，那么它会被添加为章节的第一个条目</p></li><li><p>book.json<br>该文件主要用来存放配置信息</p></li><li><p>.bookignore<br>将读取.gitignore，.bookignore以及.ignore文件以获得文件和文件夹跳过列表</p></li><li><p>Glossary.md<br>允许指定要显示为注释的术语及其各自的定义。根据这些条款，GitBook将自动构建一个索引并突出显示这些术语</p></li><li><p>SUMMARY.md<br>用于存放GitBook的文件目录信息，左侧的目录就是根据这个文件来生成的，默认对应的文件是 SUMMARY.md，可以在 book.json 重新定义该文件的对应值。它通过Markdown中的列表语法来表示文件的父子关系</p><p><strong>注意</strong> 不被SUMMARY.md包含的文件不会被gitbook处理</p><p><strong>SUMMARY.md示例：</strong></p><pre class="line-numbers language-text"><code class="language-text"># Summary* [Introduction](README.md)* [Part I](part1/README.md)    * [Writing is nice](part1/writing.md)    * [gitbook is nice](part1/gitbook.md)* [Part II](part2/README.md)    * [We love feedback](part2/feedback_please.md)    * [Better tools for authors](part2/better_tools.md)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  通过使用 标题 或者 水平分割线 将 gitbook 分为几个不同的部分，如下所示：</p><pre class="line-numbers language-text"><code class="language-text"># Summary### Part I* [Introduction](README.md)* [Writing is nice](part1/writing.md)* [gitbook is nice](part1/gitbook.md)### Part II* [We love feedback](part2/feedback_please.md)* [Better tools for authors](part2/better_tools.md)---* [Last part without title](part3/title.md)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  目录中的章节可以使用锚点指向文件的特定部分</p><pre class="line-numbers language-text"><code class="language-text"># Summary### Part I* [Part I](part1/README.md)    * [Writing is nice](part1/README.md#writing)    * [gitbook is nice](part1/README.md#gitbook)* [Part II](part2/README.md)    * [We love feedback](part2/README.md#feedback)    * [Better tools for authors](part2/README.md#tools)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="2-命令行"><a href="#2-命令行" class="headerlink" title="2. 命令行"></a>2. 命令行</h3><ol><li><p>gitbook init</p><p> gitbook项目初始化,会自动生成两个必要的文件 README.md 和 SUMMARY.md</p></li><li><p>gitbook build [path]</p><p> 构建gitbook项目生成静态网页，会生成一个 _book 文件夹（包含了 .md 对应的.html文件）</p></li><li><p>gitbook serve</p><p>该命令实际上会首先调用 gitbook build 编译 .md，完成以后会打开一个web服务器，监听在本地的4000端口。</p><p>生产的静态文件可单独放到tomcat或者nginx供静态访问</p><pre class="line-numbers language-text"><code class="language-text">./├── _book│   ├── gitbook│   │   ├── fonts│   │   ├── gitbook.js│   │   ├── gitbook-plugin-fontsettings│   │   ├── gitbook-plugin-highlight│   │   ├── gitbook-plugin-livereload│   │   ├── gitbook-plugin-lunr│   │   ├── gitbook-plugin-search│   │   ├── gitbook-plugin-sharing│   │   ├── images│   ├── index.html│   └── search_index.json├── README.md└── SUMMARY.md<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>gitbook update #更新gitbook到最新版本</p></li><li><p>gitbook install    #安装依赖</p></li><li><p>gitbook builid –debug    #输出错误信息</p></li><li><p>gitbook build –log=debug  #指定log级别</p></li></ol><h3 id="3-插件"><a href="#3-插件" class="headerlink" title="3. 插件"></a>3. 插件</h3><p>gitbook 提供了丰富插件，默认带有 5 个插件，highlight、search、sharing、font-settings、livereload，如果要去除自带的插件， 可以在插件名称前面加 -，比如：</p><pre class="line-numbers language-bash"><code class="language-bash">        <span class="token string">"plugins"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>            <span class="token string">"-search"</span>        <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>插件使用参考</p><ul><li><a href="https://gitbook.zhangjikai.com/plugins.html">https://gitbook.zhangjikai.com/plugins.html</a></li></ul><h2 id="gitlab-与gitbook集成"><a href="#gitlab-与gitbook集成" class="headerlink" title="gitlab 与gitbook集成"></a>gitlab 与gitbook集成</h2><p><strong>.gitlab-ci.yml 示例：</strong></p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># requiring the environment of NodeJS 10</span><span class="token key atrule">image</span><span class="token punctuation">:</span> node<span class="token punctuation">:</span><span class="token number">10</span><span class="token comment" spellcheck="true"># add 'node_modules' to cache for speeding up builds</span><span class="token key atrule">cache</span><span class="token punctuation">:</span>  <span class="token key atrule">paths</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> node_modules/ <span class="token comment" spellcheck="true"># Node modules and dependencies</span><span class="token key atrule">before_script</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> npm install gitbook<span class="token punctuation">-</span>cli <span class="token punctuation">-</span>g <span class="token comment" spellcheck="true"># install gitbook</span>  <span class="token punctuation">-</span> gitbook fetch 3.2.3 <span class="token comment" spellcheck="true"># fetch final stable version</span>  <span class="token punctuation">-</span> gitbook install <span class="token comment" spellcheck="true"># add any requested plugins in book.json</span><span class="token key atrule">test</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> test  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> gitbook build . public <span class="token comment" spellcheck="true"># build to public path</span>  <span class="token key atrule">only</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> branches <span class="token comment" spellcheck="true"># this job will affect every branch except 'master'</span>  <span class="token key atrule">except</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> master<span class="token comment" spellcheck="true"># the 'pages' job will deploy and build your site to the 'public' path</span><span class="token key atrule">pages</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> deploy  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> gitbook build . public <span class="token comment" spellcheck="true"># build to public path</span>  <span class="token key atrule">artifacts</span><span class="token punctuation">:</span>    <span class="token key atrule">paths</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> public    <span class="token key atrule">expire_in</span><span class="token punctuation">:</span> 1 week  <span class="token key atrule">only</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> master <span class="token comment" spellcheck="true"># this job will affect only the 'master' branch</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://www.chengweiyang.cn/gitbook/index.html">http://www.chengweiyang.cn/gitbook/index.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gitbook, gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 后台运行进程</title>
      <link href="2018/02/27/linux-hou-tai-yun-xing-jin-cheng/"/>
      <url>2018/02/27/linux-hou-tai-yun-xing-jin-cheng/</url>
      
        <content type="html"><![CDATA[<blockquote><p>当我们在终端或控制台工作时，可能不希望由于运行一个作业而占住了屏幕，因为可能还有更重要的事情要做，比如阅读电子邮件。对于密集访问磁盘的进程，我们更希望它能够在每天的非负荷高峰时间段运行(例如凌晨)。为了使这些进程能够在后台运行，也就是说不在终端屏幕上运行，有几种选择方法可供使用。</p></blockquote><h2 id="后台执行"><a href="#后台执行" class="headerlink" title="后台执行"></a>后台执行</h2><p><strong>比较下 &amp; 与 nohup：</strong></p><ul><li>&amp; ：后台运行，但用户终端退出时（断连），命令结束</li><li>nohup test.sh &amp; : 后台运行，用户终端退出时（断连）依然保持运行，可使用标准输入输出</li></ul><h3 id="amp"><a href="#amp" class="headerlink" title="&amp;"></a>&amp;</h3><p>当在前台运行某个作业时，终端被该作业占据；可以在命令后面加上&amp; 实现后台运行。e.g. <code>sh test.sh &amp;</code></p><p>适合在后台运行的命令有f i n d、费时的排序及一些s h e l l脚本。在后台运行作业时要当心：需要用户交互的命令不要放在后台执行，因为这样你的机器就会在那里傻等。不过，作业在后台运行一样会将结果输出到屏幕上，干扰你的工作。如果放在后台运行的作业会产生大量的输出，最好使用下面的方法把它的输出重定向到某个文件中：</p><p><code>command &gt; out.file 2&gt;&amp;1 &amp;</code><br>这样，所有的标准输出和错误输出都将被重定向到一个叫做out.file 的文件中。</p><p>PS：当你成功地提交进程以后，就会显示出一个进程号，可以用它来监控该进程，或杀死它。(ps -ef | grep 进程号 或者 kill -9 进程号）</p><h3 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a>nohup</h3><p>使用&amp;命令后，作业被提交到后台运行，当前控制台没有被占用，但是一但把当前控制台关掉(退出帐户时)，作业就会停止运行。nohup命令可以在你退出帐户之后继续运行相应的进程。nohup就是不挂起的意思( no hang up / ignoring hangup signals) 即 忽略挂起信号一直在后台执行。</p><p><code>语法: nohup Command [ Arg … ] [&amp; ]</code></p><p><code>e.g. $nohup python manage.py runserver &amp;</code></p><p><strong>使用时注意:</strong></p><p>在当shell中提示了nohup成功后，还需要按终端上键盘任意键退回到shell输入命令窗口，然后通过在shell中输入exit来退出终端；如果在nohup执行成功后直接点关闭程序按钮关闭终端的话，这时候会断掉该命令所对应的session，导致nohup对应的进程被通知需要一起shutdown，起不到关掉终端后调用程序继续后台运行的作用。</p><p><code>nohup command &gt; myout.file 2&gt;&amp;1 &amp;</code></p><p>无论是否将 nohup 命令的输出重定向到终端，输出都将附加到当前目录的nohup.out 文件中。如果当前目录的nohup.out文件不可写，输出重定向到$HOME/nohup.out文件中。如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。</p><p><strong>2&gt;&amp;1解析:</strong></p><p><code>command &gt;out.file 2&gt;&amp;1 &amp;</code></p><ul><li><p>command&gt;out.file是将command的输出重定向到out.file文件，即输出内容不打印到屏幕上，而是输出到out.file文件中。</p></li><li><p>2&gt;&amp;1 是将标准出错 重定向到标准输出，这里的标准输出已经重定向到了out.file文件，即将标准出错也输出到out.file文件中。最后一个&amp;， 是让该命令在后台执行。</p></li></ul><p>试想2&gt;1代表什么，2与&gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&gt;&amp;1，&amp;与1结合就代表标准输出了，就变成错误重定向到标准输出.</p><h2 id="查看后台运行的命令"><a href="#查看后台运行的命令" class="headerlink" title="查看后台运行的命令"></a>查看后台运行的命令</h2><p>有两个命令可以来查看，<code>ps</code> 和 <code>jobs</code>。区别在于 jobs 只能查看当前终端后台执行的任务，换了终端就看不见了。而ps命令适用于查看瞬时进程的动态，可以看到别的终端的任务</p><h3 id="jobs"><a href="#jobs" class="headerlink" title="jobs"></a>jobs</h3><p>查看当前有多少在后台运行的命令</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/1603718157_20201026141913132_275681253.png"></p><p>jobs -l选项可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell 从当前的shell环境已知的列表中删除任务的进程标识。</p><p>“+”代表最近的一个任务（当前任务），“-”代表之前的任务。</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/1603718158_20201026143108907_1737208027.png"></p><p>只有在当前命令行中使用 nohup和&amp; 时，jobs命令才能将它显示出来。如果将他们写到 .sh 脚本中，然后执行脚本，是显示不出来的</p><p>比如执行下面这个脚本后，jobs 显示不出来：</p><pre class="line-numbers language-shell"><code class="language-shell">#!/bin/bashnohup java -Dfile.encoding=UTF-8 -Dname=Runtime-Name -server -Xms128M -Xmx512M -XX:MetaspaceSize=128M -XX:MaxMetaspaceSize=256M -XX:+HeapDumpOnOutOfMemoryError -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -jar test.jar $1 $2 $3 &<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><p>nohup命令可以在你退出帐户/关闭终端之后继续运行相应的进程。关闭中断后，在另一个终端<code>jobs</code>已无法看到后台跑得程序了，此时利用ps（进程查看命令）</p><p><code>ps -aux | grep &quot;test.sh&quot;  #a:显示所有程序 u:以用户为主的格式来显示 x:显示所有程序，不以终端机来区分</code></p><h2 id="关闭当前后台运行的程序"><a href="#关闭当前后台运行的程序" class="headerlink" title="关闭当前后台运行的程序"></a>关闭当前后台运行的程序</h2><h3 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h3><ol><li><p>通过jobs命令查看job号（假设为num），然后执行kill %num</p></li><li><p>通过ps命令查看job的进程号（PID，假设为pid），然后执行kill pid</p></li></ol><p>前台进程的终止：ctrl+c</p><h2 id="前后台进程的切换与控制"><a href="#前后台进程的切换与控制" class="headerlink" title="前后台进程的切换与控制"></a>前后台进程的切换与控制</h2><h3 id="ctrl-z-命令"><a href="#ctrl-z-命令" class="headerlink" title="ctrl + z 命令"></a>ctrl + z 命令</h3><p>将一个正在前台执行的命令放到后台，并且处于暂停状态。</p><h3 id="fg-命令"><a href="#fg-命令" class="headerlink" title="fg 命令"></a>fg 命令</h3><p>将后台中的命令 <code>调至 前台继续运行</code>。如果后台中有多个命令，可以用 <code>fg %jobnumber</code>（是命令编号，不是进程号）将选中的命令调出</p><h3 id="bg-命令"><a href="#bg-命令" class="headerlink" title="bg 命令"></a>bg 命令</h3><p>将一个在后台暂停的命令，<code>变成在后台继续执行</code>。如果后台中有多个命令，可以用<code>bg %jobnumber</code>将选中的命令调出。</p><p><img src="https://gitee.com/owen2016/pic-hub/raw/master/1603718158_20201026142920042_1829517779.png"></p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h3 id="问题1-为什么ssh一关闭，程序就不再运行了"><a href="#问题1-为什么ssh一关闭，程序就不再运行了" class="headerlink" title="问题1-为什么ssh一关闭，程序就不再运行了"></a>问题1-为什么ssh一关闭，程序就不再运行了</h3><p>元凶：SIGHUP 信号</p><p>让我们来看看为什么关掉窗口/断开连接会使得正在运行的程序死掉。</p><p>在Linux/Unix中，有这样几个概念：</p><ul><li><p>进程组（process group）：<code>一个或多个进程的集合</code>，每一个进程组有唯一一个进程组ID，即进程组长进程的ID。</p></li><li><p>会话期（session）：<code>一个或多个进程组的集合</code>，有唯一一个会话期首进程（session leader）。会话期ID为首进程的ID。<br>会话期可以有一个单独的控制终端（controlling terminal）。与控制终端连接的会话期首进程叫做控制进程（controlling process）。当前与终端交互的进程称为前台进程组。其余进程组称为后台进程组。</p></li></ul><p>根据POSIX.1定义：</p><ul><li>挂断信号（SIGHUP）默认的动作是终止程序。</li><li>当终端接口检测到网络连接断开，将挂断信号发送给控制进程（会话期首进程）。</li><li>如果会话期首进程终止，则该信号发送到该会话期前台进程组。</li></ul><p>一个进程退出导致一个孤儿进程组中产生时，如果任意一个孤儿进程组进程处于STOP状态，发送SIGHUP和SIGCONT信号到该进程组中所有进程。（关于孤儿进程参照：<a href="http://blog.csdn.net/hmsiwtv/article/details/7901711">http://blog.csdn.net/hmsiwtv/article/details/7901711</a> ）</p><p>结论：因此当网络断开或终端窗口关闭后，也就是SSH断开以后，控制进程收到SIGHUP信号退出，会导致该会话期内其他进程退出。</p><p>简而言之：就是ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉！！ 导致一旦ssh关闭，执行中的任务就取消了</p><p><strong>示例：</strong></p><p>打开两个SSH终端窗口，在其中一个运行top命令。</p><p><code>owen@swarm-manager-105:~$ top</code></p><p>在另一个终端窗口，找到top的进程ID为 38779，其父进程ID为38751，即登录shell。</p><pre class="line-numbers language-shell"><code class="language-shell">owen@swarm-manager-105:~$ ps -ef|grep topowen      24007  23571  0 16:58 tty2     00:00:01 nautilus-desktopowen      38779  38751  0 20:22 pts/1    00:00:00 top<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用pstree命令可以更清楚地看到这个关系：</p><pre class="line-numbers language-shell"><code class="language-shell">owen@swarm-manager-105:~$ pstree -H 38779|grep top        |-sshd-+-sshd---sshd---bash---top<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用<code>ps -xj</code>命令可以看到，登录shell（PID 38751）和top在同一个会话期，shell为会话期首进程，所在进程组PGID为38751，top所在进程组PGID为38779，为前台进程组。</p><pre class="line-numbers language-shell"><code class="language-shell">owen@swarm-manager-105:~$ ps -xj|grep 38751 38750  38751  38751  38751 pts/1     38779 Ss    1000   0:00 -bash 38751  38779  38779  38751 pts/1     38779 S+    1000   0:03 top<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>关闭第一个SSH窗口，在另一个窗口中可以看到top也被杀掉了。</p><pre class="line-numbers language-shell"><code class="language-shell">owen@swarm-manager-105:~$ ps -ef|grep 38751owen      40412  38966  0 20:52 pts/4    00:00:00 grep --color=auto 38751<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="问题2-为什么守护程序就算ssh-打开的，就算关闭ssh也不会影响其运行？"><a href="#问题2-为什么守护程序就算ssh-打开的，就算关闭ssh也不会影响其运行？" class="headerlink" title="问题2- 为什么守护程序就算ssh 打开的，就算关闭ssh也不会影响其运行？"></a>问题2- 为什么守护程序就算ssh 打开的，就算关闭ssh也不会影响其运行？</h3><p>因为他们的程序特殊，比如httpd –k start运行这个以后，他不属于sshd这个进程组  而是单独的进程组，所以就算关闭了ssh，和他也没有任何关系！</p><pre class="line-numbers language-shell"><code class="language-shell">[owen@centos-1 ~]$ pstree |grep http        |-httpd---8*[httpd]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>结论：守护进程的启动命令本身就是特殊的，和一般命令不同的，比如mysqld_safe 这样的命令 一旦使用了  就是守护进程运行。所以想把一般程序改造为守护程序是不可能，</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VSCode </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
